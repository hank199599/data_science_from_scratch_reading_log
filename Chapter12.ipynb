{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter12.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN5/M92XrskmVg6JSwVfwDb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hank199599/data_science_from_scratch_reading_log/blob/main/Chapter12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDopS-BoJ_pE"
      },
      "source": [
        "# 最近鄰分類法(Nearest neighbors)\n",
        "* 要有某種距離的概念\n",
        "* 有個假設：距離較近的點彼此間會較類似"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWyI25qhGPfT"
      },
      "source": [
        "# 計算票數的函式\n",
        "from typing import List\n",
        "from collections import Counter\n",
        "\n",
        "def raw_majority_vote(labels:List[str])->str:\n",
        "  votes = Counter(labels)\n",
        "  winner,_ = votes.most_common(1)[0]\n",
        "  return winner"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPowKhxaNCRy"
      },
      "source": [
        "def major_votes(labels:List[str])->str:\n",
        "  \"\"\"假設labels中的資料已事先依據從進到遠的順序排序\"\"\"\n",
        "  vote_conuts = Counter(labels)\n",
        "  winner,winner_count = vote_conuts.most_common(1)[0]\n",
        "  num_winners = len([count for count in vote_conuts.values() if count == winner_count])\n",
        "  \n",
        "  if num_winners == 1:\n",
        "    return winner\n",
        "  else:\n",
        "    return major_votes(labels[:-1])"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-uEe-h6Ppcs"
      },
      "source": [
        "引用第四章 線性代數 的函數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmCi__GzPd_H"
      },
      "source": [
        "\n",
        "from typing import List\n",
        "\n",
        "Vector = List[float]\n",
        "\n",
        "def subtrate( v:Vector, w:Vector) -> Vector:\n",
        "  assert len(v) == len(w) #兩個向量必須有相同的維度\n",
        "\n",
        "  return [ v_i-w_i for v_i,w_i in zip(v,w)]\n",
        "\n",
        "def magnitude(v:Vector)->float:\n",
        "  return math.sqrt(sum_of_squares(v)) #math.sqrt 是計算平方根的一個函式\n",
        "\n",
        "def distance(v:Vector,w:Vector) -> float:\n",
        "  return magnitude(subtrate(v,w))\n",
        "\n",
        "def sum_of_squares(v:Vector) -> float:\n",
        "  return dot(v,v)\n",
        "\n",
        "def dot(v:Vector,w:Vector)->float:\n",
        "  #計算v_1*w_1+... +v_n*w_n\n",
        "  assert len(v)==len(w),\"兩個向量必須有相同的維度\"\n",
        "\n",
        "  return sum(v_i*w_i for v_i,w_i in zip(v,w))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVZJNciyPqB9"
      },
      "source": [
        "from typing import NamedTuple\n",
        "\n",
        "class LabeledPoint(NamedTuple):\n",
        "  point:Vector\n",
        "  label:str\n",
        "\n",
        "def knn_classify(k:int,\n",
        "         label_points:List[LabeledPoint],\n",
        "         new_point:Vector) ->str:\n",
        "  \n",
        "  #針對這些已標示分類標籤的點，根據距離進到遠的順序進行排序\n",
        "  by_distance = sorted(label_points,\n",
        "             key=lambda lp:distance(lp.point,new_point))\n",
        "  \n",
        "  #找出k個最近點所對應的分類標籤\n",
        "  k_nearest_labels = [lp.label for lp in by_distance[k]]\n",
        "\n",
        "  #讓他們進行投票\n",
        "  return majority_vote(k_nearest_labels)"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvBRtnUuRTIh"
      },
      "source": [
        "## 範例：鳶尾花資料集 \n",
        "在機器學習方面常被運用的資料集。  \n",
        "這個資料集包含150朵鳶尾花的測量值，每一朵花都有對應的花瓣長度、花瓣寬度、萼片長度與萼片寬度、以及它所屬品種。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3TyU_wJR9ZP"
      },
      "source": [
        "**下載資料集**  \n",
        "書本上採行Python內建的IO函式庫，在本地端進行資料讀寫。  \n",
        "於CodeLab上實行，會發生讀寫錯誤只會建檔不會寫入資料。  \n",
        "因而改為透過Numpy函式庫對資料進行處理。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L3z0JzIm3VK"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
        "\n",
        "data=pd.read_csv(url, sep=',',header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9HaoKAOYBPx"
      },
      "source": [
        "|sepal_length|sepal_width|petal_length|petal_width|class|  \n",
        "|---|---|---|---|---|\n",
        "|花瓣長度|花辦寬度|萼片長度|萼片寬度|品種\n",
        "  \n",
        "資料標籤(label)如上顯示↑"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH_Q5MR41lQJ"
      },
      "source": [
        "# 進行預處理，將資料轉換為150個獨立陣列集合\n",
        "preprocess_data = [list(data) for data in zip(list(data[0]),list(data[1]),list(data[2]),list(data[3]),list(data[4]))]\n",
        "preprocess_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TvM9Yk6Mdz9"
      },
      "source": [
        "先將資料載入並轉為「LabeledPoint」物件作為輸入。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe4MuyHaXqgz"
      },
      "source": [
        "from typing import Dict\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "\n",
        "def parse_iris_row(row:List[str])->LabeledPoint:\n",
        "  \"\"\"\n",
        "  sepal_length, sepal_width, petal length, petal_width, class\n",
        "  (花瓣長度,花辦寬度,等片長度,對片寬度,品種)\n",
        "  \"\"\"\n",
        "  measurements = [float(value) for value in row[:-1]]\n",
        "  \n",
        "  #像\"Iris-virginica\"這樣的品種名稱，我們只取其中的\"virginica\"\n",
        "  label = row[-1].split(\"-\")[1]\n",
        "\n",
        "  return LabeledPoint(measurements,label)\n",
        "\n",
        "reader = data\n",
        "iris_data = [parse_iris_row(row) for row in preprocess_data]\n",
        "\n",
        "#我們只處理標有品種名稱的資料點，這樣才能順利畫出圖形\n",
        "points_by_species:Dict[str,List[Vector]] = defaultdict(list)\n",
        "for iris in iris_data:\n",
        "  points_by_species[iris.label].append(iris.point)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFJ0iHK6rT4u"
      },
      "source": [
        "### 圖 12-1 鳶尾花散點圖\n",
        "由於資料有四個維度，很難直接繪製成圖形。  \n",
        "透過將四種測量值兩兩配對形成六種配對方式，再觀察這六種組合的散點圖。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqZgJ1-lrRBS"
      },
      "source": [
        "from matplotlib import pyplot as plt \n",
        "metrics = ['sepal length','sepal width','petal length','petal width']\n",
        "pairs=[(i,j) for i in range(4) for j in range(4) if i<j]\n",
        "marks = [\"+\",\".\",\"x\"] #資料共有三種類別，故採用三種不同的標記符號\n",
        "\n",
        "fig,ax = plt.subplots(2,3) #建立2x3的子圖展示框架\n",
        "\n",
        "for row in range(2):\n",
        "  for col in range(3):\n",
        "    i,j = pairs[3*row+col]\n",
        "    ax[row][col].set_title(f\"{metrics[i]} vs {metrics[j]}\",fontsize=8)\n",
        "    ax[row][col].set_xticks([])\n",
        "    ax[row][col].set_yticks([])\n",
        "\n",
        "    for mark,(species,points) in zip(marks,points_by_species.items()):\n",
        "      xs = [point[i] for point in points]\n",
        "      ys = [point[j] for point in points]\n",
        "      ax[row][col].scatter(xs,ys,marker=mark,label=species)\n",
        "\n",
        "ax[-1][-1].legend(loc='lower right',prop={'size':6})\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUBCD_Ali-pD"
      },
      "source": [
        "透過觀察圖形，可以觀察到測量值會隨著不同品種而構成不同的集群。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1zn-U2jjOJK"
      },
      "source": [
        "### 運用機器學習建立預測模型\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUtcxpDxmJzl"
      },
      "source": [
        "首先，將資料拆分為測試組資料與訓練組資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4pdrM_AmQXu"
      },
      "source": [
        "import random\n",
        "from typing import TypeVar,List,Tuple\n",
        "X=TypeVar('X') #以通用型別來代表資料點\n",
        "\n",
        "def split_data(data:List[X],prob:float) ->Tuple[List[X],List[X]]:\n",
        "  \"\"\"把資料依照[prob,1-prob]的比率進行切割\"\"\"\n",
        "  data = data[:]        #複製一份資料\n",
        "  random.shuffle(data)      #因shuffle會打亂資料\n",
        "  cut = int(len(data)*prob)   #用prob算出切分點\n",
        "  return data[:cut],data[cut:]  #用打亂過的資料進行切分"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcpvJb4zmlXl"
      },
      "source": [
        "random.seed(12)\n",
        "iris_train,iris_test = split_data(iris_data,0.7)\n",
        "assert len(iris_train)==0.7*150\n",
        "assert len(iris_test)==0.3*150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezPmCBo_nCSb"
      },
      "source": [
        "from typing import Tuple\n",
        "import math\n",
        "\n",
        "#追蹤紀錄我們看到幾次(預測值、實際值)\n",
        "confusion_matrix:Dict[Tuple[str,str],int] = defaultdict(int)\n",
        "num_correct = 0\n",
        "\n",
        "for iris in iris_test:\n",
        "  predicted = knn_classify(5,iris_train,iris.point)\n",
        "  actual= iris.label\n",
        "\n",
        "  if predicted == actual:\n",
        "    num_correct += 1\n",
        "\n",
        "  confusion_matrix[(predicted,actual)] += 1\n",
        "\n",
        "pct_correct = num_correct/len(iris_test)\n",
        "print(num_correct,confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc6DOz2TmkxM"
      },
      "source": [
        ""
      ]
    }
  ]
}