{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter19.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNV9Gx9SSuywhKCAH7ggCqs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hank199599/data_science_from_scratch_reading_log/blob/main/Chapter19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-upQJRhBT4RG"
      },
      "source": [
        "# 深度學習(Deep learning)\r\n",
        "原本指的是「深度」神經網路，現被用來泛指各種神經網路。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDNDb28zUSny"
      },
      "source": [
        "# 張量\r\n",
        "在神經網路函示庫中，n維陣列被稱為**張量(tensor)**  \r\n",
        "理想情況下，可以使用：\r\n",
        "\r\n",
        "```python\r\n",
        "# 張量Tensor要不是一個浮點數，就是一個張量列表\r\n",
        "Tensor = Union[float,List[Tensor]]\r\n",
        "```\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woz6w24ma8-S"
      },
      "source": [
        "#如同我們說：\r\n",
        "Tensor = list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd7FNN-kYo3Q"
      },
      "source": [
        "### 輔助函式：找出張量的形狀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWyI25qhGPfT"
      },
      "source": [
        "from typing import List\r\n",
        "\r\n",
        "def shape(tensor: Tensor) -> List[int]:\r\n",
        "    sizes: List[int] = []\r\n",
        "    while isinstance(tensor, list):\r\n",
        "        sizes.append(len(tensor))\r\n",
        "        tensor = tensor[0]\r\n",
        "    return sizes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qb4-AEsazDh"
      },
      "source": [
        "assert shape([1,2,3]) == [3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXsIC8XsazJ8"
      },
      "source": [
        "assert shape([[1,2],[3,4],[5,6]]) == [3,2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7AGAv0fbnqe"
      },
      "source": [
        "由於張量可能具有任意數量的維度，  \r\n",
        "因此在使用張量時，通常需要採用**遞迴**的作法。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xXAhkwzcQRo"
      },
      "source": [
        "def is_1d(tensor:Tensor) ->bool:\r\n",
        "  \"\"\"\r\n",
        "  如果tensor[0]是一個列表，他就是一個高維張量\r\n",
        "  否則就是一個一維向量\r\n",
        "  \"\"\"\r\n",
        "  return not isinstance(tensor[0],list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQBHGayKfGlt"
      },
      "source": [
        "assert is_1d([1,2,3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QqTfOGDfMgf"
      },
      "source": [
        "assert not is_1d([[1,2],[3,4]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An2tSSvMYxou"
      },
      "source": [
        "### 輔助函式：tensor_sum 函數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAp2fHb1h1Tu"
      },
      "source": [
        "def tensor_sum(tensor:Tensor)->float:\r\n",
        "  \"\"\"把張量的所有值加總起來\"\"\"\r\n",
        "  if is_1d(tensor):\r\n",
        "    return sum(tensor) #只是一個浮點數列表，就用Python的sum函式\r\n",
        "  else:\r\n",
        "    return sum(tensor_sum(tensor_i) for tensor_i in tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz3kN599ipib"
      },
      "source": [
        "assert tensor_sum([1,2,3]) == 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nplU-Hygipl6"
      },
      "source": [
        "assert tensor_sum([[1,2],[3,4]]) == 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZPRdxx2i_m3"
      },
      "source": [
        "### 輔助函式：把某個函數套用到單一張量中的每個元素"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6QLhWB_jTNN"
      },
      "source": [
        "from typing import Callable\r\n",
        "\r\n",
        "def tensor_apply(f:Callable[[float],float],tensor:Tensor) ->Tensor:\r\n",
        "  \"\"\"把函式f套用到每個元素\"\"\"\r\n",
        "  if is_1d(tensor):\r\n",
        "    return [f(x) for x in tensor]\r\n",
        "  else:\r\n",
        "    return [tensor_apply(f,tensor_i) for tensor_i in tensor]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TLvyl-bq7pL"
      },
      "source": [
        "assert tensor_apply(lambda x:x+1,[1,2,3]) == [2,3,4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D09dMuvMq7xm"
      },
      "source": [
        "assert tensor_apply(lambda x:2*x,[[1,2],[3,4]]) == [[2,4],[6,8]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmGXgbgRZFLh"
      },
      "source": [
        "### 輔助函式：依據張量形狀，建立另一個形狀一樣的零張量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PSDSY2fZFXx"
      },
      "source": [
        "def zero_like(tensor:Tensor) ->Tensor:\r\n",
        "  return tensor_apply(lambda _: 0.0,tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a87CsAo_ceaQ"
      },
      "source": [
        "assert zero_like([1,2,3]) == [0,0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYPFd8JQcefc"
      },
      "source": [
        "assert zero_like([[1,2],[3,4]]) == [[0,0],[0,0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4XgTY9yczxt"
      },
      "source": [
        "### 輔助函式：將某個函式套用到兩個張量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nM-Tj84czxu"
      },
      "source": [
        "def tensor_combine(f:Callable[[float,float],float],t1:Tensor,t2:Tensor) ->Tensor:\r\n",
        "  \"\"\"把函式f套用到t1與t2的相應元素\"\"\"\r\n",
        "  if is_1d(t1):\r\n",
        "    return [f(x,y) for x,y in zip(t1,t2)]\r\n",
        "  else:\r\n",
        "    return [tensor_combine(f,t1_i,t2_i) for t1_i,t2_i in zip(t1,t2)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnb9TX7zczxv"
      },
      "source": [
        "import operator\r\n",
        "assert tensor_combine(operator.add,[1,2,3],[4,5,6]) == [5,7,9]\r\n",
        "assert tensor_combine(operator.mul,[1,2,3],[4,5,6]) == [4,10,18]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fT8zSoVUX4P"
      },
      "source": [
        "# 層的抽象概念\r\n",
        "\r\n",
        "建立一種機制，能用來時做出各式各樣的神經網路。\r\n",
        "最基本的概念是「Layer」。  \r\n",
        "他知道如何把輸入套入某種函數，亦能夠進行**反向傳播**的方式計算梯度。\r\n",
        "  \r\n",
        "在真正的子類別中，forward 與 backward 方法都會進行實作，  \r\n",
        "一旦建構了神經網路，我們就能以梯度遞減的方式來進行訓練。\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDMQu5srquHd"
      },
      "source": [
        "from typing import Iterable,Tuple\r\n",
        "\r\n",
        "class Layer:\r\n",
        "  \"\"\"\r\n",
        "  我們的神經網路是由許多層組成，其中每一層都知道\r\n",
        "  如何以正向傳播的方式對輸入進行某些計算\r\n",
        "  以及如何以反向傳播的方式計算梯度\r\n",
        "  \"\"\"\r\n",
        "  def forward(self,input):\r\n",
        "    \"\"\"\r\n",
        "    可以注意到，這裡缺了型別可以設定。\r\n",
        "    我們並不打算限定各層的輸入是什麼型別。\r\n",
        "    也不限定return的輸入是甚麼型別\r\n",
        "    \"\"\"\r\n",
        "    raise NotImplementedError\r\n",
        "  \r\n",
        "  def backward(self,gradient):\r\n",
        "    \"\"\"\r\n",
        "    同樣地，我們並不打算限定梯度應該是什麼型別，\r\n",
        "    這完全由你自己決定，\r\n",
        "    只要確定合理即可\r\n",
        "    \"\"\"\r\n",
        "    raise NotImplementedError\r\n",
        "  \r\n",
        "  def params(self)->Iterable[Tensor]:\r\n",
        "    \"\"\"\r\n",
        "    返回此層的參數，預設的實作方式不會回送任何東西。\r\n",
        "    如果你的Layer沒有任何參數，\r\n",
        "    並不需要實做這個方法\r\n",
        "    \"\"\"\r\n",
        "    return ()\r\n",
        "  \r\n",
        "  def grads(self) ->Iterable[Tensor]:\r\n",
        "    \"\"\"\r\n",
        "    送回梯度，順序與params相同\r\n",
        "    \"\"\"\r\n",
        "    return ()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3kdcqT4qTJE"
      },
      "source": [
        "### 範例：不須更新參數的sigmoid層：\r\n",
        "在正向傳遞中，保存了sigmoid函式的計算結果。  \r\n",
        "以供後續的反向傳遞使用。\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FXO4EaYUcBM"
      },
      "source": [
        "from typing import List\r\n",
        "import math\r\n",
        "\r\n",
        "Vector = List[float]\r\n",
        "\r\n",
        "def sigmoid(t:float)->float:\r\n",
        "  return 1/(1+math.exp(-t))\r\n",
        " \r\n",
        "class Sigmoid(Layer):\r\n",
        "  def forward(self, input: Tensor) -> Tensor:\r\n",
        "    \"\"\"\r\n",
        "    把sigmoid函式套用到輸入張量的每個元素，\r\n",
        "    然後儲存結果，供反向傳播使用\r\n",
        "    \"\"\"\r\n",
        "    self.sigmoids = tensor_apply(sigmoid, input)\r\n",
        "    return self.sigmoids\r\n",
        "\r\n",
        "  def backward(self, gradient: Tensor) -> Tensor:\r\n",
        "    \"\"\"\r\n",
        "    微積分連鎖定律之定義：\r\n",
        "    input=(predicted - actual) ** 2\r\n",
        "    d(input)/d(grad) * d(grad)/d(sig) = sig*(1-sig)*grad\r\n",
        "    \"\"\"\r\n",
        "    return tensor_combine(lambda sig, grad: sig * (1 - sig) * grad,\r\n",
        "                                self.sigmoids,\r\n",
        "                                gradient)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBbLJbvHUcmy"
      },
      "source": [
        "## 線性層\r\n",
        "代表神經元的 **dot(weight,inputs)** 點積的部分\r\n",
        "  \r\n",
        "在這裡實作三種方式生成初始的隨機張量：\r\n",
        "1. 自[0,1]的隨機分布中選擇初始值\r\n",
        "2. 自標準常態分布中選擇初始值\r\n",
        "3. 使用「Xavier initialization」，其中每個權重為平均是0，變異量為2/(num_inputs+num_outputs)的標準常態分布中選擇初始值\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHX0GNIrUTVZ"
      },
      "source": [
        "### 前置作業"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKo_NO-0Ueov"
      },
      "source": [
        "import random\r\n",
        "import math\r\n",
        "\r\n",
        "SQRT_TWO_PI = math.sqrt(2* math.pi)\r\n",
        "\r\n",
        "def normal_pdf(x:float,mu:float=0,sigma:float=1) ->float:\r\n",
        "  return (math.exp(-(x-mu)**2/2/sigma**2)/(SQRT_TWO_PI*sigma))\r\n",
        "\r\n",
        "def normal_cdf(x:float,mu:float=0,sigma:float=1)->float:\r\n",
        "  return (1+math.erf((x-mu)/math.sqrt(2)/sigma))/2\r\n",
        "\r\n",
        "def inverse_normal_cdf(p:float,\r\n",
        "            mu:float = 0,\r\n",
        "            sigma:float = 1,\r\n",
        "            tolerance:float=0.00001) -> float:\r\n",
        "  # 如果不是標準常態分佈，就先轉換成標準常態分佈\r\n",
        "  if mu != 0 or sigma != 1:\r\n",
        "    return mu + sigma*inverse_normal_cdf(p,tolerance = tolerance)\r\n",
        "  \r\n",
        "  low_z = -10.0 # normal_cdf(-10)是(趨近於) 0\r\n",
        "  hi_z =  10.0 # normal_cdf(10)是(趨近於) 1\r\n",
        "  while hi_z - low_z > tolerance:  \r\n",
        "    mid_z = (low_z + hi_z) / 2   # 計算出中間值\r\n",
        "    mid_p = normal_cdf(mid_z)     # 以及累積分佈函數在該處所應對的值\r\n",
        "    if mid_p < p :\r\n",
        "      low_z = mid_z        #中間的值太低，就往上繼續搜尋\r\n",
        "    else:\r\n",
        "      hi_z = mid_z        #中間的值太高，就往下繼續搜尋\r\n",
        "  \r\n",
        "  return mid_z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW2Vn3UhJ_Qz"
      },
      "source": [
        "# 自[0,1]的隨機分布中選擇初始值\r\n",
        "def random_uniform(*dims:int) ->Tensor:\r\n",
        "  if len(dims) == 1:\r\n",
        "    return [random.random() for _ in range(dims[0])]\r\n",
        "  else:\r\n",
        "    return [random_uniform(*dims[1:]) for _ in range(dims[0])]\r\n",
        "\r\n",
        "# 自標準常態分布中選擇初始值\r\n",
        "def random_normal(*dims:int,mean:float=0.0,variance:float=1.0) ->Tensor:\r\n",
        "  if len(dims) == 1:\r\n",
        "    return [mean + variance * inverse_normal_cdf(random.random()) for _ in range(dims[0])]\r\n",
        "  else:\r\n",
        "    return [random_normal(*dims[1:],mean=mean,variance=variance) for _ in range(dims[0])]\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mbIHyPPMWif"
      },
      "source": [
        "assert shape(random_uniform(2,3,4)) == [2,3,4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2CncpfLMWlv"
      },
      "source": [
        "assert shape(random_normal(5,6,mean=10)) == [5,6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY4zE-U3TZLi"
      },
      "source": [
        "將他們包裝在random_tensor函式中"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VBwpJI8Tfrw"
      },
      "source": [
        "def random_tensor(*dims:int,init:str = 'normal')->Tensor:\r\n",
        "  if init == 'normal':\r\n",
        "    return random_normal(*dims) # 自[0,1]的隨機分布中選擇初始值\r\n",
        "  elif init == 'uniform':\r\n",
        "    return random_uniform(*dims) # 自標準常態分布中選擇初始值\r\n",
        "  elif init == 'xavier': \r\n",
        "    variance = len(dims)/sum(dims)\r\n",
        "    return random_normal(*dims,variance=variance) #使用「Xavier initialization」，其中每個權重為平均是0，變異量為2/(num_inputs+num_outputs)的標準常態分布中選擇初始值\r\n",
        "  else:\r\n",
        "    raise ValueError(f\"unknown init: {init}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z1E58LWUQMe"
      },
      "source": [
        "### 定義線性層\r\n",
        "須提供以下資訊：  \r\n",
        "* 輸入的維度 (每個神經元需要幾個權重)\r\n",
        "* 輸出的維度 (有幾個神經元)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISoxN0F1UV5U"
      },
      "source": [
        "def dot(v:Vector,w:Vector)->float:\r\n",
        "  #計算v_1*w_1+... +v_n*w_n\r\n",
        "  assert len(v)==len(w),\"兩個向量必須有相同的維度\"\r\n",
        "\r\n",
        "  return sum(v_i*w_i for v_i,w_i in zip(v,w))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiI2le6Od92Z"
      },
      "source": [
        "class Linear(Layer):\r\n",
        "    def __init__(self, input_dim: int, output_dim: int, init: str = 'xavier') -> None:\r\n",
        "        \"\"\"\r\n",
        "        此層具有output_dims個神經元，每個神經元都有 imnput_dims個權重以及一個偏差量\r\n",
        "        \"\"\"\r\n",
        "        self.input_dim = input_dim\r\n",
        "        self.output_dim = output_dim\r\n",
        "\r\n",
        "        # self.w[o] 是第 o 個神經元的權重\r\n",
        "        self.w = random_tensor(output_dim, input_dim, init=init)\r\n",
        "\r\n",
        "        # self.w[o] 是第 o 個神經元的偏差項\r\n",
        "        self.b = random_tensor(output_dim, init=init)\r\n",
        "\r\n",
        "    def forward(self, input: Tensor) -> Tensor:\r\n",
        "        # 保存以供反向傳遞使用\r\n",
        "        self.input = input\r\n",
        "\r\n",
        "        # 送回神經元的輸出向量\r\n",
        "        return [dot(input, self.w[o]) + self.b[o]\r\n",
        "                for o in range(self.output_dim)]\r\n",
        "\r\n",
        "    def backward(self, gradient: Tensor) -> Tensor:\r\n",
        "        # 每個　b[o]　都會被加到　output[o]　之中\r\n",
        "        # 亦即ｂ的梯度等於　output的梯度\r\n",
        "        self.b_grad = gradient\r\n",
        "\r\n",
        "        # 每個w[o][i]都會乘以input[i]再加到output[o]之中\r\n",
        "        # 因此梯度是 input[i]*gradient[o]\r\n",
        "        self.w_grad = [[self.input[i] * gradient[o]\r\n",
        "                        for i in range(self.input_dim)]\r\n",
        "                        for o in range(self.output_dim)]\r\n",
        "\r\n",
        "        # 每個input[i]都會與每個w[o][i]相乘，再加到每個output[o]之中\r\n",
        "        # 因此其梯度就是橫跨所有outputs\r\n",
        "        # w[o][i]*gradient[o]加總之和\r\n",
        "        return [sum(self.w[o][i] * gradient[o] for o in range(self.output_dim))\r\n",
        "                for i in range(self.input_dim)]\r\n",
        "\r\n",
        "    def params(self) -> Iterable[Tensor]:\r\n",
        "        return [self.w, self.b]\r\n",
        "\r\n",
        "    def grads(self) -> Iterable[Tensor]:\r\n",
        "        return [self.w_grad, self.b_grad]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvIcc97hUfl6"
      },
      "source": [
        "# 把神經網路視為一系列的層"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmVWBY0xUlST"
      },
      "source": [
        "from typing import List\r\n",
        "\r\n",
        "class Sequential(Layer):\r\n",
        "  \"\"\"\r\n",
        "  一行就包括一系列的其他層。\r\n",
        "  每一層的輸出做為下一層的輸入，\r\n",
        "  \"\"\"\r\n",
        "  def __init__(self,layers:List[Layer])->None:\r\n",
        "    self.layers = layers\r\n",
        "  \r\n",
        "  def forward(self,input):\r\n",
        "    \"\"\"讓輸入照順序正向通過每一層\"\"\"\r\n",
        "    for layer in self.layers:\r\n",
        "      input = layer.forward(input)\r\n",
        "    return input\r\n",
        "  \r\n",
        "  def backward(self,gradient):\r\n",
        "    \"\"\"讓梯度反向通過每一層以進行反向傳播\"\"\"\r\n",
        "    for layer in reversed(self.layers):\r\n",
        "      gradient = layer.backward(gradient)\r\n",
        "    return gradient\r\n",
        "  \r\n",
        "  def params(self) ->Iterable[Tensor]:\r\n",
        "    \"\"\"送回每一層的參數\"\"\"\r\n",
        "    return (param for layer in self.layers for param in layer.params())\r\n",
        "\r\n",
        "  def grads(self) ->Iterable[Tensor]:\r\n",
        "    \"\"\"送回每一層的梯度\"\"\"\r\n",
        "    return (grad for layer in self.layers for grad in layer.grads())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW9Dara_HLjR"
      },
      "source": [
        "將XOR神經網路表示為："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxIzGM4YHTD0"
      },
      "source": [
        "xor_net=Sequential([\r\n",
        "  Linear(input_dim=2,output_dim=2),\r\n",
        "  Sigmoid(),\r\n",
        "  Linear(input_dim=2,output_dim=1),\r\n",
        "  Sigmoid()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSXW6lccUmge"
      },
      "source": [
        "# 損失與最佳化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7VZXbxRMYXH"
      },
      "source": [
        "### 定義名為「Loss」的抽象類別"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67lJO9pWUoWz"
      },
      "source": [
        "class Loss:\r\n",
        "  def loss(self,predicted:Tensor,actual:Tensor) ->float:\r\n",
        "    \"\"\"計算我們預測結果的程度\"\"\"\r\n",
        "    raise NotImplementedError\r\n",
        "  \r\n",
        "  def gradient(self,predicted:Tensor,actual:Tensor) ->Tensor:\r\n",
        "    \"\"\"如果預測改變，則損失會隨之改變\"\"\"\r\n",
        "    raise NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akk4XbMjMdX0"
      },
      "source": [
        "### 利用**平方誤差和**做為損失函數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grM1_A85Mc4I"
      },
      "source": [
        "class SSE(Loss):\r\n",
        "  \"\"\"計算平方誤差和，以作為損失函數\"\"\"\r\n",
        "  def loss(self,predicted:Tensor,actual:Tensor)->float:\r\n",
        "\r\n",
        "    #計算出平方誤差量\r\n",
        "    squared_errors = tensor_combine(\r\n",
        "      lambda predicted,actual:(predicted - actual) ** 2,\r\n",
        "      predicted,\r\n",
        "      actual)\r\n",
        "\r\n",
        "    #接著全部加總起來\r\n",
        "    return tensor_sum(squared_errors)\r\n",
        "  \r\n",
        "  def gradient(self,predicted:Tensor,actual:Tensor)->Tensor:\r\n",
        "    return tensor_combine(\r\n",
        "      lambda predicted,actual: 2 * (predicted - actual),\r\n",
        "      predicted,\r\n",
        "      actual)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx6raLi4TBRm"
      },
      "source": [
        "sse_loss = SSE()\r\n",
        "assert sse_loss.loss([1, 2, 3], [10, 20, 30]) == 9 ** 2 + 18 ** 2 + 27 ** 2\r\n",
        "assert sse_loss.gradient([1, 2, 3], [10, 20, 30]) == [-18, -36, -54]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcsCqNy6MdBv"
      },
      "source": [
        "### 梯度遞減的實作\r\n",
        "以往是以人工方式完成所有梯度遞減的操作，然而在這裡不太適用。\r\n",
        "\r\n",
        "```python\r\n",
        "theta = gradient_step(theta,grad,-learning_rate)\r\n",
        "```\r\n",
        "\r\n",
        "1. 神經網路有多個參數需要更新\r\n",
        "2. 希望能使用更聰明的梯度遞減變形作法而無須重新改寫程式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITBGvoV7XDX7"
      },
      "source": [
        "class Optimizer:\r\n",
        "  \"\"\"\r\n",
        "  Optimizer會更新layer的權重值，\r\n",
        "  其根據不是來自layer就是來自Optimizer\r\n",
        "  \"\"\"\r\n",
        "  def step(self,layer:Layer) ->None:\r\n",
        "    raise NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4btsn8qbPfD"
      },
      "source": [
        "利用Optimizer來實作梯度遞減\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF-eA1FDbPua"
      },
      "source": [
        "class GradientDescent(Optimizer):\r\n",
        "  def __init__(self,learning_rate:float=0.1)->None:\r\n",
        "    self.lr = learning_rate\r\n",
        "  \r\n",
        "  def step(self,layer:Layer) ->None:\r\n",
        "    for param,grad in zip(layer.params(),layer.grads()):\r\n",
        "      #運用梯度遞減的方式更新參數\r\n",
        "      param[:] = tensor_combine(\r\n",
        "        lambda param,grad:param - grad * self.lr,\r\n",
        "        param,\r\n",
        "        grad\r\n",
        "      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7pAg2xPdtgr"
      },
      "source": [
        "### 片段指定值(slice assignment)\r\n",
        "**反映一個事實**：重新指定列表的值，並不會改變其值\r\n",
        "\r\n",
        "\r\n",
        "```python\r\n",
        "tensor= [[1,2],[3,4]]\r\n",
        "\r\n",
        "for row in tensor:\r\n",
        "  row = [0,0]\r\n",
        "\r\n",
        "assert tensor == [[1,2],[3,4]] #一般指定值的方式不會更動到列表內容\r\n",
        "\r\n",
        "for row in tensor:\r\n",
        "  row[:] = [0,0]\r\n",
        "\r\n",
        "assert tensor == [[0,0],[0,0]] #  片段指定值的方式就會更動到列表內容\r\n",
        "```\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KalOzNqqkiBs"
      },
      "source": [
        "### 動量(momentum)\r\n",
        "保留先前梯度移動平均值，每得到新的梯度值就更新這個平均梯度值並往這個平均方向邁開一步。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ4wJPlAoGMz"
      },
      "source": [
        "class Momentum(Optimizer):\r\n",
        "  def __init__(self,learning_rate:float,momentum:float=0.9) ->None:\r\n",
        "    self.lr = learning_rate\r\n",
        "    self.mo = momentum\r\n",
        "    self.updates:List[Tensor]=[] #移動平均\r\n",
        "\r\n",
        "  def step(self,layer:Layer)->None:\r\n",
        "    #如果還沒有之前的更新值，就全部使用零來當作起始值\r\n",
        "    if not self.updates:\r\n",
        "      self.updates = [zero_like(grad) for grad in layer.grads()]\r\n",
        "    \r\n",
        "    for update,param,grad in zip(self.updates,layer.params(),layer.grads()):\r\n",
        "      #套用動量的計算方式\r\n",
        "      update[:] = tensor_combine(lambda u,g:self.mo * u + (1 - self.mo) * g, update , grad)\r\n",
        "\r\n",
        "      #接著執行梯度遞減的步驟\r\n",
        "      param[:] = tensor_combine(lambda p,u:p-self.lr*u,param,update)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaUMuzB5UpHZ"
      },
      "source": [
        "# 範例：XOR再次嘗試"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTyx0vvHqET0"
      },
      "source": [
        "重新建立訓練資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SB9e9PLUtL-"
      },
      "source": [
        "xs = [[0.,0],[0.,1],[1.,0],[1.,1]]\r\n",
        "ys = [[0.],[1.],[1.],[0.]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4BRthc5qYs-"
      },
      "source": [
        "定義網路  \r\n",
        "(*在這裡可以省去最後的sigmoid層*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IbqiiuaqaRg"
      },
      "source": [
        "random.seed(1)\r\n",
        "\r\n",
        "net = Sequential([\r\n",
        "  Linear(input_dim=2,output_dim=2),\r\n",
        "  Sigmoid(),\r\n",
        "  Linear(input_dim=2,output_dim=1)\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZeRrgzyo7Zt"
      },
      "source": [
        "定義一個簡易的定義迴圈"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KWUoTk9o7hz",
        "outputId": "ccf6325a-2719-476f-9311-b57ba67c22eb"
      },
      "source": [
        "import tqdm\r\n",
        "\r\n",
        "optimizer = GradientDescent(learning_rate=0.1)\r\n",
        "loss = SSE()\r\n",
        "\r\n",
        "with tqdm.trange(3000) as t:\r\n",
        "    for epoch in t:\r\n",
        "        epoch_loss = 0.0\r\n",
        "\r\n",
        "        for x, y in zip(xs, ys):\r\n",
        "            predicted = net.forward(x)\r\n",
        "            epoch_loss += loss.loss(predicted, y)\r\n",
        "            gradient = loss.gradient(predicted, y)\r\n",
        "            net.backward(gradient)\r\n",
        "\r\n",
        "            optimizer.step(net)\r\n",
        "\r\n",
        "        t.set_description(f\"xor loss {epoch_loss:.3f}\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xor loss 0.000: 100%|██████████| 3000/3000 [00:05<00:00, 560.37it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hgt41Bk3log"
      },
      "source": [
        "檢查訓練後的網路"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfLUJHj13pED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "022bda5f-b6fc-48cf-c620-4e223a6618c1"
      },
      "source": [
        "for param in net.params():\r\n",
        "  print(param)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-2.7093966262104487, 2.653711088340027], [2.2917078536634508, -2.251697656785721]]\n",
            "[-1.894089978443923, -1.450879940018008]\n",
            "[[2.594140810886788, 2.5817610835024105]]\n",
            "[-0.8294478276015247]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZdweO51nqdq"
      },
      "source": [
        "從得到的網路來看，結果大致如下：\r\n",
        "* hidden1 = -2.6 * x1 + -2.7 * x2 + 0.2\r\n",
        "* hidden2 = 2.1 * x1 + 2.1 * x2 -3.4\r\n",
        "* optput= -3.1 * h1 + -2.6 * x2 + 1.8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnijD7kSUxY4"
      },
      "source": [
        "# 其他激活函數"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mchWjL1GoqPf"
      },
      "source": [
        "## 雙曲正切函數( tanh, 雙曲正切函數)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN2IrAL4U0Wl"
      },
      "source": [
        "import math\r\n",
        "\r\n",
        "def tanh(x:float) ->float:\r\n",
        "  # 如果x非常大或非常小，tanh就會非常接近-1或1\r\n",
        "  # 由於math.exp(1000)會發生錯誤，因此需要檢查\r\n",
        "  if x < -100 : return -1\r\n",
        "  elif x > 100 : return 1\r\n",
        "\r\n",
        "  emx2 = math.exp(-2*x)\r\n",
        "  return (1-emx2)/(1+emx2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PqzoftmpaVB"
      },
      "source": [
        "class Tanh(Layer):\r\n",
        "  def forward(self,input:Tensor) ->Tensor:\r\n",
        "    #保存tanh輸出以供反向傳播使用\r\n",
        "    self.tanh = tensor_apply(tanh,input)\r\n",
        "    return self.tanh\r\n",
        "  \r\n",
        "  def backward(self,gradient:Tensor) ->Tensor:\r\n",
        "    return tensor_combine(lambda tanh,grad:(1-tanh**2)*grad,\r\n",
        "                self.tanh,\r\n",
        "                gradient)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2XevIb4zRNV"
      },
      "source": [
        "## Relu函數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYVccZHQzVWv"
      },
      "source": [
        "class Relu(Layer):\r\n",
        "  def forward(self,input:Tensor)->Tensor:\r\n",
        "    self.input = input\r\n",
        "    return tensor_apply(lambda x:max(x,0),input)\r\n",
        "  \r\n",
        "  def backward(self,gradient:Tensor)->Tensor:\r\n",
        "    return tensor_combine(lambda x,grad:grad if x >0 else 0, self.input,gradient)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOcHTbFtU1UQ"
      },
      "source": [
        "# **範例**：FizzBuzz 再次嘗試"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR6KOXHsU-OG"
      },
      "source": [
        "#引入上一章建立的函式\r\n",
        "def binary_encode(x:int)->Vector:\r\n",
        "  binary:List[float] = []\r\n",
        "\r\n",
        "  for i in range(10):\r\n",
        "    binary.append(x%2)\r\n",
        "    x = x // 2\r\n",
        "  \r\n",
        "  return binary\r\n",
        "\r\n",
        "\r\n",
        "def fizz_buzz_encode(x:int)->Vector:\r\n",
        "  if x%15 == 0 :\r\n",
        "    return [0,0,0,1]\r\n",
        "  if x%5 == 0 :\r\n",
        "    return [0,0,1,0]\r\n",
        "  if x%3 == 0 :\r\n",
        "    return [0,1,0,0]\r\n",
        "  else:\r\n",
        "    return [1,0,0,0]\r\n",
        "\r\n",
        "def argmax(xs:list) ->int:\r\n",
        "  \"\"\"送回最大值相應的索引值\"\"\"\r\n",
        "  return max(range(len(xs)), key = lambda i:xs[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noftsRFX21V8"
      },
      "source": [
        "xs = [binary_encode(n) for n in range(101,1024)]\r\n",
        "ys = [fizz_buzz_encode(n) for n in range(101,1024)] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdSaH3623GuW"
      },
      "source": [
        "建立網路"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15kq5Z-33FDI"
      },
      "source": [
        "NUM_HIDDEN = 25\r\n",
        "\r\n",
        "random.seed(0)\r\n",
        "\r\n",
        "net = Sequential([\r\n",
        "    Linear(input_dim=10,output_dim=NUM_HIDDEN,init='uniform'),\r\n",
        "    Tanh(),\r\n",
        "    Linear(input_dim=NUM_HIDDEN,output_dim=4,init='uniform'),\r\n",
        "    Sigmoid()\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h96fgFo5AdG"
      },
      "source": [
        "進行訓練時，我們須同時追蹤訓練組資料的正確率變化："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpni_PbE5H2H"
      },
      "source": [
        "def fizzbuzz_accuracy(low:int,hi:int,net:Layer)->float:\r\n",
        "  num_correct = 0\r\n",
        "  for n in range(low,hi):\r\n",
        "    x = binary_encode(n)\r\n",
        "    predicted = argmax(net.forward(x))\r\n",
        "    actual = argmax(fizz_buzz_encode(n))\r\n",
        "\r\n",
        "    if predicted == actual:\r\n",
        "      num_correct += 1\r\n",
        "    \r\n",
        "  return num_correct/(hi-low)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c-yXTie50FI",
        "outputId": "e4c9ac97-a728-41fe-e8c3-a8581e5b8231"
      },
      "source": [
        "optimizer = Momentum(learning_rate=0.1,momentum=0.9)\r\n",
        "loss = SSE()\r\n",
        "\r\n",
        "with tqdm.trange(1000) as t:\r\n",
        "  for epoch in t:\r\n",
        "\r\n",
        "    epoch_loss = 0.0\r\n",
        "\r\n",
        "    for x,y in zip(xs,ys):\r\n",
        "      predicted = net.forward(x)\r\n",
        "      epoch_loss += loss.loss(predicted,y)\r\n",
        "      gradient = loss.gradient(predicted,y)\r\n",
        "      net.backward(gradient)\r\n",
        "\r\n",
        "      optimizer.step(net)\r\n",
        "    \r\n",
        "    accuracy = fizzbuzz_accuracy(101,1024,net)\r\n",
        "    t.set_description(f\"fb loss:{epoch_loss:.2f} acc:{accuracy:.2f}\")\r\n",
        "\r\n",
        "#將測試組資料的結果列印出來\r\n",
        "print()\r\n",
        "print(\"test results\",fizzbuzz_accuracy(1,101,net))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fb loss:64.54 acc:0.95: 100%|██████████| 1000/1000 [08:32<00:00,  1.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "test results 0.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh__l6Z56xti"
      },
      "source": [
        "經過1000次的迭代訓練後，該模型可以在測試組資料上獲得90%以上的正確率。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH64QUuLU-cM"
      },
      "source": [
        "# Softmax與交叉熵"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r3FmtJoynH2"
      },
      "source": [
        "## Softmax 函數\r\n",
        "為了使輸出類別分類時能**以機率來表示可能性**，會採用softmax函數。\r\n",
        "該函數會將數值向量轉換成機率值向量。  \r\n",
        "1. 計算出向量中每個數值的exp(x)\r\n",
        "2. 把每個正值除以所有值的總和 (即 **機率向量** )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT_MJ-jjVLRb"
      },
      "source": [
        "def softmax(tensor:Tensor) -> Tensor:\r\n",
        "  \"\"\"沿著最後一個維度，進行Softmax計算\"\"\"\r\n",
        "  if is_1d(tensor):\r\n",
        "    #考慮數值穩定性，先減去最大值\r\n",
        "    largest = max(tensor)\r\n",
        "    exps = [math.exp( x - largest ) for x in tensor]\r\n",
        "\r\n",
        "    sum_of_steps = sum(exps)\r\n",
        "    return [exp_i / sum_of_steps for exp_i in exps]\r\n",
        "  \r\n",
        "  else:\r\n",
        "    return [softmax(tensor_i) for tensor_i in tensor]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4GOvas62F75"
      },
      "source": [
        "## 交叉熵 (Cross - entropy)\r\n",
        "代表觀測資料的負對數可能性\r\n",
        "  \r\n",
        "如果最小化這個損失，即最大化訓練資料的對數可能性"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogKf3P0Q2tlQ"
      },
      "source": [
        "class SoftmaxCrossEntropy(Loss):\r\n",
        "  \"\"\"\r\n",
        "  這就是在給定神經網路模型的情形下，觀察值的負對數可能性。\r\n",
        "  因此，選擇的權重值若能最小化負對數可能性，\r\n",
        "  也就相當於最大化觀測資料的可能性。\r\n",
        "  \"\"\"\r\n",
        "  def loss(self,predicted:Tensor,actual:Tensor)->float:\r\n",
        "    # 套用softmax取得機率值\r\n",
        "    probabilities = softmax(predicted)\r\n",
        "\r\n",
        "    # 如果是正確的分類i，其值就是log p_i 其他對應類別則為零\r\n",
        "    # 我們會幫p加上一個黑小的值，避免出現log(0)的情況\r\n",
        "    likelihoods = tensor_combine(lambda p, act: math.log(p + 1e-30) * act,\r\n",
        "                                    probabilities,\r\n",
        "                                    actual)\r\n",
        "\r\n",
        "    # 接著全部加總起來，再取負值\r\n",
        "    return -tensor_sum(likelihoods)\r\n",
        "  \r\n",
        "  def gradient(self,predicted:Tensor,actual:Tensor)->Tensor:\r\n",
        "    probabilities = softmax(predicted)\r\n",
        "\r\n",
        "    return tensor_combine(lambda p,actual:p-actual,\r\n",
        "                        probabilities,\r\n",
        "                        actual)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeQacN4K56ao"
      },
      "source": [
        "### 利用SoftmaxCrossEntropy進行嘗試"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5LBNvsz6A4I",
        "outputId": "11ab505c-bcd2-423a-8524-d25b4b08a3ae"
      },
      "source": [
        "xs = [binary_encode(n) for n in range(101,1024)]\r\n",
        "ys = [fizz_buzz_encode(n) for n in range(101,1024)] \r\n",
        "\r\n",
        "random.seed(0)\r\n",
        "\r\n",
        "NUM_HIDDEN=25\r\n",
        "\r\n",
        "net = Sequential([\r\n",
        "    Linear(input_dim=10,output_dim=NUM_HIDDEN,init='uniform'),\r\n",
        "    Tanh(),\r\n",
        "    Linear(input_dim=NUM_HIDDEN,output_dim=4,init='uniform')\r\n",
        "    #現在最後面不是Sigmoid層了\r\n",
        "])\r\n",
        "\r\n",
        "\r\n",
        "optimizer = Momentum(learning_rate=0.1,momentum=0.9)\r\n",
        "loss = SoftmaxCrossEntropy()\r\n",
        "\r\n",
        "with tqdm.trange(100) as t:\r\n",
        "  for epoch in t:\r\n",
        "    epoch_loss = 0.0\r\n",
        "\r\n",
        "    for x,y in zip(xs,ys):\r\n",
        "      predicted = net.forward(x)\r\n",
        "      epoch_loss += loss.loss(predicted,y)\r\n",
        "      gradient = loss.gradient(predicted,y)\r\n",
        "      net.backward(gradient)\r\n",
        "\r\n",
        "      optimizer.step(net)\r\n",
        "    \r\n",
        "    accuracy = fizzbuzz_accuracy(101,1024,net)\r\n",
        "    t.set_description(f\"fb loss:{epoch_loss:.2f} acc:{accuracy:.2f}\")\r\n",
        "\r\n",
        "#將測試組資料的結果列印出來\r\n",
        "print()\r\n",
        "print(\"test results\",fizzbuzz_accuracy(1,101,net))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fb loss:6.12 acc:1.00: 100%|██████████| 100/100 [00:50<00:00,  1.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "test results 0.97\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwm6kqFKagHX"
      },
      "source": [
        "改用SoftmaxCrossEntropy來訓練神經網路，訓練時間能更短且較容易找到結果對應的權重值。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f6CQrGMVGbu"
      },
      "source": [
        "# Dropout 隨機拋棄\r\n",
        "用來防止神經網路出現**過擬和**的情形  \r\n",
        "* 在訓練階段，每個神經元會依據特定機率隨機關閉→神經網路在學習時不能太過依賴單一神經元\r\n",
        "* 在訓練階段則盡量使用到所有神經元 → **Dropout曾必須知道是否處於訓練階段**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dIIcHKXVLxK"
      },
      "source": [
        "class Dropout(Layer):\r\n",
        "  def __init__(self,p:float) ->None:\r\n",
        "    self.p = p\r\n",
        "    self.train = True\r\n",
        "  \r\n",
        "  def forward(self,input:Tensor) ->Tensor:\r\n",
        "    if self.train:\r\n",
        "      # 根據所輸入的機率值，建立一個由0和1組成的遮罩向量 (即建立是否開關要神經元的陣列資料)\r\n",
        "      # 其形狀與輸入相同\r\n",
        "      self.mask = tensor_apply(\r\n",
        "        lambda _ : 0 if random.random() < self.p else 1,\r\n",
        "        input\r\n",
        "      )\r\n",
        "  def backward(self,gradient:Tensor)->Tensor:\r\n",
        "    if self.train:\r\n",
        "      # 只需傳遞 mask == 1 相應位置的梯度\r\n",
        "      return tensor_combine(operator.nul,gradient,self.mask)\r\n",
        "    \r\n",
        "    else:\r\n",
        "      raise RuntimeError(\"don't call backeard when not in train mode\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f84htktVNAg"
      },
      "source": [
        "# 範例：[MNIST](https://yann.lecun.com/exdb/mnist)\r\n",
        "這是一個包含許多手寫數字的資料集  \r\n",
        "由於這個資料即是相對棘手的二元格式，需要額外的函式庫來幫助\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjoWqpPahIdN",
        "outputId": "7403650c-4f28-4abc-ebbf-f8a068fcc52a"
      },
      "source": [
        "!pip install mnist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mnist in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mnist) (1.19.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnZRLFqQoJmN"
      },
      "source": [
        "## 載入訓練圖片"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2lx5MJOVPmz"
      },
      "source": [
        "import mnist\r\n",
        "\r\n",
        "# 下載資料\r\n",
        "mnist.temporary = lambda:'/content/sample_data/'\r\n",
        "\r\n",
        "# 以下幾個函式都會先下載資料，並送回一個numpy陣列\r\n",
        "# 之所以調用 .tolist()是因為我們宣告的「張量」實際上是列表\r\n",
        "train_images = mnist.train_images().tolist()\r\n",
        "train_labels = mnist.train_labels().tolist()\r\n",
        "\r\n",
        "assert shape(train_images) == [60000,28,28]\r\n",
        "assert shape(train_labels) == [60000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK68Dhbyhm2v"
      },
      "source": [
        "將前100個訓練圖片提取出來"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOr7PwfPhu1n"
      },
      "source": [
        "### 圖 19-1 MNIST圖片"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "uhZCvKgWhydz",
        "outputId": "1752e9d8-4e00-4f0c-955a-e4b4c3bf3923"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "fig,ax = plt.subplots(10,10) # 建立內含10*10子圖的圖片\r\n",
        "\r\n",
        "for i in range(10):\r\n",
        "  for j in range(10):\r\n",
        "    # 以黑白格式畫出每張圖片，並隱藏軸線\r\n",
        "    ax[i][j].imshow(train_images[10*i+j],cmap=\"Greys\")\r\n",
        "    ax[i][j].xaxis.set_visible(False)\r\n",
        "    ax[i][j].yaxis.set_visible(False)\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 100 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp33xnlioFuz"
      },
      "source": [
        "## 載入測試圖片"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtovNAKxoORq"
      },
      "source": [
        "test_images = mnist.test_images().tolist()\r\n",
        "test_labels = mnist.test_labels().tolist()\r\n",
        "\r\n",
        "assert shape(test_images) == [10000,28,28]\r\n",
        "assert shape(test_labels) == [10000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hIpSdndogdO"
      },
      "source": [
        "## 資料預處理\r\n",
        "每張圖片都是 28x28 像素，，但我們的線性曾只能處理一維輸入。  \r\n",
        "故要先在進行訓練前進行以下操作：\r\n",
        "1. 將輸入資料**展平**\r\n",
        "2. 再減去平均值 (使訓練效果更好)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRTUl9cWpLLm"
      },
      "source": [
        "# 計算像素平均值\r\n",
        "avg = tensor_sum(train_images) / 60000 / 28 / 28\r\n",
        "\r\n",
        "#重新調整數據的中心與尺度比對\r\n",
        "train_images = [[(pixel - avg)/256 for row in image for pixel in row] for image in train_images]\r\n",
        "test_images = [[(pixel - avg)/256 for row in image for pixel in row] for image in test_images]\r\n",
        "\r\n",
        "assert shape(train_images) == [60000,784],\"圖片應該要先展平\"\r\n",
        "assert shape(test_images) == [10000,784],\"圖片應該要先展平\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjzpq_zytPwZ"
      },
      "source": [
        "調整後，像素的平均值中心應該會很靠近0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQSo-0pTtP7_"
      },
      "source": [
        "assert -0.0001 < tensor_sum(train_images) < 0.0001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzUQbu-DtfQa"
      },
      "source": [
        "## 使用 One-hot編碼的形式表示輸出結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTLcUDfmtlYq"
      },
      "source": [
        "def one_hot_encode(i:int,num_labels:int=10)->List[float]:\r\n",
        "  return [1.0 if j==i else 0.0 for j in range(num_labels)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER6NSk1kt2yt"
      },
      "source": [
        "assert one_hot_encode(3) == [0,0,0,1,0,0,0,0,0,0]\r\n",
        "assert one_hot_encode(2,num_labels=5) == [0,0,1,0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKsnuNsEybD7"
      },
      "source": [
        "套用到我們的資料上"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbpjieQZydVq"
      },
      "source": [
        "train_labels = [one_hot_encode(label) for label in train_labels]\r\n",
        "test_labels = [one_hot_encode(label) for label in test_labels]\r\n",
        "\r\n",
        "assert shape(train_labels) == [60000,10]\r\n",
        "assert shape(test_labels) == [10000,10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2DKRch8uoQl"
      },
      "source": [
        "## 建立將輸入物件進行訓練的函式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOGEH4J1uqSe"
      },
      "source": [
        "import tqdm\r\n",
        "\r\n",
        "def loop(model:Layer,\r\n",
        "     images:List[Tensor],\r\n",
        "     labels:List[Tensor],\r\n",
        "     loss:Loss,\r\n",
        "     optimizer:Optimizer = None) ->None:\r\n",
        "  \r\n",
        "  correct = 0 #追蹤正確預測的數量\r\n",
        "  total_loss = 0.0 #追蹤總損失值\r\n",
        "\r\n",
        "  with tqdm.trange(len(images)) as t:\r\n",
        "    for i in t:\r\n",
        "      prediected = model.forward(images[i])    # 進行預測\r\n",
        "      if argmax(predicted) == argmax(labels[i]): \r\n",
        "        correct += 1               # 若預測正確，則正確次數+1\r\n",
        "      total_loss += loss.loss(predicted,labels[i]) # 計算相對損失\r\n",
        "    \r\n",
        "      # 若正在進行訓練，則反向傳播梯度值並更新權重值\r\n",
        "      if optimizer is not None:\r\n",
        "        gradient = loss.gradient(predicted,labels[i])\r\n",
        "        model.backward(gradient)\r\n",
        "        optimizer.step(normal)\r\n",
        "      \r\n",
        "      # 接著，更新進度條中的相關數值\r\n",
        "      avg_loss = total_loss / (i+1)\r\n",
        "      acc = correct / (i+1)\r\n",
        "      t.set_description(f\"mnist loss : {avg_loss:.3f} acc : {acc:.3f}\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY8k7BQOwjbt"
      },
      "source": [
        "在圖像辨識的模型中，本質上就是在查找10個線性函數。  \r\n",
        "舉例來說，若輸入是5→第五個線性函數就會產生最大的輸出"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPgPdeoOAar7"
      },
      "source": [
        "### 邏輯迴歸\r\n",
        "一個線性層 + 一個SoftMax函數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "z9INCT2ExGpJ",
        "outputId": "361326c3-5133-4648-d2cd-a98f1abed875"
      },
      "source": [
        "random.seed(0)\r\n",
        "\r\n",
        "model = Linear(784,10) # 邏輯迴歸\r\n",
        "loss = SoftmaxCrossEntropy()\r\n",
        "\r\n",
        "optimizer = Momentum(learning_rate=0.01,momentum=0.99)\r\n",
        "\r\n",
        "#針對訓練資料進行訓練\r\n",
        "loop(model,train_images,train_labels,loss,optimizer)\r\n",
        "\r\n",
        "#針對測試資料進行測試(無提供optimizer代表要進行評估)\r\n",
        "loop(model,test_images,test_labels,loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/60000 [00:00<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-da07b0341c54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#針對訓練資料進行訓練\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#針對測試資料進行測試(無提供optimizer代表要進行評估)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-f0311a03ae8f>\u001b[0m in \u001b[0;36mloop\u001b[0;34m(model, images, labels, loss, optimizer)\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-4b641ac13730>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient)\u001b[0m\n\u001b[1;32m     30\u001b[0m         self.w_grad = [[self.input[i] * gradient[o]\n\u001b[1;32m     31\u001b[0m                         for i in range(self.input_dim)]\n\u001b[0;32m---> 32\u001b[0;31m                         for o in range(self.output_dim)]\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# 每個input[i]都會與每個w[o][i]相乘，再加到每個output[o]之中\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-4b641ac13730>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m         self.w_grad = [[self.input[i] * gradient[o]\n\u001b[1;32m     31\u001b[0m                         for i in range(self.input_dim)]\n\u001b[0;32m---> 32\u001b[0;31m                         for o in range(self.output_dim)]\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# 每個input[i]都會與每個w[o][i]相乘，再加到每個output[o]之中\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-4b641ac13730>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# 因此梯度是 input[i]*gradient[o]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         self.w_grad = [[self.input[i] * gradient[o]\n\u001b[0;32m---> 31\u001b[0;31m                         for i in range(self.input_dim)]\n\u001b[0m\u001b[1;32m     32\u001b[0m                         for o in range(self.output_dim)]\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7bLL25ut5hh"
      },
      "source": [
        "### 改造為深度學習神經網路\r\n",
        "兩個隱藏層  \r\n",
        "* 第一層：30個神經元\r\n",
        "* 第二層：10個神經元  \r\n",
        "並採用Tanh激活函數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSkctFs4t92j"
      },
      "source": [
        "random.seed(0)\r\n",
        "\r\n",
        "# 取個名字以便在訓練時啟用或關閉\r\n",
        "dropout1 = Dropout(0.1)\r\n",
        "dropout2 = Dropout(0.1)\r\n",
        "\r\n",
        "model = Sequential([\r\n",
        "  Linear(784,30), # 隱藏層1：大小為10\r\n",
        "  dropout1,\r\n",
        "  Tanh(),\r\n",
        "  Linear(30,10), # 隱藏層2：大小為10\r\n",
        "  dropout2,\r\n",
        "  Tanh(),\r\n",
        "  Linear(10,10) # 輸出層：大小為10\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk4e6zD9uwt5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "c2e66eb7-d487-461e-d27c-6cfa1387e7bf"
      },
      "source": [
        "optimizer = Momentum(learning_rate=0.01,momentum=0.99)\r\n",
        "loss = SoftmaxCrossEntropy()\r\n",
        "\r\n",
        "#針對訓練資料進行訓練\r\n",
        "dropout1.train = dropout2.train = True\r\n",
        "loop(model,train_images,train_labels,loss,optimizer)\r\n",
        "\r\n",
        "#針對測試資料進行測試(無提供optimizer代表要進行評估)\r\n",
        "dropout1.train = dropout2.train = False\r\n",
        "loop(model,train_images,train_labels,loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/60000 [00:00<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-07a58f7ba334>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#針對訓練資料進行訓練\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdropout1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#針對測試資料進行測試(無提供optimizer代表要進行評估)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-f0311a03ae8f>\u001b[0m in \u001b[0;36mloop\u001b[0;34m(model, images, labels, loss, optimizer)\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-4b641ac13730>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient)\u001b[0m\n\u001b[1;32m     30\u001b[0m         self.w_grad = [[self.input[i] * gradient[o]\n\u001b[1;32m     31\u001b[0m                         for i in range(self.input_dim)]\n\u001b[0;32m---> 32\u001b[0;31m                         for o in range(self.output_dim)]\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# 每個input[i]都會與每個w[o][i]相乘，再加到每個output[o]之中\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-4b641ac13730>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m         self.w_grad = [[self.input[i] * gradient[o]\n\u001b[1;32m     31\u001b[0m                         for i in range(self.input_dim)]\n\u001b[0;32m---> 32\u001b[0;31m                         for o in range(self.output_dim)]\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# 每個input[i]都會與每個w[o][i]相乘，再加到每個output[o]之中\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-4b641ac13730>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# 因此梯度是 input[i]*gradient[o]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         self.w_grad = [[self.input[i] * gradient[o]\n\u001b[0;32m---> 31\u001b[0;31m                         for i in range(self.input_dim)]\n\u001b[0m\u001b[1;32m     32\u001b[0m                         for o in range(self.output_dim)]\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpPdggxWVS5F"
      },
      "source": [
        "# 模型的儲存與載入"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxCBiOc9VW6i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}