{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter19.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN7WMMt6cdrlDQpjnU8ra7o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hank199599/data_science_from_scratch_reading_log/blob/main/Chapter19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-upQJRhBT4RG"
      },
      "source": [
        "# 深度學習(Deep learning)\r\n",
        "原本指的是「深度」神經網路，現被用來泛指各種神經網路。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDNDb28zUSny"
      },
      "source": [
        "# 張量\r\n",
        "在神經網路函示庫中，n維振烈被稱為**張量(tensor)**  \r\n",
        "理想情況下，可以使用：\r\n",
        "\r\n",
        "```python\r\n",
        "# 張量Tensor要不是一個浮點數，就是一個張量列表\r\n",
        "Tensor = Union[float,List[Tensor]]\r\n",
        "```\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woz6w24ma8-S"
      },
      "source": [
        "#如同我們說：\r\n",
        "Tensor = list"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd7FNN-kYo3Q"
      },
      "source": [
        "### 輔助函式：找出張量的形狀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWyI25qhGPfT"
      },
      "source": [
        "from typing import List\r\n",
        "\r\n",
        "def shape(tensor:Tensor) ->List[int]:\r\n",
        "  sizes:List[int] = []\r\n",
        "  while isinstance(tensor,list):\r\n",
        "    sizes.append(len(tensor))\r\n",
        "    tensor = tensor[0]\r\n",
        "  return sizes"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qb4-AEsazDh"
      },
      "source": [
        "assert shape([1,2,3]) == [3]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXsIC8XsazJ8"
      },
      "source": [
        "assert shape([[1,2],[3,4],[5,6]]) == [3,2]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7AGAv0fbnqe"
      },
      "source": [
        "由於張量可能具有任意數量的維度，  \r\n",
        "因此在使用張量時，通常需要採用**遞迴**的作法。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xXAhkwzcQRo"
      },
      "source": [
        "def is_1d(tensor:Tensor) ->bool:\r\n",
        "  \"\"\"\r\n",
        "  如果tensor[0]是一個列表，他就是一個高維張量\r\n",
        "  否則就是一個一維向量\r\n",
        "  \"\"\"\r\n",
        "  return not isinstance(tensor[0],list)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQBHGayKfGlt"
      },
      "source": [
        "assert is_1d([1,2,3])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QqTfOGDfMgf"
      },
      "source": [
        "assert not is_1d([[1,2],[3,4]])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An2tSSvMYxou"
      },
      "source": [
        "### 輔助函式：tensor_sum 函數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAp2fHb1h1Tu"
      },
      "source": [
        "def tensor_sum(tensor:Tensor)->float:\r\n",
        "  \"\"\"把張量的所有值加總起來\"\"\"\r\n",
        "  if is_1d(tensor):\r\n",
        "    return sum(tensor) #只是一個浮點數列表，就用Python的sum函式\r\n",
        "  else:\r\n",
        "    return sum(tensor_sum(tensor_i) for tensor_i in tensor)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz3kN599ipib"
      },
      "source": [
        "assert tensor_sum([1,2,3]) == 6"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nplU-Hygipl6"
      },
      "source": [
        "assert tensor_sum([[1,2],[3,4]]) == 10"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZPRdxx2i_m3"
      },
      "source": [
        "### 輔助函式：把某個函數套用到單一張量中的每個元素"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6QLhWB_jTNN"
      },
      "source": [
        "from typing import Callable\r\n",
        "\r\n",
        "def tensor_apply(f:Callable[[float],float],tensor:Tensor) ->Tensor:\r\n",
        "  \"\"\"把函式f套用到每個元素\"\"\"\r\n",
        "  if is_1d(tensor):\r\n",
        "    return [f(x) for x in tensor]\r\n",
        "  else:\r\n",
        "    return [tensor_apply(f,tensor_i) for tensor_i in tensor]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TLvyl-bq7pL"
      },
      "source": [
        "assert tensor_apply(lambda x:x+1,[1,2,3]) == [2,3,4]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D09dMuvMq7xm"
      },
      "source": [
        "assert tensor_apply(lambda x:2*x,[[1,2],[3,4]]) == [[2,4],[6,8]]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmGXgbgRZFLh"
      },
      "source": [
        "### 輔助函式：依據張量形狀，建立另一個形狀一樣的零張量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PSDSY2fZFXx"
      },
      "source": [
        "def zero_like(tensor:Tensor) ->Tensor:\r\n",
        "  return tensor_apply(lambda _: 0.0,tensor)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a87CsAo_ceaQ"
      },
      "source": [
        "assert zero_like([1,2,3]) == [0,0,0]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYPFd8JQcefc"
      },
      "source": [
        "assert zero_like([[1,2],[3,4]]) == [[0,0],[0,0]]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4XgTY9yczxt"
      },
      "source": [
        "### 輔助函式：將某個函式套用到兩個張量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nM-Tj84czxu"
      },
      "source": [
        "def temsor_combine(f:Callable[[float,float],float],t1:Tensor,t2:Tensor) ->Tensor:\r\n",
        "  \"\"\"把函式f套用到t1與t2的相應元素\"\"\"\r\n",
        "  if is_1d(t1):\r\n",
        "    return [f(x,y) for x,y in zip(t1,t2)]\r\n",
        "  else:\r\n",
        "    return [temsor_combine(f,t1_i,t2_i) for t1_i,t2_i in zip(t1,t2)]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnb9TX7zczxv"
      },
      "source": [
        "import operator\r\n",
        "assert temsor_combine(operator.add,[1,2,3],[4,5,6]) == [5,7,9]\r\n",
        "assert temsor_combine(operator.mul,[1,2,3],[4,5,6]) == [4,10,18]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fT8zSoVUX4P"
      },
      "source": [
        "# 層的抽象概念\r\n",
        "\r\n",
        "建立一種機制，能用來時做出各式各樣的神經網路。\r\n",
        "最基本的概念是「Layer」。  \r\n",
        "他知道如何把輸入套入某種函數，亦能夠進行**反向傳播**的方式計算梯度。\r\n",
        "\r\n",
        "\r\n",
        "```python\r\n",
        "from typing import Iterable,Tuple\r\n",
        "\r\n",
        "class Layer:\r\n",
        "  \"\"\"\r\n",
        "  我們的神經網路是由許多層組成，其中每一層都知道\r\n",
        "  如何以正向傳播的方式對輸入進行某些計算\r\n",
        "  以及如何以反向傳播的方式計算梯度\r\n",
        "  \"\"\"\r\n",
        "  def forward(self,input):\r\n",
        "    \"\"\"\r\n",
        "    可以注意到，這裡缺了型別可以設定。\r\n",
        "    我們並不打算限定各層的輸入是什麼型別。\r\n",
        "    也不限定return的輸入是甚麼型別\r\n",
        "    \"\"\"\r\n",
        "    raise NotImplementedError\r\n",
        "  \r\n",
        "  def backward(self,gradient):\r\n",
        "    \"\"\"\r\n",
        "    同樣地，我們並不打算限定梯度應該是什麼型別，\r\n",
        "    這完全由你自己決定，\r\n",
        "    只要確定合理即可\r\n",
        "    \"\"\"\r\n",
        "    raise NotImplementedError\r\n",
        "  \r\n",
        "  def params(self)->Iterable[Tensor]:\r\n",
        "    \"\"\"\r\n",
        "    返回此層的參數，預設的實作方式不會回送任何東西。\r\n",
        "    如果你的Layer沒有任何參數，\r\n",
        "    並不需要實做這個方法\r\n",
        "    \"\"\"\r\n",
        "    return ()\r\n",
        "  def grads(self) ->Iterable[Tensor]:\r\n",
        "    \"\"\"\r\n",
        "    送回梯度，順序與params相同\r\n",
        "    \"\"\"\r\n",
        "    return ()\r\n",
        "```\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FXO4EaYUcBM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBbLJbvHUcmy"
      },
      "source": [
        "# 線性層"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKo_NO-0Ueov"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvIcc97hUfl6"
      },
      "source": [
        "# 把神經網路視為一系列的層"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmVWBY0xUlST"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSXW6lccUmge"
      },
      "source": [
        "# 損失與最佳化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67lJO9pWUoWz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaUMuzB5UpHZ"
      },
      "source": [
        "# 範例：XOR再次嘗試"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SB9e9PLUtL-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnijD7kSUxY4"
      },
      "source": [
        "# 其他激活函數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN2IrAL4U0Wl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOcHTbFtU1UQ"
      },
      "source": [
        "# **範例**：FizzBuzz 再次嘗試"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR6KOXHsU-OG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH64QUuLU-cM"
      },
      "source": [
        "# Softmax與交叉熵"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT_MJ-jjVLRb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f6CQrGMVGbu"
      },
      "source": [
        "# Deopout隨機拋棄"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dIIcHKXVLxK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f84htktVNAg"
      },
      "source": [
        "# 範例：MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2lx5MJOVPmz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpPdggxWVS5F"
      },
      "source": [
        "# 模型的儲存與載入"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxCBiOc9VW6i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}