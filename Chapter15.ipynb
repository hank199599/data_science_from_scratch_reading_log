{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter15.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMkzq8xy8BGJ7IJRSSVdTNF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hank199599/data_science_from_scratch_reading_log/blob/main/Chapter15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqsbSWxNnH9F"
      },
      "source": [
        "# 模型\r\n",
        "假設每個輸入項xi不再只是單一數值，而是一個由xil,...,xik所組成的向量k。  \r\n",
        "多元遞歸模型架設如下：\r\n",
        "\r\n",
        "\r\n",
        "```\r\n",
        "yi = α+β₁χɪʟ+...+βkχɪʟ\r\n",
        "```\r\n",
        "在多元迴歸模型中，參數向量通常以β來表示。  \r\n",
        "若把常數項也包含進來，只需多加一個欄位。\r\n",
        "* beta = [alpha, beta_1 , ... ,beta_k]\r\n",
        "* x_i = [1, x_i1 , ... ,x_ik]\r\n",
        "  \r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbcSA9B144SO"
      },
      "source": [
        "於是我們的模型就變成：  \r\n",
        "[常數項，朋友數量，每天工作時數，有博士學位與否]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWyI25qhGPfT"
      },
      "source": [
        "from typing import List\r\n",
        "\r\n",
        "Vector = List[float]\r\n",
        "\r\n",
        "def dot(v:Vector,w:Vector)->float:\r\n",
        "  #計算v_1*w_1+... +v_n*w_n\r\n",
        "  assert len(v)==len(w),\"兩個向量必須有相同的維度\"\r\n",
        "\r\n",
        "  return sum(v_i*w_i for v_i,w_i in zip(v,w))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNNg__Pb22e6"
      },
      "source": [
        "def predict (x:Vector,beta:Vector) -> float:\r\n",
        "  \"\"\"假設每個x_i的第一個元素都是1\"\"\"\r\n",
        "  return dot(x,beta)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJKIM0Em41Wg"
      },
      "source": [
        "# 關於最小平方模型的進一步假設\r\n",
        "\r\n",
        "1. x的每個元素必須是**線性獨立**的：每個元素皆無法透過其他元素加總來得到。  \r\n",
        "若該假設不成立，則無法得估計出β。\r\n",
        "2. x中的每個元素全都與誤差項ε無關。  \r\n",
        "若該假設不成立，估計β時會發生系統性錯誤。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al8PDSh2TUDB"
      },
      "source": [
        "# 套入模型\r\n",
        "目標：找到某組beta係數值，讓誤差平方得到最小化的結果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1D9nRdYZKTv"
      },
      "source": [
        "## 誤差函數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLzkbC9BZHzS"
      },
      "source": [
        "from typing import List\r\n",
        "\r\n",
        "def error(x:Vector,y:float,beta:Vector) -> float:\r\n",
        "  return predict(x,beta) - y\r\n",
        "\r\n",
        "def squared_error(x:Vector,y:float,beta:Vector) -> float:\r\n",
        "  return error(x,y,beta)**2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPpdzyC4ZtaE"
      },
      "source": [
        "進行測試"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU2MSl4TZu9c"
      },
      "source": [
        "x = [1,2,3]\r\n",
        "y = 30\r\n",
        "beta = [4,4,4] #預測值為 4+8+12 = 24\r\n",
        "\r\n",
        "assert error(x,y,beta) == -6\r\n",
        "assert squared_error(x,y,beta) == 36"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRputwVZacNC"
      },
      "source": [
        "## 計算梯度\r\n",
        "透過微積分"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_VfwsL2agIs"
      },
      "source": [
        "def squerror_gradient(x:Vector,y:float,beta:Vector) -> float:\r\n",
        "  err = error(x,y,beta)\r\n",
        "  return [2*err*x_i for x_i in x]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_EinJUravgW"
      },
      "source": [
        "assert squerror_gradient(x,y,beta) == [-12,-24,-36]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDhZKsPma7mg"
      },
      "source": [
        "## 梯度遞減\r\n",
        "用來找出最佳的beta值"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwKZkd4ibDMN"
      },
      "source": [
        "import random\r\n",
        "import tqdm\r\n",
        "\r\n",
        "from typing import List\r\n",
        "\r\n",
        "Vector = List[float]\r\n",
        "\r\n",
        "def add( v:Vector, w:Vector) -> Vector:\r\n",
        "  assert len(v) == len(w) ,\"兩個向量必須有相同的維度\"\r\n",
        "\r\n",
        "  return [ v_i+w_i for v_i,w_i in zip(v,w)]\r\n",
        "\r\n",
        "def scalar_multiply(c:float,v:Vector) -> Vector:\r\n",
        "  return [c*v_i for v_i in v]\r\n",
        "\r\n",
        "def gradient_step(v:Vector,gradient:Vector,step_size:float) -> Vector:\r\n",
        "  \"\"\"從v沿著gradient的方向移動step_size的距離\"\"\"\r\n",
        "  assert len(v) == len(gradient)\r\n",
        "  step = scalar_multiply(step_size,gradient)\r\n",
        "  return add(v,step)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsYVww-Mbqqi"
      },
      "source": [
        "def least_squares_fit(\r\n",
        "          xs:List[Vector],\r\n",
        "          ys:List[float],\r\n",
        "          learning_rate:float=0.001,\r\n",
        "          num_step:int=1000,\r\n",
        "          batch_size:int=1)->Vector:\r\n",
        "  \"\"\"\r\n",
        "  找出最小化平方誤差和的beta值\r\n",
        "  假設模型y = dot(x,beta)\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  # 一開始先使隨機方式做出猜測\r\n",
        "  guess = [random.random() for _ in x_s[0]]\r\n",
        "\r\n",
        "  for _ in tqdm.trange(num_steps,desc=\"least squares fit\"):\r\n",
        "    for start in range(0,len(xs),batch_size):\r\n",
        "      batch_xs = xs[start:start+batch_size]\r\n",
        "      batch_ys = ys[start:start+batch_size]\r\n",
        "\r\n",
        "      gradient = vector_mean([squerror_gradient(x,y,guess) for x,y in zip(batch_xs,batch_ys)])\r\n",
        "\r\n",
        "      guess = gradient_step(guess,gradient,-learning_rate)\r\n",
        "  \r\n",
        "  return guess"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFV80klNcDr2"
      },
      "source": [
        "## 套用到資料中"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvDMx2NhjB2K"
      },
      "source": [
        "x = [[1,49,4,0],[1,41,9,0],[1,40,8,0],[1,25,6,0],[1,21,1,0],[1,21,0,0],[1,19,3,0],[1,19,0,0],[1,18,9,0],[1,18,8,0],[1,16,4,0],[1,15,3,0],[1,15,0,0],[1,15,2,0],[1,15,7,0],[1,14,0,0],[1,14,1,0],[1,13,1,0],[1,13,7,0],[1,13,4,0],[1,13,2,0],[1,12,5,0],[1,12,0,0],[1,11,9,0],[1,10,9,0],[1,10,1,0],[1,10,1,0],[1,10,7,0],[1,10,9,0],[1,10,1,0],[1,10,6,0],[1,10,6,0],[1,10,8,0],[1,10,10,0],[1,10,6,0],[1,10,0,0],[1,10,5,0],[1,10,3,0],[1,10,4,0],[1,9,9,0],[1,9,9,0],[1,9,0,0],[1,9,0,0],[1,9,6,0],[1,9,10,0],[1,9,8,0],[1,9,5,0],[1,9,2,0],[1,9,9,0],[1,9,10,0],[1,9,7,0],[1,9,2,0],[1,9,0,0],[1,9,4,0],[1,9,6,0],[1,9,4,0],[1,9,7,0],[1,8,3,0],[1,8,2,0],[1,8,4,0],[1,8,9,0],[1,8,2,0],[1,8,3,0],[1,8,5,0],[1,8,8,0],[1,8,0,0],[1,8,9,0],[1,8,10,0],[1,8,5,0],[1,8,5,0],[1,7,5,0],[1,7,5,0],[1,7,0,0],[1,7,2,0],[1,7,8,0],[1,7,10,0],[1,7,5,0],[1,7,3,0],[1,7,3,0],[1,7,6,0],[1,7,7,0],[1,7,7,0],[1,7,9,0],[1,7,3,0],[1,7,8,0],[1,6,4,0],[1,6,6,0],[1,6,4,0],[1,6,9,0],[1,6,0,0],[1,6,1,0],[1,6,4,0],[1,6,1,0],[1,6,0,0],[1,6,7,0],[1,6,0,0],[1,6,8,0],[1,6,4,0],[1,6,2,1],[1,6,1,1],[1,6,3,1],[1,6,6,1],[1,6,4,1],[1,6,4,1],[1,6,1,1],[1,6,3,1],[1,6,4,1],[1,5,1,1],[1,5,9,1],[1,5,4,1],[1,5,6,1],[1,5,4,1],[1,5,4,1],[1,5,10,1],[1,5,5,1],[1,5,2,1],[1,5,4,1],[1,5,4,1],[1,5,9,1],[1,5,3,1],[1,5,10,1],[1,5,2,1],[1,5,2,1],[1,5,9,1],[1,4,8,1],[1,4,6,1],[1,4,0,1],[1,4,10,1],[1,4,5,1],[1,4,10,1],[1,4,9,1],[1,4,1,1],[1,4,4,1],[1,4,4,1],[1,4,0,1],[1,4,3,1],[1,4,1,1],[1,4,3,1],[1,4,2,1],[1,4,4,1],[1,4,4,1],[1,4,8,1],[1,4,2,1],[1,4,4,1],[1,3,2,1],[1,3,6,1],[1,3,4,1],[1,3,7,1],[1,3,4,1],[1,3,1,1],[1,3,10,1],[1,3,3,1],[1,3,4,1],[1,3,7,1],[1,3,5,1],[1,3,6,1],[1,3,1,1],[1,3,6,1],[1,3,10,1],[1,3,2,1],[1,3,4,1],[1,3,2,1],[1,3,1,1],[1,3,5,1],[1,2,4,1],[1,2,2,1],[1,2,8,1],[1,2,3,1],[1,2,1,1],[1,2,9,1],[1,2,10,1],[1,2,9,1],[1,2,4,1],[1,2,5,1],[1,2,0,1],[1,2,9,1],[1,2,9,1],[1,2,0,1],[1,2,1,1],[1,2,1,1],[1,2,4,1],[1,1,0,1],[1,1,2,1],[1,1,2,1],[1,1,5,1],[1,1,3,1],[1,1,10,1],[1,1,6,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,4,1],[1,1,9,1],[1,1,9,1],[1,1,4,1],[1,1,2,1],[1,1,9,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,1,1],[1,1,1,1],[1,1,5,1]]\r\n",
        "daily_minutes_good = [68.77,51.25,52.08,38.36,44.54,57.13,51.4,41.42,31.22,34.76,54.01,38.79,47.59,49.1,27.66,41.03,36.73,48.65,28.12,46.62,35.57,32.98,35,26.07,23.77,39.73,40.57,31.65,31.21,36.32,20.45,21.93,26.02,27.34,23.49,46.94,30.5,33.8,24.23,21.4,27.94,32.24,40.57,25.07,19.42,22.39,18.42,46.96,23.72,26.41,26.97,36.76,40.32,35.02,29.47,30.2,31,38.11,38.18,36.31,21.03,30.86,36.07,28.66,29.08,37.28,15.28,24.17,22.31,30.17,25.53,19.85,35.37,44.6,17.23,13.47,26.33,35.02,32.09,24.81,19.33,28.77,24.26,31.98,25.73,24.86,16.28,34.51,15.23,39.72,40.8,26.06,35.76,34.76,16.13,44.04,18.03,19.65,32.62,35.59,39.43,14.18,35.24,40.13,41.82,35.45,36.07,43.67,24.61,20.9,21.9,18.79,27.61,27.21,26.61,29.77,20.59,27.53,13.82,33.2,25,33.1,36.65,18.63,14.87,22.2,36.81,25.53,24.62,26.25,18.21,28.08,19.42,29.79,32.8,35.99,28.32,27.79,35.88,29.06,36.28,14.1,36.63,37.49,26.9,18.58,38.48,24.48,18.95,33.55,14.24,29.04,32.51,25.63,22.22,19,32.73,15.16,13.9,27.2,32.01,29.27,33,13.74,20.42,27.32,18.23,35.35,28.48,9.08,24.62,20.12,35.26,19.92,31.02,16.49,12.16,30.7,31.22,34.65,13.13,27.51,33.2,31.57,14.1,33.42,17.44,10.12,24.42,9.82,23.39,30.93,15.03,21.67,31.09,33.29,22.61,26.89,23.48,8.38,27.81,32.35,23.84]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKW6Eom7jaTb",
        "outputId": "ec731563-9bba-47fa-9a40-720cc878a994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "random.seed(0)\r\n",
        "\r\n",
        "# 嘗試使用錯誤的方式選擇num_iters和step_size\r\n",
        "# 這會需要花一點時間\r\n",
        "learning_rate = 0.001\r\n",
        "\r\n",
        "beta = least_squares_fit(inputs,daily_minutes_good,learning_rate ,5000,25)\r\n",
        "\r\n",
        "assert 30.50 < beta[0] < 30.70 #常數\r\n",
        "assert 0.96 < beta[0] < 1.00 #朋友的數量\r\n",
        "assert -1.89 < beta[0] < -1.85 #每天的工作時數\r\n",
        "assert 0.91 < beta[0] < 0.94 #有博士學問的話"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ee8e96a57f92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleast_squares_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdaily_minutes_good\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;36m30.50\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m30.70\u001b[0m \u001b[0;31m#常數\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
          ]
        }
      ]
    }
  ]
}