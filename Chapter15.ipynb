{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter15.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPDMZcnSoJOd/IS3kFhb/eN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hank199599/data_science_from_scratch_reading_log/blob/main/Chapter15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqsbSWxNnH9F"
      },
      "source": [
        "# 模型\r\n",
        "假設每個輸入項xi不再只是單一數值，而是一個由xil,...,xik所組成的向量k。  \r\n",
        "多元遞歸模型架設如下：\r\n",
        "\r\n",
        "\r\n",
        "```\r\n",
        "yi = α+β₁χɪʟ+...+βkχɪʟ\r\n",
        "```\r\n",
        "在多元迴歸模型中，參數向量通常以β來表示。  \r\n",
        "若把常數項也包含進來，只需多加一個欄位。\r\n",
        "* beta = [alpha, beta_1 , ... ,beta_k]\r\n",
        "* x_i = [1, x_i1 , ... ,x_ik]\r\n",
        "  \r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbcSA9B144SO"
      },
      "source": [
        "於是我們的模型就變成：  \r\n",
        "[常數項，朋友數量，每天工作時數，有博士學位與否]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWyI25qhGPfT"
      },
      "source": [
        "from typing import List\r\n",
        "\r\n",
        "Vector = List[float]\r\n",
        "\r\n",
        "def dot(v:Vector,w:Vector)->float:\r\n",
        "  #計算v_1*w_1+... +v_n*w_n\r\n",
        "  assert len(v)==len(w),\"兩個向量必須有相同的維度\"\r\n",
        "\r\n",
        "  return sum(v_i*w_i for v_i,w_i in zip(v,w))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNNg__Pb22e6"
      },
      "source": [
        "def predict (x:Vector,beta:Vector) -> float:\r\n",
        "  \"\"\"假設每個x_i的第一個元素都是1\"\"\"\r\n",
        "  return dot(x,beta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJKIM0Em41Wg"
      },
      "source": [
        "# 關於最小平方模型的進一步假設\r\n",
        "\r\n",
        "1. x的每個元素必須是**線性獨立**的：每個元素皆無法透過其他元素加總來得到。  \r\n",
        "若該假設不成立，則無法得估計出β。\r\n",
        "2. x中的每個元素全都與誤差項ε無關。  \r\n",
        "若該假設不成立，估計β時會發生系統性錯誤。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al8PDSh2TUDB"
      },
      "source": [
        "# 套入模型\r\n",
        "目標：找到某組beta係數值，讓誤差平方得到最小化的結果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1D9nRdYZKTv"
      },
      "source": [
        "## 誤差函數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLzkbC9BZHzS"
      },
      "source": [
        "from typing import List\r\n",
        "\r\n",
        "def error(x:Vector,y:float,beta:Vector) -> float:\r\n",
        "  return predict(x,beta) - y\r\n",
        "\r\n",
        "def squared_error(x:Vector,y:float,beta:Vector) -> float:\r\n",
        "  return error(x,y,beta)**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPpdzyC4ZtaE"
      },
      "source": [
        "進行測試"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU2MSl4TZu9c"
      },
      "source": [
        "x = [1,2,3]\r\n",
        "y = 30\r\n",
        "beta = [4,4,4] #預測值為 4+8+12 = 24\r\n",
        "\r\n",
        "assert error(x,y,beta) == -6\r\n",
        "assert squared_error(x,y,beta) == 36"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRputwVZacNC"
      },
      "source": [
        "## 計算梯度\r\n",
        "透過微積分"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_VfwsL2agIs"
      },
      "source": [
        "def squerror_gradient(x:Vector,y:float,beta:Vector) -> float:\r\n",
        "  err = error(x,y,beta)\r\n",
        "  return [2*err*x_i for x_i in x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_EinJUravgW"
      },
      "source": [
        "assert squerror_gradient(x,y,beta) == [-12,-24,-36]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDhZKsPma7mg"
      },
      "source": [
        "## 1. 梯度遞減 (書本上作法)\r\n",
        "用來找出最佳的beta值"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwKZkd4ibDMN"
      },
      "source": [
        "import random\r\n",
        "import tqdm\r\n",
        "\r\n",
        "from typing import List\r\n",
        "\r\n",
        "Vector = List[float]\r\n",
        "\r\n",
        "def add( v:Vector, w:Vector) -> Vector:\r\n",
        "  assert len(v) == len(w) ,\"兩個向量必須有相同的維度\"\r\n",
        "\r\n",
        "  return [ v_i+w_i for v_i,w_i in zip(v,w)]\r\n",
        "\r\n",
        "def vector_sum(vectors:List[Vector]) -> Vector:\r\n",
        "  #先檢查vertors這個向量列表是否為空\r\n",
        "  assert vectors,\"列表中沒有向量!\"\r\n",
        "\r\n",
        "  #檢查vertors 向量列表內的所有向量都具有相同的維度\r\n",
        "  num_elements=len(vectors[0])\r\n",
        "  assert all(len(v)==num_elements for v in vectors),\"向量維度不一致\"\r\n",
        "\r\n",
        "  #所有vectors[i]相加起來，是結果的第i個元素值\r\n",
        "  return [sum(vector[i] for vector in vectors) for i in range(num_elements)]\r\n",
        "\r\n",
        "\r\n",
        "def scalar_multiply(c:float,v:Vector) -> Vector:\r\n",
        "  return [c*v_i for v_i in v]\r\n",
        "\r\n",
        "def vector_mean(vectors:List[Vector])->Vector:\r\n",
        "  n=len(vectors)\r\n",
        "  return scalar_multiply(1/n,vector_sum(vectors))\r\n",
        "\r\n",
        "def gradient_step(v:Vector,gradient:Vector,step_size:float) -> Vector:\r\n",
        "  \"\"\"從v沿著gradient的方向移動step_size的距離\"\"\"\r\n",
        "  assert len(v) == len(gradient)\r\n",
        "  step = scalar_multiply(step_size,gradient)\r\n",
        "  return add(v,step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsYVww-Mbqqi"
      },
      "source": [
        "def least_squares_fit(\r\n",
        "          xs:List[Vector],\r\n",
        "          ys:List[float],\r\n",
        "          learning_rate:float=0.001,\r\n",
        "          num_steps:int=1000,\r\n",
        "          batch_size:int=1)->Vector:\r\n",
        "  \"\"\"\r\n",
        "  找出最小化平方誤差和的beta值\r\n",
        "  假設模型y = dot(x,beta)\r\n",
        "  \"\"\"\r\n",
        "  # 一開始先使隨機方式做出猜測\r\n",
        "  guess = [random.random() for _ in xs[0]]\r\n",
        "\r\n",
        "  for _ in tqdm.trange(num_steps,desc=\"least squares fit\"):\r\n",
        "    for start in range(0,len(xs),batch_size):\r\n",
        "      batch_xs = xs[start:start+batch_size]\r\n",
        "      batch_ys = ys[start:start+batch_size]\r\n",
        "\r\n",
        "      gradient = vector_mean([squerror_gradient(x,y,guess) for x,y in zip(batch_xs,batch_ys)])\r\n",
        "\r\n",
        "      guess = gradient_step(guess,gradient,-learning_rate)\r\n",
        "  \r\n",
        "  return guess"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFV80klNcDr2"
      },
      "source": [
        "## 套用到資料中"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvDMx2NhjB2K"
      },
      "source": [
        "inputs = [[1,49,4,0],[1,41,9,0],[1,40,8,0],[1,25,6,0],[1,21,1,0],[1,21,0,0],[1,19,3,0],[1,19,0,0],[1,18,9,0],[1,18,8,0],[1,16,4,0],[1,15,3,0],[1,15,0,0],[1,15,2,0],[1,15,7,0],[1,14,0,0],[1,14,1,0],[1,13,1,0],[1,13,7,0],[1,13,4,0],[1,13,2,0],[1,12,5,0],[1,12,0,0],[1,11,9,0],[1,10,9,0],[1,10,1,0],[1,10,1,0],[1,10,7,0],[1,10,9,0],[1,10,1,0],[1,10,6,0],[1,10,6,0],[1,10,8,0],[1,10,10,0],[1,10,6,0],[1,10,0,0],[1,10,5,0],[1,10,3,0],[1,10,4,0],[1,9,9,0],[1,9,9,0],[1,9,0,0],[1,9,0,0],[1,9,6,0],[1,9,10,0],[1,9,8,0],[1,9,5,0],[1,9,2,0],[1,9,9,0],[1,9,10,0],[1,9,7,0],[1,9,2,0],[1,9,0,0],[1,9,4,0],[1,9,6,0],[1,9,4,0],[1,9,7,0],[1,8,3,0],[1,8,2,0],[1,8,4,0],[1,8,9,0],[1,8,2,0],[1,8,3,0],[1,8,5,0],[1,8,8,0],[1,8,0,0],[1,8,9,0],[1,8,10,0],[1,8,5,0],[1,8,5,0],[1,7,5,0],[1,7,5,0],[1,7,0,0],[1,7,2,0],[1,7,8,0],[1,7,10,0],[1,7,5,0],[1,7,3,0],[1,7,3,0],[1,7,6,0],[1,7,7,0],[1,7,7,0],[1,7,9,0],[1,7,3,0],[1,7,8,0],[1,6,4,0],[1,6,6,0],[1,6,4,0],[1,6,9,0],[1,6,0,0],[1,6,1,0],[1,6,4,0],[1,6,1,0],[1,6,0,0],[1,6,7,0],[1,6,0,0],[1,6,8,0],[1,6,4,0],[1,6,2,1],[1,6,1,1],[1,6,3,1],[1,6,6,1],[1,6,4,1],[1,6,4,1],[1,6,1,1],[1,6,3,1],[1,6,4,1],[1,5,1,1],[1,5,9,1],[1,5,4,1],[1,5,6,1],[1,5,4,1],[1,5,4,1],[1,5,10,1],[1,5,5,1],[1,5,2,1],[1,5,4,1],[1,5,4,1],[1,5,9,1],[1,5,3,1],[1,5,10,1],[1,5,2,1],[1,5,2,1],[1,5,9,1],[1,4,8,1],[1,4,6,1],[1,4,0,1],[1,4,10,1],[1,4,5,1],[1,4,10,1],[1,4,9,1],[1,4,1,1],[1,4,4,1],[1,4,4,1],[1,4,0,1],[1,4,3,1],[1,4,1,1],[1,4,3,1],[1,4,2,1],[1,4,4,1],[1,4,4,1],[1,4,8,1],[1,4,2,1],[1,4,4,1],[1,3,2,1],[1,3,6,1],[1,3,4,1],[1,3,7,1],[1,3,4,1],[1,3,1,1],[1,3,10,1],[1,3,3,1],[1,3,4,1],[1,3,7,1],[1,3,5,1],[1,3,6,1],[1,3,1,1],[1,3,6,1],[1,3,10,1],[1,3,2,1],[1,3,4,1],[1,3,2,1],[1,3,1,1],[1,3,5,1],[1,2,4,1],[1,2,2,1],[1,2,8,1],[1,2,3,1],[1,2,1,1],[1,2,9,1],[1,2,10,1],[1,2,9,1],[1,2,4,1],[1,2,5,1],[1,2,0,1],[1,2,9,1],[1,2,9,1],[1,2,0,1],[1,2,1,1],[1,2,1,1],[1,2,4,1],[1,1,0,1],[1,1,2,1],[1,1,2,1],[1,1,5,1],[1,1,3,1],[1,1,10,1],[1,1,6,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,4,1],[1,1,9,1],[1,1,9,1],[1,1,4,1],[1,1,2,1],[1,1,9,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,1,1],[1,1,1,1],[1,1,5,1]]\r\n",
        "daily_minutes_good = [68.77,51.25,52.08,38.36,44.54,57.13,51.4,41.42,31.22,34.76,54.01,38.79,47.59,49.1,27.66,41.03,36.73,48.65,28.12,46.62,35.57,32.98,35,26.07,23.77,39.73,40.57,31.65,31.21,36.32,20.45,21.93,26.02,27.34,23.49,46.94,30.5,33.8,24.23,21.4,27.94,32.24,40.57,25.07,19.42,22.39,18.42,46.96,23.72,26.41,26.97,36.76,40.32,35.02,29.47,30.2,31,38.11,38.18,36.31,21.03,30.86,36.07,28.66,29.08,37.28,15.28,24.17,22.31,30.17,25.53,19.85,35.37,44.6,17.23,13.47,26.33,35.02,32.09,24.81,19.33,28.77,24.26,31.98,25.73,24.86,16.28,34.51,15.23,39.72,40.8,26.06,35.76,34.76,16.13,44.04,18.03,19.65,32.62,35.59,39.43,14.18,35.24,40.13,41.82,35.45,36.07,43.67,24.61,20.9,21.9,18.79,27.61,27.21,26.61,29.77,20.59,27.53,13.82,33.2,25,33.1,36.65,18.63,14.87,22.2,36.81,25.53,24.62,26.25,18.21,28.08,19.42,29.79,32.8,35.99,28.32,27.79,35.88,29.06,36.28,14.1,36.63,37.49,26.9,18.58,38.48,24.48,18.95,33.55,14.24,29.04,32.51,25.63,22.22,19,32.73,15.16,13.9,27.2,32.01,29.27,33,13.74,20.42,27.32,18.23,35.35,28.48,9.08,24.62,20.12,35.26,19.92,31.02,16.49,12.16,30.7,31.22,34.65,13.13,27.51,33.2,31.57,14.1,33.42,17.44,10.12,24.42,9.82,23.39,30.93,15.03,21.67,31.09,33.29,22.61,26.89,23.48,8.38,27.81,32.35,23.84]"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKW6Eom7jaTb",
        "outputId": "f9b3d331-602e-4df6-e044-12aaba255ff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "random.seed(0)\r\n",
        "\r\n",
        "# 嘗試使用錯誤的方式選擇num_iters和step_size\r\n",
        "# 這會需要花一點時間\r\n",
        "learning_rate = 0.001\r\n",
        "\r\n",
        "beta = least_squares_fit(inputs,daily_minutes_good,learning_rate ,5000,25)\r\n",
        "\r\n",
        "assert 30.50 < beta[0] < 30.70 #常數\r\n",
        "assert 0.96 < beta[1] < 1.00 #朋友的數量\r\n",
        "assert -1.89 < beta[2] < -1.85 #每天的工作時數\r\n",
        "assert 0.91 < beta[3] < 0.94 #有博士學問的話\r\n",
        "\r\n",
        "np.round(np.array(beta),3)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "least squares fit:   3%|▎         | 168/5000 [00:00<00:02, 1671.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[1, 49, 4, 0], [1, 41, 9, 0], [1, 40, 8, 0], [1, 25, 6, 0], [1, 21, 1, 0], [1, 21, 0, 0], [1, 19, 3, 0], [1, 19, 0, 0], [1, 18, 9, 0], [1, 18, 8, 0], [1, 16, 4, 0], [1, 15, 3, 0], [1, 15, 0, 0], [1, 15, 2, 0], [1, 15, 7, 0], [1, 14, 0, 0], [1, 14, 1, 0], [1, 13, 1, 0], [1, 13, 7, 0], [1, 13, 4, 0], [1, 13, 2, 0], [1, 12, 5, 0], [1, 12, 0, 0], [1, 11, 9, 0], [1, 10, 9, 0], [1, 10, 1, 0], [1, 10, 1, 0], [1, 10, 7, 0], [1, 10, 9, 0], [1, 10, 1, 0], [1, 10, 6, 0], [1, 10, 6, 0], [1, 10, 8, 0], [1, 10, 10, 0], [1, 10, 6, 0], [1, 10, 0, 0], [1, 10, 5, 0], [1, 10, 3, 0], [1, 10, 4, 0], [1, 9, 9, 0], [1, 9, 9, 0], [1, 9, 0, 0], [1, 9, 0, 0], [1, 9, 6, 0], [1, 9, 10, 0], [1, 9, 8, 0], [1, 9, 5, 0], [1, 9, 2, 0], [1, 9, 9, 0], [1, 9, 10, 0], [1, 9, 7, 0], [1, 9, 2, 0], [1, 9, 0, 0], [1, 9, 4, 0], [1, 9, 6, 0], [1, 9, 4, 0], [1, 9, 7, 0], [1, 8, 3, 0], [1, 8, 2, 0], [1, 8, 4, 0], [1, 8, 9, 0], [1, 8, 2, 0], [1, 8, 3, 0], [1, 8, 5, 0], [1, 8, 8, 0], [1, 8, 0, 0], [1, 8, 9, 0], [1, 8, 10, 0], [1, 8, 5, 0], [1, 8, 5, 0], [1, 7, 5, 0], [1, 7, 5, 0], [1, 7, 0, 0], [1, 7, 2, 0], [1, 7, 8, 0], [1, 7, 10, 0], [1, 7, 5, 0], [1, 7, 3, 0], [1, 7, 3, 0], [1, 7, 6, 0], [1, 7, 7, 0], [1, 7, 7, 0], [1, 7, 9, 0], [1, 7, 3, 0], [1, 7, 8, 0], [1, 6, 4, 0], [1, 6, 6, 0], [1, 6, 4, 0], [1, 6, 9, 0], [1, 6, 0, 0], [1, 6, 1, 0], [1, 6, 4, 0], [1, 6, 1, 0], [1, 6, 0, 0], [1, 6, 7, 0], [1, 6, 0, 0], [1, 6, 8, 0], [1, 6, 4, 0], [1, 6, 2, 1], [1, 6, 1, 1], [1, 6, 3, 1], [1, 6, 6, 1], [1, 6, 4, 1], [1, 6, 4, 1], [1, 6, 1, 1], [1, 6, 3, 1], [1, 6, 4, 1], [1, 5, 1, 1], [1, 5, 9, 1], [1, 5, 4, 1], [1, 5, 6, 1], [1, 5, 4, 1], [1, 5, 4, 1], [1, 5, 10, 1], [1, 5, 5, 1], [1, 5, 2, 1], [1, 5, 4, 1], [1, 5, 4, 1], [1, 5, 9, 1], [1, 5, 3, 1], [1, 5, 10, 1], [1, 5, 2, 1], [1, 5, 2, 1], [1, 5, 9, 1], [1, 4, 8, 1], [1, 4, 6, 1], [1, 4, 0, 1], [1, 4, 10, 1], [1, 4, 5, 1], [1, 4, 10, 1], [1, 4, 9, 1], [1, 4, 1, 1], [1, 4, 4, 1], [1, 4, 4, 1], [1, 4, 0, 1], [1, 4, 3, 1], [1, 4, 1, 1], [1, 4, 3, 1], [1, 4, 2, 1], [1, 4, 4, 1], [1, 4, 4, 1], [1, 4, 8, 1], [1, 4, 2, 1], [1, 4, 4, 1], [1, 3, 2, 1], [1, 3, 6, 1], [1, 3, 4, 1], [1, 3, 7, 1], [1, 3, 4, 1], [1, 3, 1, 1], [1, 3, 10, 1], [1, 3, 3, 1], [1, 3, 4, 1], [1, 3, 7, 1], [1, 3, 5, 1], [1, 3, 6, 1], [1, 3, 1, 1], [1, 3, 6, 1], [1, 3, 10, 1], [1, 3, 2, 1], [1, 3, 4, 1], [1, 3, 2, 1], [1, 3, 1, 1], [1, 3, 5, 1], [1, 2, 4, 1], [1, 2, 2, 1], [1, 2, 8, 1], [1, 2, 3, 1], [1, 2, 1, 1], [1, 2, 9, 1], [1, 2, 10, 1], [1, 2, 9, 1], [1, 2, 4, 1], [1, 2, 5, 1], [1, 2, 0, 1], [1, 2, 9, 1], [1, 2, 9, 1], [1, 2, 0, 1], [1, 2, 1, 1], [1, 2, 1, 1], [1, 2, 4, 1], [1, 1, 0, 1], [1, 1, 2, 1], [1, 1, 2, 1], [1, 1, 5, 1], [1, 1, 3, 1], [1, 1, 10, 1], [1, 1, 6, 1], [1, 1, 0, 1], [1, 1, 8, 1], [1, 1, 6, 1], [1, 1, 4, 1], [1, 1, 9, 1], [1, 1, 9, 1], [1, 1, 4, 1], [1, 1, 2, 1], [1, 1, 9, 1], [1, 1, 0, 1], [1, 1, 8, 1], [1, 1, 6, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 5, 1]]\n",
            "[68.77, 51.25, 52.08, 38.36, 44.54, 57.13, 51.4, 41.42, 31.22, 34.76, 54.01, 38.79, 47.59, 49.1, 27.66, 41.03, 36.73, 48.65, 28.12, 46.62, 35.57, 32.98, 35, 26.07, 23.77, 39.73, 40.57, 31.65, 31.21, 36.32, 20.45, 21.93, 26.02, 27.34, 23.49, 46.94, 30.5, 33.8, 24.23, 21.4, 27.94, 32.24, 40.57, 25.07, 19.42, 22.39, 18.42, 46.96, 23.72, 26.41, 26.97, 36.76, 40.32, 35.02, 29.47, 30.2, 31, 38.11, 38.18, 36.31, 21.03, 30.86, 36.07, 28.66, 29.08, 37.28, 15.28, 24.17, 22.31, 30.17, 25.53, 19.85, 35.37, 44.6, 17.23, 13.47, 26.33, 35.02, 32.09, 24.81, 19.33, 28.77, 24.26, 31.98, 25.73, 24.86, 16.28, 34.51, 15.23, 39.72, 40.8, 26.06, 35.76, 34.76, 16.13, 44.04, 18.03, 19.65, 32.62, 35.59, 39.43, 14.18, 35.24, 40.13, 41.82, 35.45, 36.07, 43.67, 24.61, 20.9, 21.9, 18.79, 27.61, 27.21, 26.61, 29.77, 20.59, 27.53, 13.82, 33.2, 25, 33.1, 36.65, 18.63, 14.87, 22.2, 36.81, 25.53, 24.62, 26.25, 18.21, 28.08, 19.42, 29.79, 32.8, 35.99, 28.32, 27.79, 35.88, 29.06, 36.28, 14.1, 36.63, 37.49, 26.9, 18.58, 38.48, 24.48, 18.95, 33.55, 14.24, 29.04, 32.51, 25.63, 22.22, 19, 32.73, 15.16, 13.9, 27.2, 32.01, 29.27, 33, 13.74, 20.42, 27.32, 18.23, 35.35, 28.48, 9.08, 24.62, 20.12, 35.26, 19.92, 31.02, 16.49, 12.16, 30.7, 31.22, 34.65, 13.13, 27.51, 33.2, 31.57, 14.1, 33.42, 17.44, 10.12, 24.42, 9.82, 23.39, 30.93, 15.03, 21.67, 31.09, 33.29, 22.61, 26.89, 23.48, 8.38, 27.81, 32.35, 23.84]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1795.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-2ebf02997ad7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleast_squares_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdaily_minutes_good\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m30.50\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m30.70\u001b[0m \u001b[0;31m#常數\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;36m0.96\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.00\u001b[0m \u001b[0;31m#朋友的數量\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.89\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.85\u001b[0m \u001b[0;31m#每天的工作時數\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnNaVNNxl5H-"
      },
      "source": [
        "在實務上不會使用梯度遞減的方式來計算線性回歸的方法，  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AnxvHxZoh2M"
      },
      "source": [
        "## ✪ [線性代數投影求解](https://ithelp.ithome.com.tw/articles/10186400) (網路資源)\r\n",
        "![公式解](http://i.imgur.com/EngTecm.png)  \r\n",
        "利用numpy函式庫來協助運算\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBevWa5RpsRF"
      },
      "source": [
        "import numpy as np\r\n",
        "x = np.array(inputs)\r\n",
        "y = np.array(daily_minutes_good)\r\n",
        "\r\n",
        "# A = (X^T*X)⁻¹\r\n",
        "transpose_x = np.transpose(x)\r\n",
        "temp = transpose_x @ x\r\n",
        "A = np.linalg.inv(temp)\r\n",
        "\r\n",
        "# D = X^T * y\r\n",
        "D = transpose_x @ y\r\n",
        "\r\n",
        "# β = A*D = 最終解 = (X^T*X)⁻¹ * X^T * y\r\n",
        "β = A @ D\r\n",
        "np.round(β,3) #將最終的解,取小數點後三位"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNfi1bwFmJ2Q"
      },
      "source": [
        "## 運算後，得到的方程式是：\r\n",
        "```\r\n",
        "minutes = 30.579 + 0.973 friends - 1.865 woek hours + 0.923 phd\r\n",
        "```\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ink6Oiven5Ec"
      },
      "source": [
        "# 解釋模型\r\n",
        "　　\r\n",
        "**所有其他因素皆相等的情況下**：\r\n",
        "* 每額外增加一個朋友，每天花在網站上的時間就會增加將近1分鐘。\r\n",
        "* 使用者的工作時間美額外增加１小時，每天花在網站上的時間就會減少將近２分鐘。\r\n",
        "* 每個擁有博士學位的使用者，每天都會在網站上多待近1分鐘。\r\n",
        "  \r\n",
        "這些變數彼此間的交互關係，對於朋友多或少的人來說工作時數的影響**可能是不相同**的。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfGmM79on74k"
      },
      "source": [
        "# 套入優度\r\n",
        "利用**R平方**的值來觀察："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DQ-dhSud4De"
      },
      "source": [
        "def mean(xs:List[float]) -> float:\r\n",
        "  return sum(xs) / len(xs)\r\n",
        "\r\n",
        "def de_mean(xs:List[float]) -> List[float]:\r\n",
        "  x_bar = mean(xs)\r\n",
        "  return [x - x_bar for x in xs] \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK3tAH8Pd8iM"
      },
      "source": [
        "def error(x , y , beta):\r\n",
        "    return y - predict(x,beta)\r\n",
        "\r\n",
        "def sum_of_sqerrors(x , y , beta):\r\n",
        "    return sum( error(x_i , y_i , beta) ** 2\r\n",
        "               for x_i, y_i in zip(x, y))\r\n",
        "\r\n",
        "def total_sum_squares(y:Vector) ->float:\r\n",
        "  \"\"\"每個y_i與平均值之間的差值的總平方和，即「總變異量」\"\"\"\r\n",
        "  return sum(v**2 for v in de_mean(y))\r\n",
        "\r\n",
        "def mulity_r_squares(xs:List[float],ys:Vector,beta:Vector) ->float:\r\n",
        "  \"\"\"\r\n",
        "  模型掌握到y變異量的比率，即(1-模型未掌握到y變異量的比率)\r\n",
        "  \"\"\"\r\n",
        "  sum_of_squared_errors = sum(error(x,y,beta)**2 for x , y in zip(xs,ys))\r\n",
        "  return 1.0 - (sum_of_squared_errors/total_sum_squares(ys))\r\n",
        "\r\n",
        "def total_sum_of_squares(y):\r\n",
        "    \"\"\"the total squared variation of y_i's from their mean\"\"\"\r\n",
        "    return sum(v ** 2 for v in de_mean(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuaKmGXHe49Y"
      },
      "source": [
        "rsq= mulity_r_squares(inputs,daily_minutes_good,beta)\r\n",
        "assert 0.67 < rsq < 0.68\r\n",
        "print(\"%.3f\"%rsq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRCQyN-loMUD"
      },
      "source": [
        "在多元迴歸模型中，還要觀察各個係數的標準差，以衡量所得到每個βi估計值。  \r\n",
        "  \r\n",
        "**衡量誤差的假設**：\r\n",
        "誤差項εi是一個平均值為0，標準差σ的**獨立常態隨機變數**。  \r\n",
        "模型中係數的標準差越大，該係數的可靠程度就越低。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtmhRYwBn_UE"
      },
      "source": [
        "# Bootstrap (重複取樣)\r\n",
        "假設我們有一組其中包含N個資料的樣本，是根據某種未知的分布所生成的：\r\n",
        "\r\n",
        "```\r\n",
        "data = get_sample(num_points = n\r\n",
        "```\r\n",
        "如果重複取得多組的樣本組，我們可以計算出許多樣本組的中位數，進而觀察這些中位數的分布情況。  \r\n",
        "這種情況下，可以「重複採樣(bootstrap)」從原本的資料集內，重新選出n個資料重新組合成新的資料集以取代原本的。\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i-eDbJgGaGM"
      },
      "source": [
        "from typing import TypeVar , Callable\r\n",
        "\r\n",
        "X = TypeVar('X')\r\n",
        "Stat = TypeVar('Stat')\r\n",
        "\r\n",
        "def bootstrap_sample(data:List[X]) -> List[X]:\r\n",
        "  \"\"\"以隨機的方式重複取樣 len(data)\"\"\"\r\n",
        "  return [random.choice(data) for _ in data]\r\n",
        "\r\n",
        "def bootstrap_statistic(data:List[X],stats_fn:Callable[[List[X]],Stat],num_samples:int) -> List[X]:\r\n",
        "  \"\"\" 從 data 取出 num_samples 個重複取樣的樣本，然後進行 states_fn 的計算 \"\"\"\r\n",
        "  return [stats_fn(bootstrap_sample(data)) for _ in range(num_samples)]\r\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVrQgueGLCqZ"
      },
      "source": [
        "考慮下列兩個資料集："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63X8zszILHpo"
      },
      "source": [
        "#101個資料集，其值全都非常接近100\r\n",
        "close_to_100 = [99.5 + random.random() for _ in range(101)]\r\n",
        "\r\n",
        "#101個資料集，其中50個值很接近0，另外50個值很接近200\r\n",
        "far_from_100 = ([99.5 + random.random()]+[random.random() for _ in range(50)]+[200 + random.random() for _ in range(50)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV32IdAF1eWa"
      },
      "source": [
        "計算這組資料集的中位數，結果都會相當靠近100。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQc85B9MtiQv"
      },
      "source": [
        "def dot(v:Vector,w:Vector)->float:\n",
        "  #計算v_1*w_1+... +v_n*w_n\n",
        "  assert len(v)==len(w),\"兩個向量必須有相同的維度\"\n",
        "\n",
        "  return sum(v_i*w_i for v_i,w_i in zip(v,w))\n",
        "\n",
        "def sum_of_squares(v:Vector) -> float:\n",
        "  return dot(v,v)\n",
        "\n",
        "def _medium_odd(xs:List[float]) ->float:\n",
        "  return sorted(xs)[len(xs)//2]\n",
        "\n",
        "def _medium_even(xs:List[float]) ->float:\n",
        "  sorted_xs=sorted(xs)\n",
        "  hi_midpoint=len(xs)//2\n",
        "  return (sorted_xs[hi_midpoint-1]+sorted_xs[hi_midpoint])/2\n",
        "\n",
        "def median(v:List[float])->float:\n",
        "  return _medium_even(v) if len(v)%2 == 0 else _medium_odd(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmIfAn8C1ql_"
      },
      "source": [
        "import math\r\n",
        "\r\n",
        "def variance(xs:List[float]) ->float:\r\n",
        "  assert len(xs),\"至少有兩個元素才能計算變異數\"\r\n",
        "\r\n",
        "  n = len(xs)\r\n",
        "  deviations = de_mean(xs)\r\n",
        "  return sum_of_squares(deviations) / (n-1)\r\n",
        "\r\n",
        "def standard_deviation(xs:List[float]) ->float:\r\n",
        "  return math.sqrt(variance(xs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7MjlQ3A2Ucs"
      },
      "source": [
        "# 數值都很靠近100\r\n",
        "medians_close = bootstrap_statistic( close_to_100 , median ,100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX87Ugn-3djl"
      },
      "source": [
        "# 數值很接近0，亦有都多很靠近200\r\n",
        "medians_far = bootstrap_statistic( far_from_100 , median ,100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW6du56H2UAD"
      },
      "source": [
        "* 第一組資料中位數的標準差會很接近0\r\n",
        "* 第二組資料中位數的標準差會很接近100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU6cu5Pw6CaF"
      },
      "source": [
        "assert standard_deviation(medians_close) < 1\r\n",
        "assert standard_deviation(medians_far) > 90"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z01CCQBRoEcq"
      },
      "source": [
        "## 迴歸係數的標準差\r\n",
        "採用相同的方法，估算出迴歸係數的標準差。  \r\n",
        "針對相同資料集不斷進行重複取樣，就能估算出不同的beta值。  \r\n",
        "* 某自變數經多次取樣後仍沒太大變動 → 該係數的估計值應該十分可靠\r\n",
        "* 某自變數經多次取樣後的變化很大 → 該係數的估計值就不那麼可靠"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyNY4f197EP0"
      },
      "source": [
        "from typing import Tuple\r\n",
        "\r\n",
        "import datetime\r\n",
        "\r\n",
        "def estimate_sample_beta(pairs:List[Tuple[Vector,float]]):\r\n",
        "  learning_rate = 0.001\r\n",
        "  x_sample = [x for x , _ in pairs]\r\n",
        "  y_sample = [y for _ , y in pairs]\r\n",
        "  beta = least_squares_fit(x_sample,y_sample,learning_rate,5000,25)\r\n",
        "  print(\"bootstrap sample\",beta)\r\n",
        "  return beta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3hj4vYf7rq8"
      },
      "source": [
        "random.seed(0)\r\n",
        "\r\n",
        "bootstrap_betas = bootstrap_statistic(list(zip(inputs,daily_minutes_good)),estimate_sample_beta,100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsHa5y1NHkKI"
      },
      "source": [
        "測試"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7QvlVaxHhC5"
      },
      "source": [
        "test = bootstrap_sample(list(zip(inputs,daily_minutes_good)))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYdgOCTUHnv3"
      },
      "source": [
        "estimate_sample_beta(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9FCfh6ZI9k9"
      },
      "source": [
        "test_vector=[[1, 15, 0, 0], [1, 10, 6, 0], [1, 6, 2, 1], [1, 2, 2, 1], [1, 8, 5, 0], [1, 10, 6, 0], [1, 1, 0, 1], [1, 3, 2, 1], [1, 6, 4, 0], [1, 8, 2, 0], [1, 2, 4, 1], [1, 1, 2, 1], [1, 2, 4, 1], [1, 4, 4, 1], [1, 2, 9, 1], [1, 7, 0, 0], [1, 9, 7, 0], [1, 1, 8, 1], [1, 8, 2, 0], [1, 14, 1, 0], [1, 4, 4, 1], [1, 7, 3, 0], [1, 2, 4, 1], [1, 7, 3, 0], [1, 8, 4, 0], [1, 6, 0, 0], [1, 3, 4, 1], [1, 5, 2, 1], [1, 7, 2, 0], [1, 3, 1, 1], [1, 9, 6, 0], [1, 10, 0, 0], [1, 25, 6, 0], [1, 4, 8, 1], [1, 4, 10, 1], [1, 7, 3, 0], [1, 6, 0, 0], [1, 3, 1, 1], [1, 3, 1, 1], [1, 19, 3, 0], [1, 10, 10, 0], [1, 6, 6, 1], [1, 9, 9, 0], [1, 9, 8, 0], [1, 4, 9, 1], [1, 13, 4, 0], [1, 10, 6, 0], [1, 1, 2, 1], [1, 9, 0, 0], [1, 1, 1, 1], [1, 1, 8, 1], [1, 4, 10, 1], [1, 3, 6, 1], [1, 1, 9, 1], [1, 2, 1, 1], [1, 9, 6, 0], [1, 8, 9, 0], [1, 1, 6, 1], [1, 10, 10, 0], [1, 8, 4, 0], [1, 1, 4, 1], [1, 6, 2, 1], [1, 6, 1, 0], [1, 3, 6, 1], [1, 3, 3, 1], [1, 10, 10, 0], [1, 3, 2, 1], [1, 4, 10, 1], [1, 10, 7, 0], [1, 3, 6, 1], [1, 19, 3, 0], [1, 4, 0, 1], [1, 3, 4, 1], [1, 6, 4, 0], [1, 4, 6, 1], [1, 5, 4, 1], [1, 7, 6, 0], [1, 25, 6, 0], [1, 9, 7, 0], [1, 4, 2, 1], [1, 2, 3, 1], [1, 9, 0, 0], [1, 2, 9, 1], [1, 4, 0, 1], [1, 1, 0, 1], [1, 5, 9, 1], [1, 4, 4, 1], [1, 7, 7, 0], [1, 2, 4, 1], [1, 13, 2, 0], [1, 8, 9, 0], [1, 10, 0, 0], [1, 3, 5, 1], [1, 6, 4, 1], [1, 2, 4, 1], [1, 9, 9, 0], [1, 7, 7, 0], [1, 1, 1, 1], [1, 7, 8, 0], [1, 6, 2, 1], [1, 14, 0, 0], [1, 9, 4, 0], [1, 18, 8, 0], [1, 7, 7, 0], [1, 1, 3, 1], [1, 1, 4, 1], [1, 8, 5, 0], [1, 6, 4, 0], [1, 5, 4, 1], [1, 2, 9, 1], [1, 1, 3, 1], [1, 2, 1, 1], [1, 2, 1, 1], [1, 8, 3, 0], [1, 8, 9, 0], [1, 6, 9, 0], [1, 2, 9, 1], [1, 9, 0, 0], [1, 7, 3, 0], [1, 21, 1, 0], [1, 6, 4, 0], [1, 3, 4, 1], [1, 4, 2, 1], [1, 15, 7, 0], [1, 1, 6, 1], [1, 3, 2, 1], [1, 10, 4, 0], [1, 6, 1, 0], [1, 21, 0, 0], [1, 4, 6, 1], [1, 3, 4, 1], [1, 14, 0, 0], [1, 19, 3, 0], [1, 8, 2, 0], [1, 15, 3, 0], [1, 25, 6, 0], [1, 8, 3, 0], [1, 2, 3, 1], [1, 7, 3, 0], [1, 13, 1, 0], [1, 14, 0, 0], [1, 6, 9, 0], [1, 2, 9, 1], [1, 5, 9, 1], [1, 10, 6, 0], [1, 9, 4, 0], [1, 5, 5, 1], [1, 5, 4, 1], [1, 10, 5, 0], [1, 6, 4, 0], [1, 7, 6, 0], [1, 9, 8, 0], [1, 2, 8, 1], [1, 7, 8, 0], [1, 1, 10, 1], [1, 1, 1, 1], [1, 1, 4, 1], [1, 6, 1, 1], [1, 6, 4, 0], [1, 40, 8, 0], [1, 6, 1, 1], [1, 8, 10, 0], [1, 4, 1, 1], [1, 4, 1, 1], [1, 1, 0, 1], [1, 2, 9, 1], [1, 2, 4, 1], [1, 5, 9, 1], [1, 1, 4, 1], [1, 16, 4, 0], [1, 3, 2, 1], [1, 10, 6, 0], [1, 6, 1, 1], [1, 6, 1, 1], [1, 9, 6, 0], [1, 49, 4, 0], [1, 4, 5, 1], [1, 10, 0, 0], [1, 3, 2, 1], [1, 2, 9, 1], [1, 4, 1, 1], [1, 1, 6, 1], [1, 2, 1, 1], [1, 10, 3, 0], [1, 13, 2, 0], [1, 7, 8, 0], [1, 8, 9, 0], [1, 9, 8, 0], [1, 8, 5, 0], [1, 21, 0, 0], [1, 9, 6, 0], [1, 1, 6, 1], [1, 1, 1, 1], [1, 2, 9, 1], [1, 4, 4, 1], [1, 9, 6, 0], [1, 1, 2, 1], [1, 13, 2, 0], [1, 5, 4, 1], [1, 3, 7, 1], [1, 10, 1, 0], [1, 3, 10, 1], [1, 3, 4, 1]]\r\n",
        "test_float=[47.59, 21.93, 32.62, 27.32, 30.17, 20.45, 24.42, 26.9, 26.06, 38.18, 35.26, 31.57, 13.13, 29.06, 9.08, 35.37, 31, 9.82, 30.86, 36.73, 19.42, 32.09, 35.26, 31.98, 36.31, 44.04, 32.01, 36.65, 44.6, 33.55, 25.07, 46.94, 38.36, 14.1, 26.25, 31.98, 34.76, 33.55, 33, 51.4, 27.34, 14.18, 21.4, 22.39, 18.21, 46.62, 23.49, 33.29, 40.32, 27.81, 23.48, 25.53, 18.58, 22.61, 31.22, 29.47, 21.03, 10.12, 27.34, 36.31, 31.09, 32.62, 40.8, 19, 29.04, 27.34, 29.27, 25.53, 31.65, 15.16, 51.4, 32.8, 32.51, 26.06, 22.2, 20.59, 24.81, 38.36, 31, 36.63, 35.35, 32.24, 9.08, 36.81, 24.42, 18.63, 29.06, 19.33, 13.13, 35.57, 15.28, 46.94, 22.22, 35.24, 13.13, 23.72, 28.77, 32.35, 17.23, 32.62, 41.03, 35.02, 34.76, 19.33, 33.42, 30.93, 28.66, 34.51, 27.61, 20.12, 33.42, 28.48, 28.48, 38.11, 15.28, 15.23, 20.12, 32.24, 32.09, 44.54, 26.06, 38.48, 35.88, 27.66, 10.12, 29.27, 24.23, 40.8, 57.13, 22.2, 32.01, 41.03, 51.4, 30.86, 38.79, 38.36, 38.11, 35.35, 31.98, 48.65, 41.03, 15.23, 9.08, 24.61, 23.49, 30.2, 26.61, 18.79, 30.5, 26.06, 24.81, 22.39, 18.23, 25.73, 17.44, 32.35, 30.93, 41.82, 19.65, 52.08, 41.82, 24.17, 28.32, 28.32, 24.42, 16.49, 13.13, 13.82, 31.09, 54.01, 26.9, 21.93, 41.82, 35.59, 25.07, 68.77, 24.62, 46.94, 27.2, 9.08, 28.08, 10.12, 34.65, 33.8, 35.57, 25.73, 21.03, 22.39, 28.66, 57.13, 25.07, 23.39, 32.35, 16.49, 37.49, 25.07, 31.57, 35.57, 20.9, 25.63, 40.57, 13.9, 32.01]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTSNki3eJGyo",
        "outputId": "7dac0be5-6b5b-4bc4-f628-bc7a0172dfa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "least_squares_fit(test_vector,test_float,0.0001,5000,25)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "least squares fit:   3%|▎         | 169/5000 [00:00<00:02, 1689.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[1, 15, 0, 0], [1, 10, 6, 0], [1, 6, 2, 1], [1, 2, 2, 1], [1, 8, 5, 0], [1, 10, 6, 0], [1, 1, 0, 1], [1, 3, 2, 1], [1, 6, 4, 0], [1, 8, 2, 0], [1, 2, 4, 1], [1, 1, 2, 1], [1, 2, 4, 1], [1, 4, 4, 1], [1, 2, 9, 1], [1, 7, 0, 0], [1, 9, 7, 0], [1, 1, 8, 1], [1, 8, 2, 0], [1, 14, 1, 0], [1, 4, 4, 1], [1, 7, 3, 0], [1, 2, 4, 1], [1, 7, 3, 0], [1, 8, 4, 0], [1, 6, 0, 0], [1, 3, 4, 1], [1, 5, 2, 1], [1, 7, 2, 0], [1, 3, 1, 1], [1, 9, 6, 0], [1, 10, 0, 0], [1, 25, 6, 0], [1, 4, 8, 1], [1, 4, 10, 1], [1, 7, 3, 0], [1, 6, 0, 0], [1, 3, 1, 1], [1, 3, 1, 1], [1, 19, 3, 0], [1, 10, 10, 0], [1, 6, 6, 1], [1, 9, 9, 0], [1, 9, 8, 0], [1, 4, 9, 1], [1, 13, 4, 0], [1, 10, 6, 0], [1, 1, 2, 1], [1, 9, 0, 0], [1, 1, 1, 1], [1, 1, 8, 1], [1, 4, 10, 1], [1, 3, 6, 1], [1, 1, 9, 1], [1, 2, 1, 1], [1, 9, 6, 0], [1, 8, 9, 0], [1, 1, 6, 1], [1, 10, 10, 0], [1, 8, 4, 0], [1, 1, 4, 1], [1, 6, 2, 1], [1, 6, 1, 0], [1, 3, 6, 1], [1, 3, 3, 1], [1, 10, 10, 0], [1, 3, 2, 1], [1, 4, 10, 1], [1, 10, 7, 0], [1, 3, 6, 1], [1, 19, 3, 0], [1, 4, 0, 1], [1, 3, 4, 1], [1, 6, 4, 0], [1, 4, 6, 1], [1, 5, 4, 1], [1, 7, 6, 0], [1, 25, 6, 0], [1, 9, 7, 0], [1, 4, 2, 1], [1, 2, 3, 1], [1, 9, 0, 0], [1, 2, 9, 1], [1, 4, 0, 1], [1, 1, 0, 1], [1, 5, 9, 1], [1, 4, 4, 1], [1, 7, 7, 0], [1, 2, 4, 1], [1, 13, 2, 0], [1, 8, 9, 0], [1, 10, 0, 0], [1, 3, 5, 1], [1, 6, 4, 1], [1, 2, 4, 1], [1, 9, 9, 0], [1, 7, 7, 0], [1, 1, 1, 1], [1, 7, 8, 0], [1, 6, 2, 1], [1, 14, 0, 0], [1, 9, 4, 0], [1, 18, 8, 0], [1, 7, 7, 0], [1, 1, 3, 1], [1, 1, 4, 1], [1, 8, 5, 0], [1, 6, 4, 0], [1, 5, 4, 1], [1, 2, 9, 1], [1, 1, 3, 1], [1, 2, 1, 1], [1, 2, 1, 1], [1, 8, 3, 0], [1, 8, 9, 0], [1, 6, 9, 0], [1, 2, 9, 1], [1, 9, 0, 0], [1, 7, 3, 0], [1, 21, 1, 0], [1, 6, 4, 0], [1, 3, 4, 1], [1, 4, 2, 1], [1, 15, 7, 0], [1, 1, 6, 1], [1, 3, 2, 1], [1, 10, 4, 0], [1, 6, 1, 0], [1, 21, 0, 0], [1, 4, 6, 1], [1, 3, 4, 1], [1, 14, 0, 0], [1, 19, 3, 0], [1, 8, 2, 0], [1, 15, 3, 0], [1, 25, 6, 0], [1, 8, 3, 0], [1, 2, 3, 1], [1, 7, 3, 0], [1, 13, 1, 0], [1, 14, 0, 0], [1, 6, 9, 0], [1, 2, 9, 1], [1, 5, 9, 1], [1, 10, 6, 0], [1, 9, 4, 0], [1, 5, 5, 1], [1, 5, 4, 1], [1, 10, 5, 0], [1, 6, 4, 0], [1, 7, 6, 0], [1, 9, 8, 0], [1, 2, 8, 1], [1, 7, 8, 0], [1, 1, 10, 1], [1, 1, 1, 1], [1, 1, 4, 1], [1, 6, 1, 1], [1, 6, 4, 0], [1, 40, 8, 0], [1, 6, 1, 1], [1, 8, 10, 0], [1, 4, 1, 1], [1, 4, 1, 1], [1, 1, 0, 1], [1, 2, 9, 1], [1, 2, 4, 1], [1, 5, 9, 1], [1, 1, 4, 1], [1, 16, 4, 0], [1, 3, 2, 1], [1, 10, 6, 0], [1, 6, 1, 1], [1, 6, 1, 1], [1, 9, 6, 0], [1, 49, 4, 0], [1, 4, 5, 1], [1, 10, 0, 0], [1, 3, 2, 1], [1, 2, 9, 1], [1, 4, 1, 1], [1, 1, 6, 1], [1, 2, 1, 1], [1, 10, 3, 0], [1, 13, 2, 0], [1, 7, 8, 0], [1, 8, 9, 0], [1, 9, 8, 0], [1, 8, 5, 0], [1, 21, 0, 0], [1, 9, 6, 0], [1, 1, 6, 1], [1, 1, 1, 1], [1, 2, 9, 1], [1, 4, 4, 1], [1, 9, 6, 0], [1, 1, 2, 1], [1, 13, 2, 0], [1, 5, 4, 1], [1, 3, 7, 1], [1, 10, 1, 0], [1, 3, 10, 1], [1, 3, 4, 1]]\n",
            "[47.59, 21.93, 32.62, 27.32, 30.17, 20.45, 24.42, 26.9, 26.06, 38.18, 35.26, 31.57, 13.13, 29.06, 9.08, 35.37, 31, 9.82, 30.86, 36.73, 19.42, 32.09, 35.26, 31.98, 36.31, 44.04, 32.01, 36.65, 44.6, 33.55, 25.07, 46.94, 38.36, 14.1, 26.25, 31.98, 34.76, 33.55, 33, 51.4, 27.34, 14.18, 21.4, 22.39, 18.21, 46.62, 23.49, 33.29, 40.32, 27.81, 23.48, 25.53, 18.58, 22.61, 31.22, 29.47, 21.03, 10.12, 27.34, 36.31, 31.09, 32.62, 40.8, 19, 29.04, 27.34, 29.27, 25.53, 31.65, 15.16, 51.4, 32.8, 32.51, 26.06, 22.2, 20.59, 24.81, 38.36, 31, 36.63, 35.35, 32.24, 9.08, 36.81, 24.42, 18.63, 29.06, 19.33, 13.13, 35.57, 15.28, 46.94, 22.22, 35.24, 13.13, 23.72, 28.77, 32.35, 17.23, 32.62, 41.03, 35.02, 34.76, 19.33, 33.42, 30.93, 28.66, 34.51, 27.61, 20.12, 33.42, 28.48, 28.48, 38.11, 15.28, 15.23, 20.12, 32.24, 32.09, 44.54, 26.06, 38.48, 35.88, 27.66, 10.12, 29.27, 24.23, 40.8, 57.13, 22.2, 32.01, 41.03, 51.4, 30.86, 38.79, 38.36, 38.11, 35.35, 31.98, 48.65, 41.03, 15.23, 9.08, 24.61, 23.49, 30.2, 26.61, 18.79, 30.5, 26.06, 24.81, 22.39, 18.23, 25.73, 17.44, 32.35, 30.93, 41.82, 19.65, 52.08, 41.82, 24.17, 28.32, 28.32, 24.42, 16.49, 13.13, 13.82, 31.09, 54.01, 26.9, 21.93, 41.82, 35.59, 25.07, 68.77, 24.62, 46.94, 27.2, 9.08, 28.08, 10.12, 34.65, 33.8, 35.57, 25.73, 21.03, 22.39, 28.66, 57.13, 25.07, 23.39, 32.35, 16.49, 37.49, 25.07, 31.57, 35.57, 20.9, 25.63, 40.57, 13.9, 32.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1787.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[nan, nan, nan, nan]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziDeSy81IbVA"
      },
      "source": [
        "原本的程式碼後續"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbbmDqRCASEk"
      },
      "source": [
        "bootstarp_standard_errors = [\r\n",
        "  standard_deviation([beta[i] for beta in bootstrap_betas])\r\n",
        "  for i in range(4)\r\n",
        "]\r\n",
        "\r\n",
        "print(bootstarp_standard_errors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQMIAbpLoLOA"
      },
      "source": [
        "# 正則化"
      ]
    }
  ]
}