{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter15.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNGsijlNrE5B+o+Jg+JvtT0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hank199599/data_science_from_scratch_reading_log/blob/main/Chapter15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqsbSWxNnH9F"
      },
      "source": [
        "# 模型\r\n",
        "假設每個輸入項xi不再只是單一數值，而是一個由xil,...,xik所組成的向量k。  \r\n",
        "多元遞歸模型架設如下：\r\n",
        "\r\n",
        "\r\n",
        "```\r\n",
        "yi = α+β₁χɪʟ+...+βkχɪʟ\r\n",
        "```\r\n",
        "在多元迴歸模型中，參數向量通常以β來表示。  \r\n",
        "若把常數項也包含進來，只需多加一個欄位。\r\n",
        "* beta = [alpha, beta_1 , ... ,beta_k]\r\n",
        "* x_i = [1, x_i1 , ... ,x_ik]\r\n",
        "  \r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbcSA9B144SO"
      },
      "source": [
        "於是我們的模型就變成：  \r\n",
        "[常數項，朋友數量，每天工作時數，有博士學位與否]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWyI25qhGPfT"
      },
      "source": [
        "from typing import List\r\n",
        "\r\n",
        "Vector = List[float]\r\n",
        "\r\n",
        "def dot(v:Vector,w:Vector)->float:\r\n",
        "  #計算v_1*w_1+... +v_n*w_n\r\n",
        "  assert len(v)==len(w),\"兩個向量必須有相同的維度\"\r\n",
        "\r\n",
        "  return sum(v_i*w_i for v_i,w_i in zip(v,w))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNNg__Pb22e6"
      },
      "source": [
        "def predict (x:Vector,beta:Vector) -> float:\r\n",
        "  \"\"\"假設每個x_i的第一個元素都是1\"\"\"\r\n",
        "  return dot(x,beta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJKIM0Em41Wg"
      },
      "source": [
        "# 關於最小平方模型的進一步假設\r\n",
        "\r\n",
        "1. x的每個元素必須是**線性獨立**的：每個元素皆無法透過其他元素加總來得到。  \r\n",
        "若該假設不成立，則無法得估計出β。\r\n",
        "2. x中的每個元素全都與誤差項ε無關。  \r\n",
        "若該假設不成立，估計β時會發生系統性錯誤。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al8PDSh2TUDB"
      },
      "source": [
        "# 套入模型\r\n",
        "目標：找到某組beta係數值，讓誤差平方得到最小化的結果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1D9nRdYZKTv"
      },
      "source": [
        "## 誤差函數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLzkbC9BZHzS"
      },
      "source": [
        "from typing import List\r\n",
        "\r\n",
        "def error(x:Vector,y:float,beta:Vector) -> float:\r\n",
        "  return predict(x,beta) - y\r\n",
        "\r\n",
        "def squared_error(x:Vector,y:float,beta:Vector) -> float:\r\n",
        "  return error(x,y,beta)**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPpdzyC4ZtaE"
      },
      "source": [
        "進行測試"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU2MSl4TZu9c"
      },
      "source": [
        "x = [1,2,3]\r\n",
        "y = 30\r\n",
        "beta = [4,4,4] #預測值為 4+8+12 = 24\r\n",
        "\r\n",
        "assert error(x,y,beta) == -6\r\n",
        "assert squared_error(x,y,beta) == 36"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRputwVZacNC"
      },
      "source": [
        "## 計算梯度\r\n",
        "透過微積分"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_VfwsL2agIs"
      },
      "source": [
        "def squerror_gradient(x:Vector,y:float,beta:Vector) -> float:\r\n",
        "  err = error(x,y,beta)\r\n",
        "  return [2*err*x_i for x_i in x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_EinJUravgW"
      },
      "source": [
        "assert squerror_gradient(x,y,beta) == [-12,-24,-36]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDhZKsPma7mg"
      },
      "source": [
        "## 1. 梯度遞減 (書本上作法)\r\n",
        "用來找出最佳的beta值"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwKZkd4ibDMN"
      },
      "source": [
        "import random\r\n",
        "import tqdm\r\n",
        "\r\n",
        "from typing import List\r\n",
        "\r\n",
        "Vector = List[float]\r\n",
        "\r\n",
        "def add( v:Vector, w:Vector) -> Vector:\r\n",
        "  assert len(v) == len(w) ,\"兩個向量必須有相同的維度\"\r\n",
        "\r\n",
        "  return [ v_i+w_i for v_i,w_i in zip(v,w)]\r\n",
        "\r\n",
        "def vector_sum(vectors:List[Vector]) -> Vector:\r\n",
        "  #先檢查vertors這個向量列表是否為空\r\n",
        "  assert vectors,\"列表中沒有向量!\"\r\n",
        "\r\n",
        "  #檢查vertors 向量列表內的所有向量都具有相同的維度\r\n",
        "  num_elements=len(vectors[0])\r\n",
        "  assert all(len(v)==num_elements for v in vectors),\"向量維度不一致\"\r\n",
        "\r\n",
        "  #所有vectors[i]相加起來，是結果的第i個元素值\r\n",
        "  return [sum(vector[i] for vector in vectors) for i in range(num_elements)]\r\n",
        "\r\n",
        "\r\n",
        "def scalar_multiply(c:float,v:Vector) -> Vector:\r\n",
        "  return [c*v_i for v_i in v]\r\n",
        "\r\n",
        "def vector_mean(vectors:List[Vector])->Vector:\r\n",
        "  n=len(vectors)\r\n",
        "  return scalar_multiply(1/n,vector_sum(vectors))\r\n",
        "\r\n",
        "def gradient_step(v:Vector,gradient:Vector,step_size:float) -> Vector:\r\n",
        "  \"\"\"從v沿著gradient的方向移動step_size的距離\"\"\"\r\n",
        "  assert len(v) == len(gradient)\r\n",
        "  step = scalar_multiply(step_size,gradient)\r\n",
        "  return add(v,step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsYVww-Mbqqi"
      },
      "source": [
        "def least_squares_fit(\r\n",
        "          xs:List[Vector],\r\n",
        "          ys:List[float],\r\n",
        "          learning_rate:float=0.001,\r\n",
        "          num_steps:int=1000,\r\n",
        "          batch_size:int=1)->Vector:\r\n",
        "  \"\"\"\r\n",
        "  找出最小化平方誤差和的beta值\r\n",
        "  假設模型y = dot(x,beta)\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  # 一開始先使隨機方式做出猜測\r\n",
        "  guess = [random.random() for _ in xs[0]]\r\n",
        "\r\n",
        "  for _ in tqdm.trange(num_steps,desc=\"least squares fit\"):\r\n",
        "    for start in range(0,len(xs),batch_size):\r\n",
        "      batch_xs = xs[start:start+batch_size]\r\n",
        "      batch_ys = ys[start:start+batch_size]\r\n",
        "\r\n",
        "      gradient = vector_mean([squerror_gradient(x,y,guess) for x,y in zip(batch_xs,batch_ys)])\r\n",
        "\r\n",
        "      guess = gradient_step(guess,gradient,-learning_rate)\r\n",
        "  \r\n",
        "  return guess"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFV80klNcDr2"
      },
      "source": [
        "## 套用到資料中"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvDMx2NhjB2K"
      },
      "source": [
        "inputs = [[1,49,4,0],[1,41,9,0],[1,40,8,0],[1,25,6,0],[1,21,1,0],[1,21,0,0],[1,19,3,0],[1,19,0,0],[1,18,9,0],[1,18,8,0],[1,16,4,0],[1,15,3,0],[1,15,0,0],[1,15,2,0],[1,15,7,0],[1,14,0,0],[1,14,1,0],[1,13,1,0],[1,13,7,0],[1,13,4,0],[1,13,2,0],[1,12,5,0],[1,12,0,0],[1,11,9,0],[1,10,9,0],[1,10,1,0],[1,10,1,0],[1,10,7,0],[1,10,9,0],[1,10,1,0],[1,10,6,0],[1,10,6,0],[1,10,8,0],[1,10,10,0],[1,10,6,0],[1,10,0,0],[1,10,5,0],[1,10,3,0],[1,10,4,0],[1,9,9,0],[1,9,9,0],[1,9,0,0],[1,9,0,0],[1,9,6,0],[1,9,10,0],[1,9,8,0],[1,9,5,0],[1,9,2,0],[1,9,9,0],[1,9,10,0],[1,9,7,0],[1,9,2,0],[1,9,0,0],[1,9,4,0],[1,9,6,0],[1,9,4,0],[1,9,7,0],[1,8,3,0],[1,8,2,0],[1,8,4,0],[1,8,9,0],[1,8,2,0],[1,8,3,0],[1,8,5,0],[1,8,8,0],[1,8,0,0],[1,8,9,0],[1,8,10,0],[1,8,5,0],[1,8,5,0],[1,7,5,0],[1,7,5,0],[1,7,0,0],[1,7,2,0],[1,7,8,0],[1,7,10,0],[1,7,5,0],[1,7,3,0],[1,7,3,0],[1,7,6,0],[1,7,7,0],[1,7,7,0],[1,7,9,0],[1,7,3,0],[1,7,8,0],[1,6,4,0],[1,6,6,0],[1,6,4,0],[1,6,9,0],[1,6,0,0],[1,6,1,0],[1,6,4,0],[1,6,1,0],[1,6,0,0],[1,6,7,0],[1,6,0,0],[1,6,8,0],[1,6,4,0],[1,6,2,1],[1,6,1,1],[1,6,3,1],[1,6,6,1],[1,6,4,1],[1,6,4,1],[1,6,1,1],[1,6,3,1],[1,6,4,1],[1,5,1,1],[1,5,9,1],[1,5,4,1],[1,5,6,1],[1,5,4,1],[1,5,4,1],[1,5,10,1],[1,5,5,1],[1,5,2,1],[1,5,4,1],[1,5,4,1],[1,5,9,1],[1,5,3,1],[1,5,10,1],[1,5,2,1],[1,5,2,1],[1,5,9,1],[1,4,8,1],[1,4,6,1],[1,4,0,1],[1,4,10,1],[1,4,5,1],[1,4,10,1],[1,4,9,1],[1,4,1,1],[1,4,4,1],[1,4,4,1],[1,4,0,1],[1,4,3,1],[1,4,1,1],[1,4,3,1],[1,4,2,1],[1,4,4,1],[1,4,4,1],[1,4,8,1],[1,4,2,1],[1,4,4,1],[1,3,2,1],[1,3,6,1],[1,3,4,1],[1,3,7,1],[1,3,4,1],[1,3,1,1],[1,3,10,1],[1,3,3,1],[1,3,4,1],[1,3,7,1],[1,3,5,1],[1,3,6,1],[1,3,1,1],[1,3,6,1],[1,3,10,1],[1,3,2,1],[1,3,4,1],[1,3,2,1],[1,3,1,1],[1,3,5,1],[1,2,4,1],[1,2,2,1],[1,2,8,1],[1,2,3,1],[1,2,1,1],[1,2,9,1],[1,2,10,1],[1,2,9,1],[1,2,4,1],[1,2,5,1],[1,2,0,1],[1,2,9,1],[1,2,9,1],[1,2,0,1],[1,2,1,1],[1,2,1,1],[1,2,4,1],[1,1,0,1],[1,1,2,1],[1,1,2,1],[1,1,5,1],[1,1,3,1],[1,1,10,1],[1,1,6,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,4,1],[1,1,9,1],[1,1,9,1],[1,1,4,1],[1,1,2,1],[1,1,9,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,1,1],[1,1,1,1],[1,1,5,1]]\r\n",
        "daily_minutes_good = [68.77,51.25,52.08,38.36,44.54,57.13,51.4,41.42,31.22,34.76,54.01,38.79,47.59,49.1,27.66,41.03,36.73,48.65,28.12,46.62,35.57,32.98,35,26.07,23.77,39.73,40.57,31.65,31.21,36.32,20.45,21.93,26.02,27.34,23.49,46.94,30.5,33.8,24.23,21.4,27.94,32.24,40.57,25.07,19.42,22.39,18.42,46.96,23.72,26.41,26.97,36.76,40.32,35.02,29.47,30.2,31,38.11,38.18,36.31,21.03,30.86,36.07,28.66,29.08,37.28,15.28,24.17,22.31,30.17,25.53,19.85,35.37,44.6,17.23,13.47,26.33,35.02,32.09,24.81,19.33,28.77,24.26,31.98,25.73,24.86,16.28,34.51,15.23,39.72,40.8,26.06,35.76,34.76,16.13,44.04,18.03,19.65,32.62,35.59,39.43,14.18,35.24,40.13,41.82,35.45,36.07,43.67,24.61,20.9,21.9,18.79,27.61,27.21,26.61,29.77,20.59,27.53,13.82,33.2,25,33.1,36.65,18.63,14.87,22.2,36.81,25.53,24.62,26.25,18.21,28.08,19.42,29.79,32.8,35.99,28.32,27.79,35.88,29.06,36.28,14.1,36.63,37.49,26.9,18.58,38.48,24.48,18.95,33.55,14.24,29.04,32.51,25.63,22.22,19,32.73,15.16,13.9,27.2,32.01,29.27,33,13.74,20.42,27.32,18.23,35.35,28.48,9.08,24.62,20.12,35.26,19.92,31.02,16.49,12.16,30.7,31.22,34.65,13.13,27.51,33.2,31.57,14.1,33.42,17.44,10.12,24.42,9.82,23.39,30.93,15.03,21.67,31.09,33.29,22.61,26.89,23.48,8.38,27.81,32.35,23.84]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKW6Eom7jaTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d2309b-63c2-45d9-f1b3-131c36ed92fe"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "random.seed(0)\r\n",
        "\r\n",
        "# 嘗試使用錯誤的方式選擇num_iters和step_size\r\n",
        "# 這會需要花一點時間\r\n",
        "learning_rate = 0.001\r\n",
        "\r\n",
        "beta = least_squares_fit(inputs,daily_minutes_good,learning_rate ,5000,25)\r\n",
        "\r\n",
        "assert 30.50 < beta[0] < 30.70 #常數\r\n",
        "assert 0.96 < beta[1] < 1.00 #朋友的數量\r\n",
        "assert -1.89 < beta[2] < -1.85 #每天的工作時數\r\n",
        "assert 0.91 < beta[3] < 0.94 #有博士學問的話\r\n",
        "\r\n",
        "np.round(np.array(beta),3)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1707.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([30.515,  0.975, -1.851,  0.914])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnNaVNNxl5H-"
      },
      "source": [
        "在實務上不會使用梯度遞減的方式來計算線性回歸的方法，  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AnxvHxZoh2M"
      },
      "source": [
        "## ✪ [線性代數投影求解](https://ithelp.ithome.com.tw/articles/10186400) (網路資源)\r\n",
        "![公式解](http://i.imgur.com/EngTecm.png)  \r\n",
        "利用numpy函式庫來協助運算\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBevWa5RpsRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad0fecf-b9ee-4b05-ee3e-1e3490a3ea7d"
      },
      "source": [
        "import numpy as np\r\n",
        "x = np.array(inputs)\r\n",
        "y = np.array(daily_minutes_good)\r\n",
        "\r\n",
        "# A = (X^T*X)⁻¹\r\n",
        "transpose_x = np.transpose(x)\r\n",
        "temp = transpose_x @ x\r\n",
        "A = np.linalg.inv(temp)\r\n",
        "\r\n",
        "# D = X^T * y\r\n",
        "D = transpose_x @ y\r\n",
        "\r\n",
        "# β = A*D = 最終解 = (X^T*X)⁻¹ * X^T * y\r\n",
        "β = A @ D\r\n",
        "np.round(β,3) #將最終的解,取小數點後三位"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([30.579,  0.973, -1.865,  0.923])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNfi1bwFmJ2Q"
      },
      "source": [
        "## 運算後，得到的方程式是：\r\n",
        "```\r\n",
        "minutes = 30.579 + 0.973 friends - 1.865 woek hours + 0.923 phd\r\n",
        "```\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ink6Oiven5Ec"
      },
      "source": [
        "# 解釋模型\r\n",
        "　　\r\n",
        "**所有其他因素皆相等的情況下**：\r\n",
        "* 每額外增加一個朋友，每天花在網站上的時間就會增加將近1分鐘。\r\n",
        "* 使用者的工作時間美額外增加１小時，每天花在網站上的時間就會減少將近２分鐘。\r\n",
        "* 每個擁有博士學位的使用者，每天都會在網站上多待近1分鐘。\r\n",
        "  \r\n",
        "這些變數彼此間的交互關係，對於朋友多或少的人來說工作時數的影響**可能是不相同**的。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfGmM79on74k"
      },
      "source": [
        "# 套入優度\r\n",
        "利用**R平方**的值來觀察："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DQ-dhSud4De"
      },
      "source": [
        "def mean(xs:List[float]) -> float:\r\n",
        "  return sum(xs) / len(xs)\r\n",
        "\r\n",
        "def de_mean(xs:List[float]) -> List[float]:\r\n",
        "  x_bar = mean(xs)\r\n",
        "  return [x - x_bar for x in xs] \r\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK3tAH8Pd8iM"
      },
      "source": [
        "def error(x , y , beta):\r\n",
        "    return y - predict(x,beta)\r\n",
        "\r\n",
        "def sum_of_sqerrors(x , y , beta):\r\n",
        "    return sum( error(x_i , y_i , beta) ** 2\r\n",
        "               for x_i, y_i in zip(x, y))\r\n",
        "\r\n",
        "def total_sum_squares(y:Vector) ->float:\r\n",
        "  \"\"\"每個y_i與平均值之間的差值的總平方和，即「總變異量」\"\"\"\r\n",
        "  return sum(v**2 for v in de_mean(y))\r\n",
        "\r\n",
        "def mulity_r_squares(xs:List[float],ys:Vector,beta:Vector) ->float:\r\n",
        "  \"\"\"\r\n",
        "  模型掌握到y變異量的比率，即(1-模型未掌握到y變異量的比率)\r\n",
        "  \"\"\"\r\n",
        "  sum_of_squared_errors = sum(error(x,y,beta)**2 for x , y in zip(xs,ys))\r\n",
        "  return 1.0 - (sum_of_squared_errors/total_sum_squares(ys))\r\n",
        "\r\n",
        "def total_sum_of_squares(y):\r\n",
        "    \"\"\"the total squared variation of y_i's from their mean\"\"\"\r\n",
        "    return sum(v ** 2 for v in de_mean(y))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuaKmGXHe49Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0b5daf0-b434-43df-a9bf-2684508492ef"
      },
      "source": [
        "rsq= mulity_r_squares(inputs,daily_minutes_good,beta)\r\n",
        "assert 0.67 < rsq < 0.68\r\n",
        "print(\"%.3f\"%rsq)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRCQyN-loMUD"
      },
      "source": [
        "在多元迴歸模型中，還要觀察各個係數的標準差，以衡量所得到每個βi估計值。  \r\n",
        "  \r\n",
        "**衡量誤差的假設**：\r\n",
        "誤差項εi是一個平均值為0，標準差σ的**獨立常態隨機變數**。  \r\n",
        "模型中係數的標準差越大，該係數的可靠程度就越低。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtmhRYwBn_UE"
      },
      "source": [
        "## Bootstrap (重複取樣)\r\n",
        "假設我們有一組其中包含N個資料的樣本，是根據某種未知的分布所生成的：\r\n",
        "\r\n",
        "```\r\n",
        "data = get_sample(num_points = n\r\n",
        "```\r\n",
        "如果重複取得多組的樣本組，我們可以計算出許多樣本組的中位數，進而觀察這些中位數的分布情況。  \r\n",
        "這種情況下，可以「重複採樣(bootstrap)」從原本的資料集內，\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z01CCQBRoEcq"
      },
      "source": [
        "# 迴歸係數的標準差"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQMIAbpLoLOA"
      },
      "source": [
        "# 正則化"
      ]
    }
  ]
}