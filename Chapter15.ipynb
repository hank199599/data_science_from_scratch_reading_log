{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter15.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPjwpQiFJZsaHO4pHxoqsfJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hank199599/data_science_from_scratch_reading_log/blob/main/Chapter15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqsbSWxNnH9F"
      },
      "source": [
        "# 模型\r\n",
        "假設每個輸入項xi不再只是單一數值，而是一個由xil,...,xik所組成的向量k。  \r\n",
        "多元遞歸模型架設如下：\r\n",
        "\r\n",
        "\r\n",
        "```\r\n",
        "yi = α+β₁χɪʟ+...+βkχɪʟ\r\n",
        "```\r\n",
        "在多元迴歸模型中，參數向量通常以β來表示。  \r\n",
        "若把常數項也包含進來，只需多加一個欄位。\r\n",
        "* beta = [alpha, beta_1 , ... ,beta_k]\r\n",
        "* x_i = [1, x_i1 , ... ,x_ik]\r\n",
        "  \r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbcSA9B144SO"
      },
      "source": [
        "於是我們的模型就變成：  \r\n",
        "[常數項，朋友數量，每天工作時數，有博士學位與否]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWyI25qhGPfT"
      },
      "source": [
        "from typing import List\r\n",
        "\r\n",
        "Vector = List[float]\r\n",
        "\r\n",
        "def dot(v:Vector,w:Vector)->float:\r\n",
        "  #計算v_1*w_1+... +v_n*w_n\r\n",
        "  assert len(v)==len(w),\"兩個向量必須有相同的維度\"\r\n",
        "\r\n",
        "  return sum(v_i*w_i for v_i,w_i in zip(v,w))"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNNg__Pb22e6"
      },
      "source": [
        "def predict (x:Vector,beta:Vector) -> float:\r\n",
        "  \"\"\"假設每個x_i的第一個元素都是1\"\"\"\r\n",
        "  return dot(x,beta)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJKIM0Em41Wg"
      },
      "source": [
        "# 關於最小平方模型的進一步假設\r\n",
        "\r\n",
        "1. x的每個元素必須是**線性獨立**的：每個元素皆無法透過其他元素加總來得到。  \r\n",
        "若該假設不成立，則無法得估計出β。\r\n",
        "2. x中的每個元素全都與誤差項ε無關。  \r\n",
        "若該假設不成立，估計β時會發生系統性錯誤。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al8PDSh2TUDB"
      },
      "source": [
        "# 套入模型\r\n",
        "目標：找到某組beta係數值，讓誤差平方得到最小化的結果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1D9nRdYZKTv"
      },
      "source": [
        "## 誤差函數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLzkbC9BZHzS"
      },
      "source": [
        "from typing import List\r\n",
        "\r\n",
        "def error(x:Vector,y:float,beta:Vector) -> float:\r\n",
        "  return predict(x,beta) - y\r\n",
        "\r\n",
        "def squared_error(x:Vector,y:float,beta:Vector) -> float:\r\n",
        "  return error(x,y,beta)**2"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPpdzyC4ZtaE"
      },
      "source": [
        "進行測試"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU2MSl4TZu9c"
      },
      "source": [
        "x = [1,2,3]\r\n",
        "y = 30\r\n",
        "beta = [4,4,4] #預測值為 4+8+12 = 24\r\n",
        "\r\n",
        "assert error(x,y,beta) == -6\r\n",
        "assert squared_error(x,y,beta) == 36"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRputwVZacNC"
      },
      "source": [
        "## 計算梯度\r\n",
        "透過微積分"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_VfwsL2agIs"
      },
      "source": [
        "def squerror_gradient(x:Vector,y:float,beta:Vector) -> float:\r\n",
        "  err = error(x,y,beta)\r\n",
        "  return [2*err*x_i for x_i in x]"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_EinJUravgW"
      },
      "source": [
        "assert squerror_gradient(x,y,beta) == [-12,-24,-36]"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDhZKsPma7mg"
      },
      "source": [
        "## 1. 梯度遞減 (書本上作法)\r\n",
        "用來找出最佳的beta值"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwKZkd4ibDMN"
      },
      "source": [
        "import random\r\n",
        "import tqdm\r\n",
        "\r\n",
        "from typing import List\r\n",
        "\r\n",
        "Vector = List[float]\r\n",
        "\r\n",
        "def add( v:Vector, w:Vector) -> Vector:\r\n",
        "  assert len(v) == len(w) ,\"兩個向量必須有相同的維度\"\r\n",
        "\r\n",
        "  return [ v_i+w_i for v_i,w_i in zip(v,w)]\r\n",
        "\r\n",
        "def vector_sum(vectors:List[Vector]) -> Vector:\r\n",
        "  #先檢查vertors這個向量列表是否為空\r\n",
        "  assert vectors,\"列表中沒有向量!\"\r\n",
        "\r\n",
        "  #檢查vertors 向量列表內的所有向量都具有相同的維度\r\n",
        "  num_elements=len(vectors[0])\r\n",
        "  assert all(len(v)==num_elements for v in vectors),\"向量維度不一致\"\r\n",
        "\r\n",
        "  #所有vectors[i]相加起來，是結果的第i個元素值\r\n",
        "  return [sum(vector[i] for vector in vectors) for i in range(num_elements)]\r\n",
        "\r\n",
        "\r\n",
        "def scalar_multiply(c:float,v:Vector) -> Vector:\r\n",
        "  return [c*v_i for v_i in v]\r\n",
        "\r\n",
        "def vector_mean(vectors:List[Vector])->Vector:\r\n",
        "  n=len(vectors)\r\n",
        "  return scalar_multiply(1/n,vector_sum(vectors))\r\n",
        "\r\n",
        "def gradient_step(v:Vector,gradient:Vector,step_size:float) -> Vector:\r\n",
        "  \"\"\"從v沿著gradient的方向移動step_size的距離\"\"\"\r\n",
        "  assert len(v) == len(gradient)\r\n",
        "  step = scalar_multiply(step_size,gradient)\r\n",
        "  return add(v,step)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsYVww-Mbqqi"
      },
      "source": [
        "def least_squares_fit(\r\n",
        "          xs:List[Vector],\r\n",
        "          ys:List[float],\r\n",
        "          learning_rate:float=0.001,\r\n",
        "          num_steps:int=1000,\r\n",
        "          batch_size:int=1)->Vector:\r\n",
        "  \"\"\"\r\n",
        "  找出最小化平方誤差和的beta值\r\n",
        "  假設模型y = dot(x,beta)\r\n",
        "  \"\"\"\r\n",
        "  # 一開始先使隨機方式做出猜測\r\n",
        "  guess = [random.random() for _ in xs[0]]\r\n",
        "\r\n",
        "  for _ in tqdm.trange(num_steps,desc=\"least squares fit\"):\r\n",
        "    for start in range(0,len(xs),batch_size):\r\n",
        "      batch_xs = xs[start:start+batch_size]\r\n",
        "      batch_ys = ys[start:start+batch_size]\r\n",
        "\r\n",
        "      gradient = vector_mean([squerror_gradient(x,y,guess) for x,y in zip(batch_xs,batch_ys)])\r\n",
        "\r\n",
        "      guess = gradient_step(guess,gradient,-learning_rate)\r\n",
        "  \r\n",
        "  return guess"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFV80klNcDr2"
      },
      "source": [
        "## 套用到資料中"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvDMx2NhjB2K"
      },
      "source": [
        "inputs = [[1,49,4,0],[1,41,9,0],[1,40,8,0],[1,25,6,0],[1,21,1,0],[1,21,0,0],[1,19,3,0],[1,19,0,0],[1,18,9,0],[1,18,8,0],[1,16,4,0],[1,15,3,0],[1,15,0,0],[1,15,2,0],[1,15,7,0],[1,14,0,0],[1,14,1,0],[1,13,1,0],[1,13,7,0],[1,13,4,0],[1,13,2,0],[1,12,5,0],[1,12,0,0],[1,11,9,0],[1,10,9,0],[1,10,1,0],[1,10,1,0],[1,10,7,0],[1,10,9,0],[1,10,1,0],[1,10,6,0],[1,10,6,0],[1,10,8,0],[1,10,10,0],[1,10,6,0],[1,10,0,0],[1,10,5,0],[1,10,3,0],[1,10,4,0],[1,9,9,0],[1,9,9,0],[1,9,0,0],[1,9,0,0],[1,9,6,0],[1,9,10,0],[1,9,8,0],[1,9,5,0],[1,9,2,0],[1,9,9,0],[1,9,10,0],[1,9,7,0],[1,9,2,0],[1,9,0,0],[1,9,4,0],[1,9,6,0],[1,9,4,0],[1,9,7,0],[1,8,3,0],[1,8,2,0],[1,8,4,0],[1,8,9,0],[1,8,2,0],[1,8,3,0],[1,8,5,0],[1,8,8,0],[1,8,0,0],[1,8,9,0],[1,8,10,0],[1,8,5,0],[1,8,5,0],[1,7,5,0],[1,7,5,0],[1,7,0,0],[1,7,2,0],[1,7,8,0],[1,7,10,0],[1,7,5,0],[1,7,3,0],[1,7,3,0],[1,7,6,0],[1,7,7,0],[1,7,7,0],[1,7,9,0],[1,7,3,0],[1,7,8,0],[1,6,4,0],[1,6,6,0],[1,6,4,0],[1,6,9,0],[1,6,0,0],[1,6,1,0],[1,6,4,0],[1,6,1,0],[1,6,0,0],[1,6,7,0],[1,6,0,0],[1,6,8,0],[1,6,4,0],[1,6,2,1],[1,6,1,1],[1,6,3,1],[1,6,6,1],[1,6,4,1],[1,6,4,1],[1,6,1,1],[1,6,3,1],[1,6,4,1],[1,5,1,1],[1,5,9,1],[1,5,4,1],[1,5,6,1],[1,5,4,1],[1,5,4,1],[1,5,10,1],[1,5,5,1],[1,5,2,1],[1,5,4,1],[1,5,4,1],[1,5,9,1],[1,5,3,1],[1,5,10,1],[1,5,2,1],[1,5,2,1],[1,5,9,1],[1,4,8,1],[1,4,6,1],[1,4,0,1],[1,4,10,1],[1,4,5,1],[1,4,10,1],[1,4,9,1],[1,4,1,1],[1,4,4,1],[1,4,4,1],[1,4,0,1],[1,4,3,1],[1,4,1,1],[1,4,3,1],[1,4,2,1],[1,4,4,1],[1,4,4,1],[1,4,8,1],[1,4,2,1],[1,4,4,1],[1,3,2,1],[1,3,6,1],[1,3,4,1],[1,3,7,1],[1,3,4,1],[1,3,1,1],[1,3,10,1],[1,3,3,1],[1,3,4,1],[1,3,7,1],[1,3,5,1],[1,3,6,1],[1,3,1,1],[1,3,6,1],[1,3,10,1],[1,3,2,1],[1,3,4,1],[1,3,2,1],[1,3,1,1],[1,3,5,1],[1,2,4,1],[1,2,2,1],[1,2,8,1],[1,2,3,1],[1,2,1,1],[1,2,9,1],[1,2,10,1],[1,2,9,1],[1,2,4,1],[1,2,5,1],[1,2,0,1],[1,2,9,1],[1,2,9,1],[1,2,0,1],[1,2,1,1],[1,2,1,1],[1,2,4,1],[1,1,0,1],[1,1,2,1],[1,1,2,1],[1,1,5,1],[1,1,3,1],[1,1,10,1],[1,1,6,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,4,1],[1,1,9,1],[1,1,9,1],[1,1,4,1],[1,1,2,1],[1,1,9,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,1,1],[1,1,1,1],[1,1,5,1]]\r\n",
        "daily_minutes_good = [68.77,51.25,52.08,38.36,44.54,57.13,51.4,41.42,31.22,34.76,54.01,38.79,47.59,49.1,27.66,41.03,36.73,48.65,28.12,46.62,35.57,32.98,35,26.07,23.77,39.73,40.57,31.65,31.21,36.32,20.45,21.93,26.02,27.34,23.49,46.94,30.5,33.8,24.23,21.4,27.94,32.24,40.57,25.07,19.42,22.39,18.42,46.96,23.72,26.41,26.97,36.76,40.32,35.02,29.47,30.2,31,38.11,38.18,36.31,21.03,30.86,36.07,28.66,29.08,37.28,15.28,24.17,22.31,30.17,25.53,19.85,35.37,44.6,17.23,13.47,26.33,35.02,32.09,24.81,19.33,28.77,24.26,31.98,25.73,24.86,16.28,34.51,15.23,39.72,40.8,26.06,35.76,34.76,16.13,44.04,18.03,19.65,32.62,35.59,39.43,14.18,35.24,40.13,41.82,35.45,36.07,43.67,24.61,20.9,21.9,18.79,27.61,27.21,26.61,29.77,20.59,27.53,13.82,33.2,25,33.1,36.65,18.63,14.87,22.2,36.81,25.53,24.62,26.25,18.21,28.08,19.42,29.79,32.8,35.99,28.32,27.79,35.88,29.06,36.28,14.1,36.63,37.49,26.9,18.58,38.48,24.48,18.95,33.55,14.24,29.04,32.51,25.63,22.22,19,32.73,15.16,13.9,27.2,32.01,29.27,33,13.74,20.42,27.32,18.23,35.35,28.48,9.08,24.62,20.12,35.26,19.92,31.02,16.49,12.16,30.7,31.22,34.65,13.13,27.51,33.2,31.57,14.1,33.42,17.44,10.12,24.42,9.82,23.39,30.93,15.03,21.67,31.09,33.29,22.61,26.89,23.48,8.38,27.81,32.35,23.84]"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKW6Eom7jaTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88629bc8-6553-4dd4-8c4c-9de724ba18f8"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "random.seed(0)\r\n",
        "\r\n",
        "# 嘗試使用錯誤的方式選擇num_iters和step_size\r\n",
        "# 這會需要花一點時間\r\n",
        "learning_rate = 0.001\r\n",
        "\r\n",
        "beta = least_squares_fit(inputs,daily_minutes_good,learning_rate ,5000,25)\r\n",
        "\r\n",
        "assert 30.50 < beta[0] < 30.70 #常數\r\n",
        "assert 0.96 < beta[1] < 1.00 #朋友的數量\r\n",
        "assert -1.89 < beta[2] < -1.85 #每天的工作時數\r\n",
        "assert 0.91 < beta[3] < 0.94 #有博士學問的話\r\n",
        "\r\n",
        "np.round(np.array(beta),3)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1781.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([30.515,  0.975, -1.851,  0.914])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnNaVNNxl5H-"
      },
      "source": [
        "在實務上不會使用梯度遞減的方式來計算線性回歸的方法，  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AnxvHxZoh2M"
      },
      "source": [
        "## ✪ [線性代數求解：最小平方近似](https://ithelp.ithome.com.tw/articles/10186400) (網路資源)\r\n",
        "![公式解](http://i.imgur.com/EngTecm.png)  \r\n",
        "利用numpy函式庫來協助運算\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBevWa5RpsRF"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "def least_square_approximation(vector_x,vector_y):\r\n",
        "  x = np.array(vector_x)\r\n",
        "  y = np.array(vector_y)\r\n",
        "\r\n",
        "  # A = (X^T*X)⁻¹\r\n",
        "  transpose_x = np.transpose(x)\r\n",
        "  temp = transpose_x @ x\r\n",
        "  A = np.linalg.inv(temp)\r\n",
        "\r\n",
        "  # D = X^T * y\r\n",
        "  D = transpose_x @ y\r\n",
        "\r\n",
        "  # β = A*D = 最終解 = (X^T*X)⁻¹ * X^T * y\r\n",
        "  β = A @ D\r\n",
        "  return list(np.round(β,3)) #將最終的解,取小數點後三位"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2_Pf7mjt9Vq",
        "outputId": "a2c18d9d-7be0-4250-dfed-f2ad396cce37"
      },
      "source": [
        "least_square_approximation(inputs,daily_minutes_good)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[30.579, 0.973, -1.865, 0.923]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNfi1bwFmJ2Q"
      },
      "source": [
        "## 運算後，得到的方程式是：\r\n",
        "```\r\n",
        "minutes = 30.579 + 0.973 friends - 1.865 woek hours + 0.923 phd\r\n",
        "```\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ink6Oiven5Ec"
      },
      "source": [
        "# 解釋模型\r\n",
        "　　\r\n",
        "**所有其他因素皆相等的情況下**：\r\n",
        "* 每額外增加一個朋友，每天花在網站上的時間就會增加將近1分鐘。\r\n",
        "* 使用者的工作時間美額外增加１小時，每天花在網站上的時間就會減少將近２分鐘。\r\n",
        "* 每個擁有博士學位的使用者，每天都會在網站上多待近1分鐘。\r\n",
        "  \r\n",
        "這些變數彼此間的交互關係，對於朋友多或少的人來說工作時數的影響**可能是不相同**的。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfGmM79on74k"
      },
      "source": [
        "# 套入優度\r\n",
        "利用**R平方**的值來觀察："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DQ-dhSud4De"
      },
      "source": [
        "def mean(xs:List[float]) -> float:\r\n",
        "  return sum(xs) / len(xs)\r\n",
        "\r\n",
        "def de_mean(xs:List[float]) -> List[float]:\r\n",
        "  x_bar = mean(xs)\r\n",
        "  return [x - x_bar for x in xs] \r\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK3tAH8Pd8iM"
      },
      "source": [
        "def sum_of_sqerrors(x , y , beta):\r\n",
        "    return sum( error(x_i , y_i , beta) ** 2\r\n",
        "               for x_i, y_i in zip(x, y))\r\n",
        "\r\n",
        "def total_sum_squares(y:Vector) ->float:\r\n",
        "  \"\"\"每個y_i與平均值之間的差值的總平方和，即「總變異量」\"\"\"\r\n",
        "  return sum(v**2 for v in de_mean(y))\r\n",
        "\r\n",
        "def mulitiple_r_squared(xs:List[float],ys:Vector,beta:Vector) ->float:\r\n",
        "  \"\"\"\r\n",
        "  模型掌握到y變異量的比率，即(1-模型未掌握到y變異量的比率)\r\n",
        "  \"\"\"\r\n",
        "  sum_of_squared_errors = sum(error(x,y,beta)**2 for x , y in zip(xs,ys))\r\n",
        "  return 1.0 - (sum_of_squared_errors/total_sum_squares(ys))\r\n",
        "\r\n",
        "def total_sum_of_squares(y):\r\n",
        "    \"\"\"the total squared variation of y_i's from their mean\"\"\"\r\n",
        "    return sum(v ** 2 for v in de_mean(y))"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuaKmGXHe49Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72666b47-7cf9-4682-d77a-3709fd67e35e"
      },
      "source": [
        "rsq= mulitiple_r_squared(inputs,daily_minutes_good,beta)\r\n",
        "assert 0.67 < rsq < 0.68\r\n",
        "print(\"%.3f\"%rsq)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRCQyN-loMUD"
      },
      "source": [
        "在多元迴歸模型中，還要觀察各個係數的標準差，以衡量所得到每個βi估計值。  \r\n",
        "  \r\n",
        "**衡量誤差的假設**：\r\n",
        "誤差項εi是一個平均值為0，標準差σ的**獨立常態隨機變數**。  \r\n",
        "模型中係數的標準差越大，該係數的可靠程度就越低。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtmhRYwBn_UE"
      },
      "source": [
        "# Bootstrap (重複取樣)\r\n",
        "假設我們有一組其中包含N個資料的樣本，是根據某種未知的分布所生成的：\r\n",
        "\r\n",
        "```\r\n",
        "data = get_sample(num_points = n\r\n",
        "```\r\n",
        "如果重複取得多組的樣本組，我們可以計算出許多樣本組的中位數，進而觀察這些中位數的分布情況。  \r\n",
        "這種情況下，可以「重複採樣(bootstrap)」從原本的資料集內，重新選出n個資料重新組合成新的資料集以取代原本的。\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i-eDbJgGaGM"
      },
      "source": [
        "from typing import TypeVar , Callable\r\n",
        "\r\n",
        "X = TypeVar('X')\r\n",
        "Stat = TypeVar('Stat')\r\n",
        "\r\n",
        "def bootstrap_sample(data:List[X]) -> List[X]:\r\n",
        "  \"\"\"以隨機的方式重複取樣 len(data)\"\"\"\r\n",
        "  return [random.choice(data) for _ in data]\r\n",
        "\r\n",
        "def bootstrap_statistic(data:List[X],stats_fn:Callable[[List[X]],Stat],num_samples:int) -> List[X]:\r\n",
        "  \"\"\" 從 data 取出 num_samples 個重複取樣的樣本，然後進行 states_fn 的計算 \"\"\"\r\n",
        "  return [stats_fn(bootstrap_sample(data)) for _ in range(num_samples)]\r\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVrQgueGLCqZ"
      },
      "source": [
        "考慮下列兩個資料集："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63X8zszILHpo"
      },
      "source": [
        "#101個資料集，其值全都非常接近100\r\n",
        "close_to_100 = [99.5 + random.random() for _ in range(101)]\r\n",
        "\r\n",
        "#101個資料集，其中50個值很接近0，另外50個值很接近200\r\n",
        "far_from_100 = ([99.5 + random.random()]+[random.random() for _ in range(50)]+[200 + random.random() for _ in range(50)])"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV32IdAF1eWa"
      },
      "source": [
        "計算這組資料集的中位數，結果都會相當靠近100。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQc85B9MtiQv"
      },
      "source": [
        "def sum_of_squares(v:Vector) -> float:\n",
        "  return dot(v,v)\n",
        "\n",
        "def _medium_odd(xs:List[float]) ->float:\n",
        "  return sorted(xs)[len(xs)//2]\n",
        "\n",
        "def _medium_even(xs:List[float]) ->float:\n",
        "  sorted_xs=sorted(xs)\n",
        "  hi_midpoint=len(xs)//2\n",
        "  return (sorted_xs[hi_midpoint-1]+sorted_xs[hi_midpoint])/2\n",
        "\n",
        "def median(v:List[float])->float:\n",
        "  return _medium_even(v) if len(v)%2 == 0 else _medium_odd(v)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmIfAn8C1ql_"
      },
      "source": [
        "import math\r\n",
        "\r\n",
        "def variance(xs:List[float]) ->float:\r\n",
        "  assert len(xs),\"至少有兩個元素才能計算變異數\"\r\n",
        "\r\n",
        "  n = len(xs)\r\n",
        "  deviations = de_mean(xs)\r\n",
        "  return sum_of_squares(deviations) / (n-1)\r\n",
        "\r\n",
        "def standard_deviation(xs:List[float]) ->float:\r\n",
        "  return math.sqrt(variance(xs))"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7MjlQ3A2Ucs"
      },
      "source": [
        "# 數值都很靠近100\r\n",
        "medians_close = bootstrap_statistic( close_to_100 , median ,100)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX87Ugn-3djl"
      },
      "source": [
        "# 數值很接近0，亦有都多很靠近200\r\n",
        "medians_far = bootstrap_statistic( far_from_100 , median ,100)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW6du56H2UAD"
      },
      "source": [
        "* 第一組資料中位數的標準差會很接近0\r\n",
        "* 第二組資料中位數的標準差會很接近100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU6cu5Pw6CaF"
      },
      "source": [
        "assert standard_deviation(medians_close) < 1\r\n",
        "assert standard_deviation(medians_far) > 90"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z01CCQBRoEcq"
      },
      "source": [
        "## 迴歸係數的標準差\r\n",
        "採用相同的方法，估算出迴歸係數的標準差。  \r\n",
        "針對相同資料集不斷進行重複取樣，就能估算出不同的beta值。  \r\n",
        "* 某自變數經多次取樣後仍沒太大變動 → 該係數的估計值應該十分可靠\r\n",
        "* 某自變數經多次取樣後的變化很大 → 該係數的估計值就不那麼可靠"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyNY4f197EP0"
      },
      "source": [
        "from typing import Tuple\r\n",
        "\r\n",
        "import datetime\r\n",
        "\r\n",
        "def estimate_sample_beta(pairs:List[Tuple[Vector,float]]):\r\n",
        "  learning_rate = 0.001\r\n",
        "  x_sample = [x for x , _ in pairs]\r\n",
        "  y_sample = [y for _ , y in pairs]\r\n",
        "  beta = least_square_approximation(x_sample,y_sample)\r\n",
        "  print(\"bootstrap sample\",beta)\r\n",
        "  return beta"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3hj4vYf7rq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8864c733-150e-4cde-faf1-0375318d70df"
      },
      "source": [
        "bootstrap_betas = bootstrap_statistic(list(zip(inputs,daily_minutes_good)),estimate_sample_beta,100)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bootstrap sample [30.045, 0.931, -1.912, 1.215]\n",
            "bootstrap sample [31.798, 1.003, -2.131, 1.901]\n",
            "bootstrap sample [29.218, 1.028, -1.752, 1.135]\n",
            "bootstrap sample [29.793, 0.969, -1.822, 2.099]\n",
            "bootstrap sample [30.641, 1.025, -1.955, 0.636]\n",
            "bootstrap sample [31.363, 0.909, -1.807, 0.241]\n",
            "bootstrap sample [29.767, 0.993, -1.826, 1.285]\n",
            "bootstrap sample [29.744, 0.967, -1.787, 0.979]\n",
            "bootstrap sample [29.842, 1.017, -1.986, 2.491]\n",
            "bootstrap sample [32.779, 0.876, -1.836, 0.529]\n",
            "bootstrap sample [29.886, 0.931, -1.737, 0.928]\n",
            "bootstrap sample [31.166, 1.037, -2.137, 1.354]\n",
            "bootstrap sample [30.897, 0.964, -1.845, -0.723]\n",
            "bootstrap sample [29.698, 1.0, -1.778, 2.444]\n",
            "bootstrap sample [30.359, 0.994, -1.946, 1.932]\n",
            "bootstrap sample [30.999, 1.035, -2.14, 1.119]\n",
            "bootstrap sample [29.922, 1.005, -1.836, 0.993]\n",
            "bootstrap sample [30.898, 0.888, -1.641, 0.847]\n",
            "bootstrap sample [31.189, 0.872, -1.631, 0.399]\n",
            "bootstrap sample [30.822, 0.91, -1.916, 0.973]\n",
            "bootstrap sample [29.61, 1.136, -1.768, 2.076]\n",
            "bootstrap sample [29.657, 1.058, -1.967, 2.396]\n",
            "bootstrap sample [31.445, 0.864, -1.782, -0.277]\n",
            "bootstrap sample [30.606, 0.951, -1.857, 0.054]\n",
            "bootstrap sample [28.203, 1.131, -1.877, 2.666]\n",
            "bootstrap sample [31.378, 1.016, -2.012, 0.373]\n",
            "bootstrap sample [31.757, 0.976, -2.073, 1.173]\n",
            "bootstrap sample [30.872, 0.908, -1.877, 1.093]\n",
            "bootstrap sample [26.987, 1.286, -1.847, 2.889]\n",
            "bootstrap sample [32.064, 1.049, -2.091, 1.026]\n",
            "bootstrap sample [29.222, 1.038, -1.853, 2.147]\n",
            "bootstrap sample [30.248, 1.043, -1.881, 1.564]\n",
            "bootstrap sample [30.651, 0.978, -1.8, 0.421]\n",
            "bootstrap sample [31.551, 0.98, -1.895, 0.769]\n",
            "bootstrap sample [30.144, 0.97, -1.914, 1.523]\n",
            "bootstrap sample [32.536, 0.907, -2.012, -0.812]\n",
            "bootstrap sample [30.744, 0.952, -1.928, 1.212]\n",
            "bootstrap sample [30.044, 1.015, -1.8, 1.306]\n",
            "bootstrap sample [29.291, 1.087, -1.755, 0.849]\n",
            "bootstrap sample [29.895, 0.995, -1.868, 3.068]\n",
            "bootstrap sample [30.725, 0.991, -1.765, 0.656]\n",
            "bootstrap sample [30.004, 0.977, -1.794, 0.674]\n",
            "bootstrap sample [31.145, 0.892, -1.882, 0.9]\n",
            "bootstrap sample [32.427, 0.909, -2.087, 0.115]\n",
            "bootstrap sample [31.803, 0.946, -2.01, 1.297]\n",
            "bootstrap sample [31.417, 0.924, -1.793, 0.162]\n",
            "bootstrap sample [30.669, 0.955, -1.804, 1.972]\n",
            "bootstrap sample [29.119, 0.983, -1.734, 2.285]\n",
            "bootstrap sample [30.65, 0.936, -1.875, 0.862]\n",
            "bootstrap sample [30.563, 1.079, -1.992, 1.192]\n",
            "bootstrap sample [29.784, 1.019, -1.77, 1.11]\n",
            "bootstrap sample [33.648, 0.885, -1.994, -0.937]\n",
            "bootstrap sample [32.135, 0.905, -2.003, 1.042]\n",
            "bootstrap sample [31.36, 0.924, -1.911, -0.959]\n",
            "bootstrap sample [26.956, 1.321, -1.891, 4.357]\n",
            "bootstrap sample [30.45, 0.955, -2.023, 1.905]\n",
            "bootstrap sample [30.825, 0.933, -1.805, 0.314]\n",
            "bootstrap sample [31.315, 0.942, -1.958, -0.175]\n",
            "bootstrap sample [29.544, 1.205, -2.119, 2.529]\n",
            "bootstrap sample [30.731, 0.867, -1.727, 0.378]\n",
            "bootstrap sample [30.004, 0.971, -1.846, 1.699]\n",
            "bootstrap sample [29.855, 0.983, -1.839, 1.447]\n",
            "bootstrap sample [31.533, 1.031, -2.062, 0.864]\n",
            "bootstrap sample [29.59, 1.084, -1.87, 1.345]\n",
            "bootstrap sample [28.925, 1.066, -1.79, 2.656]\n",
            "bootstrap sample [30.881, 0.976, -1.843, 1.09]\n",
            "bootstrap sample [30.095, 1.046, -1.756, 0.473]\n",
            "bootstrap sample [31.967, 0.863, -1.926, -0.696]\n",
            "bootstrap sample [29.196, 0.992, -1.669, 1.571]\n",
            "bootstrap sample [29.579, 1.022, -1.813, 1.645]\n",
            "bootstrap sample [30.215, 0.962, -1.793, 1.261]\n",
            "bootstrap sample [28.068, 1.163, -1.771, 1.642]\n",
            "bootstrap sample [33.303, 0.916, -2.105, -1.091]\n",
            "bootstrap sample [29.631, 1.034, -1.965, 0.862]\n",
            "bootstrap sample [30.848, 0.947, -1.891, -0.35]\n",
            "bootstrap sample [32.805, 0.866, -1.931, -0.801]\n",
            "bootstrap sample [29.326, 1.185, -1.924, 1.663]\n",
            "bootstrap sample [31.426, 0.96, -1.852, 0.891]\n",
            "bootstrap sample [31.216, 0.994, -1.986, -0.293]\n",
            "bootstrap sample [30.242, 1.015, -1.948, 2.034]\n",
            "bootstrap sample [30.785, 0.893, -1.882, 0.137]\n",
            "bootstrap sample [29.293, 0.969, -1.783, 1.887]\n",
            "bootstrap sample [29.971, 0.938, -1.726, 0.936]\n",
            "bootstrap sample [29.408, 1.031, -1.798, 1.254]\n",
            "bootstrap sample [30.963, 0.952, -1.796, 1.448]\n",
            "bootstrap sample [30.618, 1.015, -1.836, 1.096]\n",
            "bootstrap sample [31.339, 0.956, -1.992, 0.189]\n",
            "bootstrap sample [32.545, 0.93, -1.948, -1.501]\n",
            "bootstrap sample [29.99, 1.022, -1.832, 1.668]\n",
            "bootstrap sample [30.792, 0.941, -1.841, 0.479]\n",
            "bootstrap sample [31.362, 0.93, -1.891, 1.461]\n",
            "bootstrap sample [30.412, 0.935, -1.744, 0.855]\n",
            "bootstrap sample [30.883, 0.926, -1.784, 0.988]\n",
            "bootstrap sample [30.985, 0.992, -1.941, -0.179]\n",
            "bootstrap sample [32.093, 0.9, -1.868, 0.47]\n",
            "bootstrap sample [29.958, 0.963, -1.903, 1.047]\n",
            "bootstrap sample [29.599, 0.966, -1.753, 1.502]\n",
            "bootstrap sample [28.702, 1.081, -1.922, 3.223]\n",
            "bootstrap sample [30.324, 0.981, -1.992, 1.186]\n",
            "bootstrap sample [30.305, 0.996, -1.847, 0.955]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbbmDqRCASEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4617c2c1-7dd4-4268-ef3e-5b49015cd8cf"
      },
      "source": [
        "bootstarp_standard_errors = [\r\n",
        "  standard_deviation([beta[i] for beta in bootstrap_betas])\r\n",
        "  for i in range(4)]\r\n",
        "\r\n",
        "print(bootstarp_standard_errors)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.1682705603246244, 0.08243581831591254, 0.11094275710263993, 1.0043213234354185]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSvlCYX4_C_R"
      },
      "source": [
        "我們可以用這些標準差的值，來檢定每個βi係數是不是「等於零」。  \r\n",
        "並提出以下假設：\r\n",
        "* 零假設(H₀)：**βi=0**\r\n",
        "* 對立假設(H₁)：**βi≠0**\r\n",
        "  \r\n",
        "定義一個統計量如下：  \r\n",
        "![公式](https://lh3.googleusercontent.com/3c2Ut_B-HmaR4KyErS_m2LOTSacVpzPjShCHhYokeYI-nJXWjXyn3NXMMKiFC8FbWXhqNtLtNAQrE9Y4KaAVK1poTrd_RVgHW8JfvDPANAz_8j8oG1ZFd44KKLdWU8e3RkUXRPHGhv-eFc3XrRQgCW2wOssYfGSwqz56FHIKJFgczzwntTcdVVMYV8LAENyHcrANIxO88FYWwas55tmtudxz1qRS_W5mOqATnmHRETImjEtla9Pc-vjiRDcF4NSXfZL6aamh8abg0VIQ2VK7tBv6MrYhPiJk6MLEKUJaAMSkkA0AFuB7k80Q3xqSdnu-UYOGqG5id3QnPsVzu_vEBF5yli9wfSMgfPPs29EsYGl-mwd-rR5IoisBJDmHYbPR7vfS8mdxpN1Wx4nYnP_eypfri4nqblpgPIH717f3oBkor0n_YBJ7uwUIgxJ_UifLMsjYX4GrIN-H-YE_ovh9OxIKiXykdZALZrs8XH73Yc2sj3OjRaUBy9GaUJHYAihpFP5r3R5xLK0388Ur1nwIM0YjWLfvR9Xhu-8Vgc8zk_0Ff-p6Y2vypJi9CE3YC5bfGRuQSe_s71ZDSG_XSR_t6tuLZEgK-1Km2gDXvzkFsv5zghGwNvnTehBqaSYBSDD0GPj4SKpGxvuYlzyG_50fpgQzf9ZtefoEAr1GaHhdlqqpY3wxPnRZqMYg8yJRfQ=w175-h99-no?authuser=0)  \r\n",
        "該統計量代表我們對βj的統計值，與其相應標準差估計值兩者相除的結果，其本身應該會形成一個「自由度為n-k」的學生t分佈。  \r\n",
        "如果我們知道**學生t分布的累積分佈函數**，就可以針對最小平方法所得出的每個細數計算出相對應的p值。\r\n",
        ">p值代表 零假設成立的情況下，觀察到該估計值的可能性有多大。  \r\n",
        "  \r\n",
        "儘管我們無法得知學生t分布的累積分佈函數；隨著自由度越來越大，該分佈仍會趨近於常態分佈。  \r\n",
        "因此，只要n遠大於k。我們就能使用常態累積分佈函數得出結果。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQmyLlbxIIbl"
      },
      "source": [
        "import math\r\n",
        "def normal_cdf(x:float,mu:float=0,sigma:float=1)->float:\r\n",
        "  return (1+math.erf((x-mu)/math.sqrt(2)/sigma))/2"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27gg4qu9ITUR"
      },
      "source": [
        "def p_value(beta_hat_j:float,sigma_hat_j:float)->float:\r\n",
        "  if beta_hat_j >0:\r\n",
        "    #如果係數為正，我們必須把「看到更大值」的機率乘以兩倍\r\n",
        "    return 2*( 1 - normal_cdf(beta_hat_j/sigma_hat_j))\r\n",
        "  else:\r\n",
        "    #否則就是把「看到更小值」的機率乘以兩倍\r\n",
        "    return 2* normal_cdf(beta_hat_j/sigma_hat_j)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDQtQ8glK2Hx"
      },
      "source": [
        "assert p_value(30.58,1.27) < 0.001  # 常數項\r\n",
        "assert p_value(0.972,0.103) < 0.001  # 朋友數量\r\n",
        "assert p_value(-1.865,0.115) < 0.001  # 工作時數\r\n",
        "assert p_value(0.923,1.249) > 0.4   # 博士"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQMIAbpLoLOA"
      },
      "source": [
        "# 正則化\r\n",
        "在誤差項中加入一懲罰項，以避免得到過大的beta係數值。  \r\n",
        "例如：**脊回歸(ridge regression)**  \r\n",
        "在誤差項中加入一個正比於beta_i平方和的懲罰項(beta_0常數項除外)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmKNej-sI3Ll"
      },
      "source": [
        "# alpha項：一個超參數(hyperparameter)，他控制的是懲罰項的影響程度\r\n",
        "# 有時也以lambda代稱，但已經被Python定義為匿名函式了\r\n",
        "def ridge_penalty(beta:Vector,alpha:float)->float:\r\n",
        "  return alpha * dot(beta[1:],beta[1:])\r\n",
        "\r\n",
        "def squared_error_ridge(x:Vector,y:float,beta:Vector,alpha:float)->float:\r\n",
        "  \"\"\"估計誤差值的平方，再加上對beta的脊懲罰項(ridge_penalty)\"\"\"\r\n",
        "  return error(x,y,beta)**2 + ridge_penalty(beta,alpha)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS7zGaDANpGA"
      },
      "source": [
        "接著，引入梯度遞減的作法："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2od4uTkNoro"
      },
      "source": [
        "def ridge_penalty_gradient(beta:Vector,alpha:float)->Vector:\r\n",
        "  \"\"\"純粹只估算脊懲罰項(ridge penalty)所對應的梯度值\"\"\"\r\n",
        "  return [0.]+[2*alpha*beta_j for beta_j in beta[1:]]\r\n",
        "\r\n",
        "def sqerror_ridge_gradient(x:Vector,y:float,beta:Vector,alpha:float)->Vector:\r\n",
        "  \"\"\"\r\n",
        "  計算出第i個平方誤差所對應的梯度值，其中也包括脊懲罰項\r\n",
        "  \"\"\"\r\n",
        "  return add(squerror_gradient(x,y,beta),ridge_penalty_gradient(beta,alpha))"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbZ1YEviQIv7"
      },
      "source": [
        "修改原本的least_squares_fit函式："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP7IwJ7qQXdh"
      },
      "source": [
        "def least_squares_fit_ridge(\r\n",
        "          xs:List[Vector],\r\n",
        "          ys:List[float],\r\n",
        "          alpha:float=0.0,\r\n",
        "          learning_rate:float=0.001,\r\n",
        "          num_steps:int=1000,\r\n",
        "          batch_size:int=1)->Vector:\r\n",
        "  \"\"\"\r\n",
        "  找出最小化平方誤差和的beta值\r\n",
        "  假設模型y = dot(x,beta)\r\n",
        "  \"\"\"\r\n",
        "  # 一開始先使隨機方式做出猜測\r\n",
        "  guess = [random.random() for _ in xs[0]]\r\n",
        "\r\n",
        "  for _ in tqdm.trange(num_steps,desc=\"least squares fit\"):\r\n",
        "    for start in range(0,len(xs),batch_size):\r\n",
        "      batch_xs = xs[start:start+batch_size]\r\n",
        "      batch_ys = ys[start:start+batch_size]\r\n",
        "\r\n",
        "      gradient = vector_mean([sqerror_ridge_gradient(x,y,guess,alpha) for x,y in zip(batch_xs,batch_ys)])\r\n",
        "\r\n",
        "      guess = gradient_step(guess,gradient,-learning_rate)\r\n",
        "  \r\n",
        "  return guess"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqsmkhaTQhbZ"
      },
      "source": [
        "### 假定alpha設定為0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS8ybIFSQlGG",
        "outputId": "0cb58436-a6ec-4d7c-ce34-bde1fca5ee46"
      },
      "source": [
        "random.seed(0)\r\n",
        "learning_rate=0.001\r\n",
        "beta_0 = least_squares_fit_ridge(inputs,daily_minutes_good,0.0,learning_rate,5000,25)\r\n",
        "\r\n",
        "#[30.51,0.97,-1.85,0.91]\r\n",
        "print(\"\\nbeta_0:\",list(np.round(np.array(beta_0),2)))\r\n",
        "print(\"beta_0內積：\",dot(beta_0[1:],beta_0[1:]) )\r\n",
        "assert 5 < dot(beta_0[1:],beta_0[1:]) < 6\r\n",
        "assert 0.67 < mulitiple_r_squared(inputs,daily_minutes_good,beta_0) < 0.69"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "least squares fit: 100%|██████████| 5000/5000 [00:04<00:00, 1107.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "beta_0: [30.51, 0.97, -1.85, 0.91]\n",
            "beta_0內積： 5.21088501552135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8zlmkM2YMj1"
      },
      "source": [
        "## 增加 alpha 值\r\n",
        "套入優度會變差，而beta的相應係數值也會變得越來越小。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hen7wgSeYZRZ",
        "outputId": "a1e99b2c-fecf-4c91-b4c7-d0b97e80c50a"
      },
      "source": [
        "random.seed(0)\r\n",
        "learning_rate=0.001\r\n",
        "beta_0_1 = least_squares_fit_ridge(inputs,daily_minutes_good,0.1,learning_rate,5000,25)\r\n",
        "\r\n",
        "#[30.8,0.95,-1.83,0.54]\r\n",
        "print(\"\\nbeta_0_1:\",list(np.round(np.array(beta_0_1),2)))\r\n",
        "print(\"beta_0_1內積：\",dot(beta_0_1[1:],beta_0_1[1:]) )\r\n",
        "assert 4 < dot(beta_0_1[1:],beta_0_1[1:]) < 5\r\n",
        "assert 0.67 < mulitiple_r_squared(inputs,daily_minutes_good,beta_0_1) < 0.69"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "least squares fit: 100%|██████████| 5000/5000 [00:04<00:00, 1109.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "beta_0_1: [30.8, 0.95, -1.83, 0.54]\n",
            "beta_0_1內積： 4.554201608410774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyYY-S0qYZbg",
        "outputId": "11869661-71d5-4b9d-d97b-fe680f40b540"
      },
      "source": [
        "random.seed(0)\r\n",
        "learning_rate=0.001\r\n",
        "beta_1 = least_squares_fit_ridge(inputs,daily_minutes_good,1.0,learning_rate,5000,25)\r\n",
        "\r\n",
        "#[30.65,0.9,-1.68,0.1]\r\n",
        "print(\"\\nbeta_1:\",list(np.round(np.array(beta_1),2)))\r\n",
        "print(\"beta_1內積：\",dot(beta_1[1:],beta_1[1:]) )\r\n",
        "assert 3 < dot(beta_1[1:],beta_1[1:]) < 4\r\n",
        "assert 0.67 < mulitiple_r_squared(inputs,daily_minutes_good,beta_1) < 0.69"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "least squares fit: 100%|██████████| 5000/5000 [00:04<00:00, 1102.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "beta_1: [30.65, 0.9, -1.68, 0.1]\n",
            "beta_1內積： 3.6274483410516174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ksc-SDoZMyy",
        "outputId": "dced9192-7226-4b5f-b891-edd24c2b2fc5"
      },
      "source": [
        "random.seed(0)\r\n",
        "learning_rate=0.001\r\n",
        "beta_10 = least_squares_fit_ridge(inputs,daily_minutes_good,10,learning_rate,5000,25)\r\n",
        "\r\n",
        "#[28.31, 0.67, -0.9, -0.01]\r\n",
        "print(\"\\nbeta_10:\",list(np.round(np.array(beta_10),2)))\r\n",
        "print(\"beta_10內積：\",dot(beta_10[1:],beta_10[1:]) )\r\n",
        "assert 1 < dot(beta_10[1:],beta_10[1:]) < 2\r\n",
        "assert 0.5 < mulitiple_r_squared(inputs,daily_minutes_good,beta_10) < 0.6"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "least squares fit: 100%|██████████| 5000/5000 [00:04<00:00, 1112.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "beta_10: [28.31, 0.67, -0.9, -0.01]\n",
            "beta_10內積： 1.2706657437961764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-MNQDpVhjk7"
      },
      "source": [
        "## 結論\r\n",
        "「PhD」係數隨著懲罰增加而消失，故可推論該係數很有可能根本就等於零。  \r\n",
        "與先前推估的結果是一致的。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BFmCZfvh6jt"
      },
      "source": [
        "# lasso迴歸\r\n",
        "傾向強迫某些係數變為零的作法，但不適合搭配梯度遞減的做法。"
      ]
    }
  ]
}