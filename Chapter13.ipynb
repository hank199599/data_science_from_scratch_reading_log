{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter13.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPsmBCsw5K3FRioaXIl2Rsr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hank199599/data_science_from_scratch_reading_log/blob/main/Chapter13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v56obdLeyaht"
      },
      "source": [
        "# 單純貝氏(Naive Bayes)\n",
        "描述在已知一些條件下，某事件的發生機率。  \n",
        "  \n",
        "**建立前提**：每個事件特徵基本上是獨立的，與其他事件沒有關係。  \n",
        "**特色**：不易發生過擬合\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPlZEX3vaBMA"
      },
      "source": [
        "# 理論：建構垃圾郵件篩選器"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNMHdRjZcSWE"
      },
      "source": [
        "## 極為簡單的版本 \n",
        "利用貝氏定理計算「此郵件為垃圾郵件」的機率：\n",
        "  \n",
        "在「此郵件包含bitcoin這個字眼」的事件下，此郵件為垃圾郵件的機率是：\n",
        "```\n",
        "P(S|B)=[P(B|S)P(S)/[P(B|S)P(S)+P(B|¬S)]P(¬S)\n",
        "```\n",
        "* S : 此郵件為垃圾郵件的事件  \n",
        "* B : 此郵件包含bitcoin這個字眼的事件\n",
        "  \n",
        "\n",
        "若手邊有大量郵件確定是垃圾郵件，亦有大量郵件確定不是垃圾郵件。  \n",
        "可以輕易估算出P(B|S)以及P(B|¬S)的值。  \n",
        "  \n",
        "若進一步假設，一封郵件是不是垃圾郵件的機率各占一半。(即P(S)=P(¬S)=0.5)  \n",
        "則原式可以被改寫為：\n",
        "\n",
        "```\n",
        "P(S|B)=[P(B|S)/[P(B|S)P(S)+P(B|¬S)]\n",
        "```\n",
        "假設：\n",
        "* 50%的垃圾郵件含有bitcoin這個字眼\n",
        "* 1%的非垃圾郵件含有bitcoin這個字眼\n",
        "→確實是垃圾郵件的機率是：\n",
        "\n",
        "\n",
        "```\n",
        "0.5/(0.5+0.01)=98%\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA1xsUv-cUxc"
      },
      "source": [
        "## 較為精巧的版本\n",
        "**假設**：  \n",
        "* 有個包含許多單詞w₁,...,wɴ的詞彙表(vocabulary)。  \n",
        "* 以Xi代表「郵件中包含wi這個單詞的事件」\n",
        "  \n",
        "**再假設我們能估計出**：\n",
        "* 垃圾郵件中包含wi的機率P(Xi|S)\n",
        "* 垃圾郵件中不包含wi的機率P(Xi|¬S)\n",
        "  \n",
        "```\n",
        "P(X₁=X₁,...,Xn=xn|S) = P(X₁=x₁|S)×...×P(Xn=xn|S)\n",
        "```\n",
        "\n",
        "假定詞彙表中只有「bitcion」與「rolex」兩個單詞，而在已知所有的垃圾郵件中：  \n",
        "* 一半擁有「earn bitcoin」\n",
        "* 一半擁有「authenic rolex」  \n",
        "\n",
        "在這個情況下，垃圾郵件同時包含「bitcion」與「rolex」兩字眼的機率為0。  \n",
        "若使用單純貝氏估算其機率：\n",
        "```\n",
        "P(X₁=1,X₂=1|S) = P(X₁=1|S)×P(X₂=1|S) = .5×.5 = .25\n",
        "```\n",
        "在這個假設裡，並未考慮到實際上「bitcion」與「rolex」這兩個單詞還是會互相影響。  \n",
        "而非理想上的獨立事件。在忽略理想情形與現實情形有所差距的情況下，這個模型仍經常被運用在現實世界的垃圾郵件篩選器之中。\n",
        "  \n",
        "在實務上，通常會盡量避免很多機率值相乘。  \n",
        "多個小於零的浮點數相乘後，易造成「**下溢(underflow)**」。  \n",
        "根據代數關係：\n",
        "* log(ab)=log(a)+log(b)\n",
        "* exp(log(x))=x  \n",
        "  \n",
        "我們能將原式轉換為：\n",
        "```\n",
        "exp(log(p1)+...+log(pn))\n",
        "```\n",
        "假定我們手邊有大量以標示過的垃圾郵件與非垃圾郵件用於訓練。  \n",
        "(log(x))=x  \n",
        "  \n",
        "我們能將原式轉換為：\n",
        "```\n",
        "exp(log(p1)+...+log(pn))\n",
        "```\n",
        "假定我們手邊有大量以標示過的垃圾郵件與非垃圾郵件用於訓練。  \n",
        "則我們可以估算出**垃圾郵件內容中包含wi這個單詞的機率P(Xi|S)**\n",
        "  \n",
        "然而，在機率計算中仍會出現問題：  \n",
        "假設在我們用於訓練的所有郵件中，詞彙表裡的「data」只出現在非垃圾郵件中。  \n",
        "```\n",
        "P(\"data\"|S)=0\n",
        "```\n",
        "這代表這個分類器只要遇到任何含有「**data**」單詞的郵件會判定為**非垃圾郵件**。\n",
        "即便出現「data on free bitcoin and authetic watches」這類的句子。  \n",
        "  \n",
        "在這種情況下，會使用一個**偽計數值k**。  \n",
        "在估算垃圾郵件中出現wi這個單詞時，採取以下作法：\n",
        "```\n",
        "P(Xi|S) = (k+所有垃圾郵件中含有wi這個單詞的郵件數量)/(2k+所有垃圾郵件的數量)\n",
        "```\n",
        "```\n",
        "P(Xi|¬S) = (k+所有非垃圾郵件中含有wi這個單詞的郵件數量)/(2k+所有非垃圾郵件的數量)\n",
        "```\n",
        "舉例來說：  \n",
        "如果「data」這個單詞在98封垃圾郵件中完全沒出現，而k值設定為1時。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS7HvSK5yBaW"
      },
      "source": [
        "# 實作\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blGFZ8tyCJes"
      },
      "source": [
        "## **建立物件的方式**\n",
        "1. 把郵件內容依據單詞進行拆分(tokenize)\n",
        "2. 把各不相同的單詞token集合起來\n",
        "3. 利用re.fill把所有單詞token都提取出來\n",
        "4. 用**set()**整併重複的token\n",
        " *斜體文字*\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWyI25qhGPfT"
      },
      "source": [
        "from typing import Set\n",
        "import re\n",
        "\n",
        "def tokenize(text:str) ->Set[str]:\n",
        "  text = text.lower()           #轉為小寫\n",
        "  all_words = re.findall(\"[a-z0-9]+\",text) #取出其中的單詞\n",
        "  return set(all_words)           #去掉重複的單詞"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r3Dj-dGDW7i"
      },
      "source": [
        "assert tokenize(\"Data Science is science\") == {\"data\",\"science\",\"is\"}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dqh--EuDua8"
      },
      "source": [
        "## 針對訓練資料定義資料型別 (基本物件)\n",
        "由於分類器須持續記錄訓練資料中出現的單詞token以及各種計數與標籤，因此採用物件類別的方法。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl2XJdZ9DuzD"
      },
      "source": [
        "from typing import NamedTuple\n",
        "\n",
        "class Message(NamedTuple):\n",
        "  text:str\n",
        "  is_spam:bool"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McdcbkpCEHur"
      },
      "source": [
        "## 定義處理該資料型別的方法(**method**)\n",
        "\n",
        "* ham ：非垃圾郵件\n",
        "* spam ：垃圾郵件\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "from typing import List,Tuple,Dict,Iterable\n",
        "import math\n",
        "from collections import defaultdict\n",
        "\n",
        "class NaiveBayesClassifier:\n",
        "  def __init__(self,k:float=0.5)->None:\n",
        "    self.k = k #平滑因子\n",
        "    \n",
        "    self.tokens:Set[str] = set()\n",
        "    self.token_spam_counts:Dict[str,int] = defaultdict(int)\n",
        "    self.token_ham_counts:Dict[str,int] = defaultdict(int)\n",
        "    self.spam_messages = self.ham_messages = 0\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPJOUVz6Mxa_"
      },
      "source": [
        "### 定義**方法**：針對一堆郵件進行訓練\n",
        "**方法**：針對一堆郵件進行訓練\n",
        "1. 累計垃圾郵件與非垃圾郵件數量\n",
        "2. 針對每封郵件進行分詞(tokenize)後的每個單詞token，根據該郵件是否是垃圾郵件來斷定該累計 **token_spam_counts** 還是 **token_ham_counts**\n",
        "\n",
        "\n",
        "```python\n",
        "def train(self,messages:Iterable[Message]) ->None:\n",
        "  for message in messages:\n",
        "    #累計郵件數量\n",
        "    if message.is_spam:\n",
        "      self.spam_messages += 1\n",
        "    else:\n",
        "      self.ham_messages += 1\n",
        "    \n",
        "    #累計單詞出現的次數\n",
        "    for token in tokenize(message.text):\n",
        "      self.tokens.add(token)\n",
        "      if message.is_spam:\n",
        "        self.token_spam_counts[token] += 1\n",
        "      else:\n",
        "        self.token_ham_counts[token] += 1\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xhCdnkwPYhy"
      },
      "source": [
        "###  定義**方法**：預測P(spam|token)此事件的機率值\n",
        "即出現某token的機率下，郵件為垃圾郵件的機率。  \n",
        "  \n",
        "**目標**；得到詞彙表中每個token相應的P(token|spam)與P(token|ham)  \n",
        "**方法**：建立一個private輔助函式來進行計算\n",
        "\n",
        "\n",
        "```python\n",
        "def _probabilities(self,token:str) ->Tuple[float,float]:\n",
        "  \"\"\"送回P(token|spam)與P(token|ham) \"\"\"\n",
        "  spam = self.token_spam_counts[token]\n",
        "  ham = self.token_ham_countsp[token]\n",
        "\n",
        "  p_token_spam = (spam + self.k)/(self.spam_messages + 2 * self.k)\n",
        "  p_token_ham = (ham + self.k)/(self.ham_messages + 2 * self.k)\n",
        "\n",
        "  return p_token_spam,p_token_ham\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7dGGmWpRM5b"
      },
      "source": [
        "### 定義**方法**：編寫預測方式\n",
        "在計算最終機率值上，採用對數相加而非直接相乘。\n",
        "\n",
        "```python\n",
        "def predict(self,text:str) ->float:\n",
        "  text.tokens = tokenize(text)\n",
        "  log_prob_if_spam = log_prob_if_ham = 0.0\n",
        "\n",
        "  # 以迭代方式，處理詞彙表中的每個單詞\n",
        "  for token in self.tokens:\n",
        "    log_prob_if_spam, p_token_ham = self._probabilities(token)\n",
        "\n",
        "    # 如果*token*有出現在郵件中，\n",
        "    # 就把「有看到該token」的對數機率值加進去\n",
        "    if token in text_tokens:\n",
        "      log_prob_if_spam += math.log(log_prob_if_spam)\n",
        "      log_prob_if_ham += math.log(log_prob_if_ham)\n",
        "    \n",
        "    #否則就把「沒有看到該token」的對數機率值加進去\n",
        "    #「沒有看到該token」的對數機率值就是log( 1 - 有看到該token機率值)\n",
        "    else:\n",
        "      log_prob_if_spam += math.log(1.0 - log_prob_if_spam)\n",
        "      log_prob_if_ham += math.log(1.0 - log_prob_if_ham)\n",
        "  \n",
        "  prob_if_spam = math.exp(log_prob_if_spam)\n",
        "  prob_if_ham = math.exp(log_prob_if_ham)\n",
        "  return prob_if_spam/(prob_if_spam + log_prob_if_ham)\n",
        "\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djJ1bViATAd_"
      },
      "source": [
        "### 到此，分類器已建置完成!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vck29wIXWSDo"
      },
      "source": [
        "from typing import List,Tuple,Dict,Iterable\n",
        "import math\n",
        "from collections import defaultdict\n",
        "\n",
        "class NaiveBayesClassifier:\n",
        "  def __init__(self,k:float=0.5)->None:\n",
        "    \"\"\"初始化欲包含的資料結構\"\"\"\n",
        "\n",
        "    self.k = k #平滑因子\n",
        "    self.tokens:Set[str] = set()\n",
        "    self.token_spam_counts:Dict[str,int] = defaultdict(int)\n",
        "    self.token_ham_counts:Dict[str,int] = defaultdict(int)\n",
        "    self.spam_messages = self.ham_messages = 0\n",
        "\n",
        "  def train(self,messages:Iterable[Message]) ->None:\n",
        "    for message in messages:\n",
        "      #累計郵件數量\n",
        "      if message.is_spam:\n",
        "        self.spam_messages += 1\n",
        "      else:\n",
        "        self.ham_messages += 1\n",
        "      \n",
        "      #累計單詞出現的次數\n",
        "      for token in tokenize(message.text):\n",
        "        self.tokens.add(token)\n",
        "        if message.is_spam:\n",
        "          self.token_spam_counts[token] += 1\n",
        "        else:\n",
        "          self.token_ham_counts[token] += 1\n",
        "  \n",
        "  def _probabilities(self,token:str) ->Tuple[float,float]:\n",
        "    \"\"\"預測P(spam|token)此事件的機率值\n",
        "      送回P(token|spam)與P(token|ham) \"\"\"\n",
        "    spam = self.token_spam_counts[token]\n",
        "    ham = self.token_ham_countsp[token]\n",
        "\n",
        "    p_token_spam = (spam + self.k)/(self.spam_messages + 2 * self.k)\n",
        "    p_token_ham = (ham + self.k)/(self.ham_messages + 2 * self.k)\n",
        "\n",
        "    return p_token_spam,p_token_ham\n",
        "  \n",
        "  def predict(self,text:str) ->float:\n",
        "    \"\"\"編寫預測方法\"\"\"\n",
        "\n",
        "    text.tokens = tokenize(text)\n",
        "    log_prob_if_spam = log_prob_if_ham = 0.0\n",
        "\n",
        "    # 以迭代方式，處理詞彙表中的每個單詞\n",
        "    for token in self.tokens:\n",
        "      log_prob_if_spam, p_token_ham = self._probabilities(token)\n",
        "\n",
        "      # 如果*token*有出現在郵件中，\n",
        "      # 就把「有看到該token」的對數機率值加進去\n",
        "      if token in text_tokens:\n",
        "        log_prob_if_spam += math.log(log_prob_if_spam)\n",
        "        log_prob_if_ham += math.log(log_prob_if_ham)\n",
        "      \n",
        "      #否則就把「沒有看到該token」的對數機率值加進去\n",
        "      #「沒有看到該token」的對數機率值就是log( 1 - 有看到該token機率值)\n",
        "      else:\n",
        "        log_prob_if_spam += math.log(1.0 - log_prob_if_spam)\n",
        "        log_prob_if_ham += math.log(1.0 - log_prob_if_ham)\n",
        "    \n",
        "    prob_if_spam = math.exp(log_prob_if_spam)\n",
        "    prob_if_ham = math.exp(log_prob_if_ham)\n",
        "\n",
        "    return prob_if_spam/(prob_if_spam + log_prob_if_ham)\n",
        "\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOD--8uhyFCG"
      },
      "source": [
        "# 測試模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxE7pSe6zttH"
      },
      "source": [
        "#編寫一些單元測試方法，以確保模型可以正確運作\n",
        "message=[Message(\"spam rules\",is_spam=True),\n",
        "     Message(\"ham rules\",is_spam=False),\n",
        "     Message(\"hello ham\",is_spam=False)]\n",
        "\n",
        "model = NaiveBayesClassifier(k=0.5) #假定平滑因子為0.5\n",
        "model.train(message)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUdaE2cqZoH7"
      },
      "source": [
        "### 1. 檢查它是否可以正確計算出各種計數值"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWG_50hiZ1Lx"
      },
      "source": [
        "assert model.tokens == {\"spam\",\"ham\",\"rules\",\"hello\"}\n",
        "assert model.spam_messages == 1\n",
        "assert model.ham_messages == 2\n",
        "assert model.token_spam_counts =={\"spam\":1,\"rules\":1}\n",
        "assert model.token_ham_counts == {\"ham\":2,\"rules\":1,\"hello\":1}\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K71iaNDSZvmH"
      },
      "source": [
        "### 2.進行預測\n",
        "透過手工方式進行單純貝氏邏輯的相關計算，並確認可的到相同的結果：\n",
        "  \n",
        "假定文字是：\"hello spam\"\n",
        "\n",
        "* 分析這段文字：\n",
        "  * 出現\"sapm\"次數：1\n",
        "  * 出現\"ham\"次數：0\n",
        "  * 出現\"rules\"次數：0\n",
        "  * 出現\"hello\"次數：1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsHMJyGEazaU"
      },
      "source": [
        "text = \"hello spam\"\n",
        "\n",
        "probs_if_spam =[\n",
        "  (1+0.5)/(1+2*0.5),  #\"spam\"：有這個詞\n",
        "  1-(0+0.5)/(1+2*0.5), #\"ham\"：沒有這個詞\n",
        "  1-(1+0.5)/(1+2*0.5), #\"rules\"：沒有這個詞 \n",
        "  (0+0.5)/(1+2*0.5)   #\"hello\"：有這個詞\n",
        "]\n",
        "\n",
        "probs_if_ham =[\n",
        "  (0+0.5)/(2+2*0.5),  #\"spam\"：有這個詞\n",
        "  1-(2+0.5)/(2+2*0.5), #\"ham\"：沒有這個詞\n",
        "  1-(1+0.5)/(2+2*0.5), #\"rules\"：沒有這個詞 \n",
        "  (1+0.5)/(2+2*0.5)   #\"hello\"：有這個詞\n",
        "]\n",
        "\n",
        "p_if_spam = math.exp(sum(math.log(p) for p in probs_if_spam))\n",
        "p_if_ham = math.exp(sum(math.log(p) for p in probs_if_ham))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hldHr_2fyG7h"
      },
      "source": [
        "# 運用模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2T94rnZzuEJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}